{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.getcwd() != '/home/hyeryungson/mucoco':\n",
    "    print(\"change dir to '/home/hyeryungson/mucoco'\")\n",
    "    os.chdir('/home/hyeryungson/mucoco')\n",
    "\n",
    "from notebooks.energy_model_retrain.load_ckpt import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('/home/hyeryungson/mucoco/data/toxicity/jigsaw-unintended-bias-in-toxicity-classification/fine-grained/test.jsonl',\n",
    "                    lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select toxic 0.5~1.0\n",
    "test = test.loc[test['toxicity']>=0.5]\n",
    "test = test.reset_index(drop=True)\n",
    "test['toxicity_bin'] = pd.cut(test['toxicity'], np.arange(0.5, 1.1, 0.1), labels=np.arange(6))\n",
    "test_=test.copy()\n",
    "\n",
    "## randomly select from each bin\n",
    "tot_count=150\n",
    "bin_count=6\n",
    "test = test.groupby('toxicity_bin').sample(int(tot_count/bin_count), random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add 4 examples from toxicity 1\n",
    "test = pd.concat([test, test_.loc[((~test_.index.isin(test.index)) & (test_.toxicity>0.99))].sample(4, random_state=11)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_json('./notebooks/results/labelling_samples_test_geq0.5_150.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda\n"
     ]
    }
   ],
   "source": [
    "model,config,tokenizer=define_model('/home/hyeryungson/mucoco/models_bak_contd/roberta-base-jigsaw-toxicity-classifier-with-gpt2-large-embeds/checkpoint_best/pytorch_model.bin',\n",
    "                                 output_attentions=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized=tokenizer(test['text'].tolist(),padding=True, return_tensors=\"pt\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model input size와 같아야할거같은데!\n",
    "tokenized_ids=tokenized['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(tokenized_ids.shape[0]):\n",
    "    tmp_sent = tokenized_ids[i]\n",
    "    tmp_toks = [tokenizer.decode(x) for x in tmp_sent]\n",
    "    res.append(tmp_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting from index 4.0\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./notebooks/results/toxic_labels.txt'):\n",
    "    with open('./notebooks/results/toxic_labels.txt','r') as f:\n",
    "        contents = f.readlines()\n",
    "    last_index = len(contents)/2\n",
    "    print(f'starting from index {last_index}')\n",
    "else:\n",
    "    fptr = open('./notebooks/results/toxic_labels.txt', 'w')\n",
    "    fptr.close()\n",
    "    last_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525 ||||||||||| as long as you cannot admit who your enemies are you are losing fast. these guys want you dead yet they get modern missiles from your army. WTF!!!!<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "0 ------ as\n",
      "1 ------  long\n",
      "2 ------  as\n",
      "3 ------  you\n",
      "4 ------  cannot\n",
      "5 ------  admit\n",
      "6 ------  who\n",
      "7 ------  your\n",
      "8 ------  enemies\n",
      "9 ------  are\n",
      "10 ------  you\n",
      "11 ------  are\n",
      "12 ------  losing\n",
      "13 ------  fast\n",
      "14 ------ .\n",
      "15 ------  these\n",
      "16 ------  guys\n",
      "17 ------  want\n",
      "18 ------  you\n",
      "19 ------  dead\n",
      "20 ------  yet\n",
      "21 ------  they\n",
      "22 ------  get\n",
      "23 ------  modern\n",
      "24 ------  missiles\n",
      "25 ------  from\n",
      "26 ------  your\n",
      "27 ------  army\n",
      "28 ------ .\n",
      "29 ------  W\n",
      "30 ------ TF\n",
      "31 ------ !!!!\n",
      "List you typed: \n",
      "0.525 ||||||||||| Bahaha. \n",
      "\n",
      "That is super funny.\n",
      "\n",
      "Seriously, though. If I ever wanted to kill myself, I'd climb your ego, and jump to your IQ.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "0 ------ Bah\n",
      "1 ------ aha\n",
      "2 ------ .\n",
      "3 ------  \n",
      "4 ------ \n",
      "\n",
      "5 ------ \n",
      "\n",
      "6 ------ That\n",
      "7 ------  is\n",
      "8 ------  super\n",
      "9 ------  funny\n",
      "10 ------ .\n",
      "11 ------ \n",
      "\n",
      "12 ------ \n",
      "\n",
      "13 ------ Seriously\n",
      "14 ------ ,\n",
      "15 ------  though\n",
      "16 ------ .\n",
      "17 ------  If\n",
      "18 ------  I\n",
      "19 ------  ever\n",
      "20 ------  wanted\n",
      "21 ------  to\n",
      "22 ------  kill\n",
      "23 ------  myself\n",
      "24 ------ ,\n",
      "25 ------  I\n",
      "26 ------ 'd\n",
      "27 ------  climb\n",
      "28 ------  your\n",
      "29 ------  ego\n",
      "30 ------ ,\n",
      "31 ------  and\n",
      "32 ------  jump\n",
      "33 ------  to\n",
      "34 ------  your\n",
      "35 ------  IQ\n",
      "36 ------ .\n"
     ]
    }
   ],
   "source": [
    "for i in range(last_index, tokenized_ids.shape[0]):\n",
    "    try:\n",
    "        print(f\"{test['toxicity'].tolist()[i]} ||||||||||| {''.join(res[i])}\")\n",
    "        for j in range(len(res[i])):\n",
    "            if res[i][j] != '<|endoftext|>':\n",
    "                print(f\"{j} ------ {res[i][j]}\")\n",
    "        toxic_tokens=input(\"input comma separated list of tokens that are toxic >>\")\n",
    "        if '-' in toxic_tokens:\n",
    "            start, end = toxic_tokens.split('-')    \n",
    "            toxic_tokens = ','.join([str(x) for x in range(int(start.strip()), int(end.strip())+1,1)])\n",
    "        print(f\"List you typed: {toxic_tokens}\")\n",
    "        # toxic_tokens=toxic_tokens.split(\",\")\n",
    "        fptr = open('./notebooks/results/toxic_labels.txt', 'a')\n",
    "        fptr.write(''.join(res[i]) + '\\n')\n",
    "        fptr.write(toxic_tokens + '\\n')\n",
    "        fptr.close()\n",
    "    except KeyboardInterrupt:\n",
    "        fptr = open('./notebooks/results/toxic_labels.txt', 'a')\n",
    "        fptr.write(i + '\\n')\n",
    "        fptr.close()\n",
    "        last_index = i    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
