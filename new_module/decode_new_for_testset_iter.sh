#!/bin/bash
#SBATCH --time=0-72:00:00
#SBATCH --mem=10GB
#SBATCH --nodes=1
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:1
#SBATCH --output='formality_decoding_original_mlm_reranking_%j.out'
#SBATCH --nodelist=n02

source ~/.bashrc
source ~/miniconda3/etc/profile.d/conda.sh
conda activate loc-edit

srun python mucoco/decode_new_for_testset_iter.py \
 --AR_temperature=1.0\
 --AR_top_k=0\
 --AR_top_p=0.96\
 --adam_betas='(0.9, 0.999)'\
 --adam_eps=1e-08\
 --additional_data='none'\
 --allow_diff_vocab=True\
 --always_mucoco='false'\
 --baselm_gen_online=True\
 --batch_size=1\
 --beam=False\
 --beam_size=1\
 --betas='0.8:0.2'\
 --bos=True\
 --cache_dir='hf_cache'\
 --coeff_pattern='constant'\
 --coeff_steps=200\
 --cpu=False\
 --custom_epsilons='none'\
 --damp=False\
 --dampness=0.1\
 --data='data/formality/GYAFC_Corpus/Entertainment_Music/test/informal'\
 --datastyle='text'\
 --debug=False\
 --debug_gradients='false'\
 --decay_method=None\
 --decay_steps=1\
 --decode_temperature=0.1\
 --dynamic_lambda_update=True\
 --dynamic_lr_update=True\
 --early_stop_steps=40\
 --embedgd_begin_temperature=0.5\
 --embedgd_decay_method=None\
 --embedgd_do_sample='false'\
 --embedgd_final_temperature=0.05\
 --embedgd_grad_distance='l2'\
 --embedgd_gumbel_noise_max=0.0\
 --embedgd_lr_pattern='constant'\
 --embedgd_momentum=0.0\
 --embedgd_noise_variance=1.0\
 --embedgd_temperature_reduction_steps=50\
 --embedgd_top_k=0\
 --embedgd_top_p=1.0\
 --end_idx=-1\
 --eos=True\
 --epsilon=0.2\
 --epsilon_cooldown_steps='1'\
 --epsilon_decay_functions='linear'\
 --epsilon_warmup_steps='0'\
 --epsilons='-3'\
 --evaluation_metrics='fluency'\
 --expgd_do_sample=False\
 --expgd_gumbel_noise_max=0.0\
 --expgd_momentum=0.0\
 --expgd_mw=1\
 --expgd_top_k=0\
 --expgd_top_p=1.0\
 --final_bias=False\
 --fp16_source='pytorch'\
 --gold_loss_epsilons='none'\
 --half_lr=False\
 --init='target'\
 --jsonl_primary_key='prompt'\
 --jsonl_secondary_key='text'\
 --jsonl_tertiary_key=None\
 --jsonl_tokenized='false'\
 --keyword_tau=2.0\
 --keyword_topk=1\
 --keywords='none'\
 --kweight=5.0\
 --label_id='0:0'\
 --lambda_lr=1.0\
 --lambda_update=50\
 --length_diff='0'\
 --length_normalize=False\
 --linear_scale='false'\
 --locate_edit=True\
 --log_interval=25\
 --loss='gpt2:classification_no_prefix'\
 --loss_type='dotplusplus'\
 --lossabbr='pyx:formality'\
 --lr=0.25\
 --lr_decay=1.0\
 --lr_update_size=0.01\
 --match_with='reference'\
 --max_allowed_length=200\
 --max_grad_norm=0.0\
 --max_length=20\
 --max_lr=0.45\
 --max_output_length=20\
 --max_prefix_length=50\
 --metric='l2'\
 --min_epsilons='-3'\
 --min_lr=None\
 --model='gpt2-large:models/roberta-base-pt16-formality-regressor-with-gpt2-large-embeds-rescale/epoch_17'\
 --model_dtype='fp32'\
 --model_types='AutoModelForCausalLM:RobertaCustomForSequenceClassification'\
 --num_edit_token_per_step=6\
 --num_examples=100\
 --num_locate_steps=-1\
 --num_log_steps=5\
 --num_project_steps=5\
 --num_samples=1\
 --only_mucoco='false'\
 --optim='embedgd'\
 --optim_steps=20\
 --outfile='outputs/formality/roberta-base-pt16-formality-regressor-with-gpt2-large-embeds-rescale/locate-edit-gpt2-loc-6toks--1steps-project-5steps-allsat/outputs_epsilon-3.txt'\
 --output_style='jsonl'\
 --prefix_length=0\
 --random_example='true'\
 --repetition_penalty=0.0\
 --restarts=0\
 --results_path=None\
 --same_embeds=True\
 --sampling_strategy='greedy'\
 --sampling_strategy_k='none'\
 --scale_loss='none'\
 --seed=42\
 --selection_criterion='allsat'\
 --semantic_methods='bertscore'\
 --sgd_momentum=0.0\
 --sgd_nesterov=False\
 --show_all_outputs=False\
 --show_warnings=False\
 --st=False\
 --start_decay_steps=1\
 --start_idx=0\
 --suffix_length=0\
 --suffix_source=None\
 --target_tokenize_different=False\
 --target_type='embeds'\
 --time=False\
 --tokenizer='gpt2-large:models/roberta-base-pt16-formality-regressor-with-gpt2-large-embeds-rescale/epoch_17'\
 --topic_target='none'\
 --topic_word_lists='none'\
 --use_context='false'\
 --warmup_end_lr=None\
 --warmup_init_lr=None\
 --warmup_steps=1\
 --weight_decay=0.0\
 --task_type='revision'\
 