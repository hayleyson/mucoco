{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hyeryung/.conda/envs/loc-edit/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "import math\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "# os.chdir('/data/hyeryung/mucoco')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from new_module.new_decode_utils import get_beam_hypotheses_v0, get_beam_hypotheses_v1, get_combi_hypotheses, final_reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_outputs = pd.read_json('/data/hyeryung/mucoco/outputs/toxicity/llm/r7kykwge/outputs_epsilon0.9.txt.intermediate', lines=True)\n",
    "intermediate_outputs = intermediate_outputs.explode('generations').reset_index(drop=True)\n",
    "\n",
    "intermediate_outputs_eda = intermediate_outputs.loc[intermediate_outputs['generations'].apply(len) != 0].reset_index(drop=True)\n",
    "intermediate_outputs_eda['prompt'] = intermediate_outputs_eda['prompt'].apply(lambda x: x['text'])\n",
    "intermediate_outputs_eda['original_sentences'] = intermediate_outputs_eda['generations'].apply(lambda x: [item[1] for item in x.items() if 'original' in item[0]])\n",
    "intermediate_outputs_eda['masked_sentences'] = intermediate_outputs_eda['generations'].apply(lambda x: [item[1] for item in x.items() if 'mask' in item[0]])\n",
    "intermediate_outputs_eda['masked_sentences_joined_by_prompt'] = intermediate_outputs_eda[['prompt','masked_sentences']].apply(lambda x: [' ' .join([x['prompt'], y]) for y in x['masked_sentences']], axis=1)\n",
    "\n",
    "intermediate_outputs_eda['explode_key'] = intermediate_outputs_eda.apply(lambda x: list(zip(x['original_sentences'], x['masked_sentences'])),axis=1)\n",
    "\n",
    "intermediate_outputs_eda = intermediate_outputs_eda.explode('explode_key')\n",
    "intermediate_outputs_eda['original_sentences'] = intermediate_outputs_eda['explode_key'].apply(lambda x: x[0])\n",
    "intermediate_outputs_eda['masked_sentences'] = intermediate_outputs_eda['explode_key'].apply(lambda x: x[1])\n",
    "\n",
    "all_masked_sentences = intermediate_outputs_eda['masked_sentences'].to_list()\n",
    "all_original_sentences = intermediate_outputs_eda['original_sentences'].to_list()\n",
    "all_matching_prompts = intermediate_outputs_eda['prompt'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_span_lengths_and_count(text):\n",
    "    mask_matches = list(re.finditer('<mask>', text))\n",
    "\n",
    "    mask_info_dict= defaultdict(list)\n",
    "    prev_mask = None\n",
    "    span_count = 0\n",
    "    curr_span_length = 1\n",
    "    for i, mask in enumerate(mask_matches):\n",
    "        \n",
    "        if i == 0:\n",
    "            mask_info_dict[span_count].append(i)\n",
    "            \n",
    "        else:\n",
    "            if prev_mask.span()[1] == mask.span()[0]:\n",
    "                mask_info_dict[span_count].append(i)\n",
    "                curr_span_length += 1\n",
    "            else:\n",
    "                span_count += 1\n",
    "                mask_info_dict[span_count].append(i)\n",
    "                curr_span_length = 1\n",
    "        prev_mask = mask\n",
    "\n",
    "    span_lengths = []\n",
    "    for span_id, span_len in mask_info_dict.items():\n",
    "        \n",
    "        span_lengths.append(len(span_len))\n",
    "    return mask_info_dict, span_lengths\n",
    "\n",
    "mask_info_dicts = []\n",
    "span_lengths_es = []\n",
    "for test_sent in all_masked_sentences:\n",
    "    \n",
    "    mask_info_dict, span_lengths = analyze_span_lengths_and_count(test_sent)\n",
    "    mask_info_dicts.append(mask_info_dict)\n",
    "    span_lengths_es.append(span_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean # of spans: 3.5402985074626865\n",
      "median # of spans: 4.0\n",
      "max # of spans: 5\n",
      "min # of spans: 1\n"
     ]
    }
   ],
   "source": [
    "# multiple spans are located in one example\n",
    "span_counts = [len(x) for x in span_lengths_es]\n",
    "print(f\"mean # of spans: {np.mean(span_counts)}\")\n",
    "print(f\"median # of spans: {np.median(span_counts)}\")\n",
    "print(f\"max # of spans: {np.max(span_counts)}\")\n",
    "print(f\"min # of spans: {np.min(span_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean # of span lengths: 1.887858347386172\n",
      "median # of span lengths: 2.0\n",
      "max # of span lengths: 8\n",
      "min # of span lengths: 1\n",
      "0,10,20,..,100% # of span lengths: [1. 1. 1. 1. 1. 2. 2. 2. 2. 3. 8.]\n"
     ]
    }
   ],
   "source": [
    "# number of tokens per span\n",
    "span_lenghts_es_unravel = sum(span_lengths_es, [])\n",
    "print(f\"mean # of span lengths: {np.mean(span_lenghts_es_unravel)}\")\n",
    "print(f\"median # of span lengths: {np.median(span_lenghts_es_unravel)}\")\n",
    "print(f\"max # of span lengths: {np.max(span_lenghts_es_unravel)}\")\n",
    "print(f\"min # of span lengths: {np.min(span_lenghts_es_unravel)}\")\n",
    "print(f\"0,10,20,..,100% # of span lengths: {np.percentile(span_lenghts_es_unravel, np.arange(0, 101, 10))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 1, 2],\n",
       " [6, 2, 2],\n",
       " [2, 2, 1, 3],\n",
       " [4, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [3, 1, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [1, 1, 1, 3],\n",
       " [3, 2, 2, 1],\n",
       " [1, 6, 2, 2],\n",
       " [2, 6, 3],\n",
       " [4, 1, 1],\n",
       " [6],\n",
       " [1, 6, 1],\n",
       " [7, 6],\n",
       " [6, 3],\n",
       " [1, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 1, 1, 1, 1],\n",
       " [4, 4, 6],\n",
       " [2, 3],\n",
       " [6],\n",
       " [2, 1, 2, 2, 1],\n",
       " [8, 2],\n",
       " [1, 6],\n",
       " [7, 6],\n",
       " [4, 2],\n",
       " [2, 1, 2, 2, 2],\n",
       " [4, 4, 2],\n",
       " [7, 6],\n",
       " [4, 1],\n",
       " [7, 6],\n",
       " [1, 4],\n",
       " [1, 1, 1, 1, 2],\n",
       " [1, 1, 1, 1, 2],\n",
       " [1, 1, 3, 2],\n",
       " [1, 2, 1, 1, 2],\n",
       " [1, 1, 1, 1, 2],\n",
       " [1, 1, 3, 2],\n",
       " [1, 1, 1, 1, 2],\n",
       " [1, 1, 1, 1, 2],\n",
       " [7, 6],\n",
       " [4, 2],\n",
       " [4, 4, 2],\n",
       " [1, 1, 1, 1, 2],\n",
       " [5, 2],\n",
       " [2, 1, 1, 1, 2],\n",
       " [2, 3, 2],\n",
       " [3, 4],\n",
       " [1, 1, 4],\n",
       " [1, 4],\n",
       " [2, 2, 2, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [2, 2, 1],\n",
       " [1, 1, 2, 3],\n",
       " [1, 3, 1, 1],\n",
       " [1, 1, 3, 3],\n",
       " [2, 4, 1, 2],\n",
       " [1, 2, 1, 2],\n",
       " [1, 1, 1, 1, 1],\n",
       " [2, 3, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [1, 1, 1, 2, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 5],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 1, 2, 2],\n",
       " [2, 2, 2, 1],\n",
       " [1, 2, 1, 1, 1],\n",
       " [2, 1, 1, 2, 1],\n",
       " [1, 4, 1],\n",
       " [2, 1, 1, 2, 1],\n",
       " [2, 2, 2, 1],\n",
       " [2, 2, 2, 1],\n",
       " [2, 3, 1],\n",
       " [1, 1, 1, 2],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 1, 1],\n",
       " [3, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [1, 1, 1, 2, 1],\n",
       " [3, 2, 2],\n",
       " [3, 2, 4],\n",
       " [2, 2, 1],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 3, 1],\n",
       " [4, 2],\n",
       " [4, 1, 2],\n",
       " [3, 2, 1],\n",
       " [3, 2, 1],\n",
       " [2, 1, 1, 1, 2],\n",
       " [4, 2],\n",
       " [3, 2, 1],\n",
       " [3, 2],\n",
       " [4, 1, 1],\n",
       " [2, 2, 1],\n",
       " [1, 1, 2, 2, 1],\n",
       " [1, 5, 3],\n",
       " [1, 3, 3, 1],\n",
       " [2, 2, 1, 4],\n",
       " [2, 2, 1, 1, 2],\n",
       " [2, 2, 1, 1, 1],\n",
       " [2, 1, 2],\n",
       " [8, 3, 1],\n",
       " [1, 5],\n",
       " [2, 1, 1, 1],\n",
       " [3, 1, 1],\n",
       " [5],\n",
       " [2, 3, 2],\n",
       " [4, 1, 1, 1, 1],\n",
       " [4],\n",
       " [6, 1],\n",
       " [5],\n",
       " [8],\n",
       " [3],\n",
       " [7],\n",
       " [7, 2],\n",
       " [1, 3, 3],\n",
       " [2, 3],\n",
       " [2, 1, 2, 3, 1],\n",
       " [1, 4, 3],\n",
       " [5, 2, 1],\n",
       " [1, 3, 1, 3],\n",
       " [3, 2, 1],\n",
       " [2, 1, 1, 3],\n",
       " [3, 2, 1, 1],\n",
       " [5, 1],\n",
       " [3, 2, 1],\n",
       " [3, 3],\n",
       " [4, 1, 1, 2],\n",
       " [2, 3, 1],\n",
       " [1, 1, 3],\n",
       " [1, 3, 1],\n",
       " [1, 3, 3, 1],\n",
       " [3, 4],\n",
       " [3, 3],\n",
       " [5, 1],\n",
       " [3, 1, 2, 1],\n",
       " [3, 2, 3],\n",
       " [4, 1, 3],\n",
       " [3, 1, 1, 1],\n",
       " [3, 3],\n",
       " [4, 3],\n",
       " [3, 3],\n",
       " [2, 1, 3],\n",
       " [4, 1, 1],\n",
       " [1, 3, 1, 1],\n",
       " [1, 4, 1],\n",
       " [1, 5, 2],\n",
       " [5, 3],\n",
       " [1, 2, 1, 6],\n",
       " [1, 1, 1, 4, 1],\n",
       " [1, 1, 2, 2],\n",
       " [5, 1, 2],\n",
       " [2, 1, 1, 1, 1],\n",
       " [2, 2, 1],\n",
       " [2, 2, 1, 2],\n",
       " [1, 6],\n",
       " [2, 3],\n",
       " [1, 2, 1, 1],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1],\n",
       " [1, 2, 2, 3],\n",
       " [1, 6, 2],\n",
       " [5, 1, 2],\n",
       " [1, 1, 1, 2, 6],\n",
       " [3, 1, 1, 1, 2],\n",
       " [4, 1, 1],\n",
       " [1, 1, 1, 2, 4],\n",
       " [2, 1, 1, 2],\n",
       " [4, 1, 1],\n",
       " [5],\n",
       " [1, 3, 2],\n",
       " [2, 1, 2],\n",
       " [1, 3, 2],\n",
       " [1, 4],\n",
       " [3, 3, 1, 2],\n",
       " [1, 3, 3],\n",
       " [1, 4, 2],\n",
       " [1, 6],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 4, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [5],\n",
       " [5, 1],\n",
       " [1, 3],\n",
       " [1, 3, 2],\n",
       " [1, 2, 2, 3],\n",
       " [1, 2, 1, 1, 4],\n",
       " [6, 4],\n",
       " [4, 2],\n",
       " [2, 3, 1],\n",
       " [2, 1, 3],\n",
       " [1, 2, 2],\n",
       " [2, 1, 3],\n",
       " [2, 1, 3],\n",
       " [2, 3],\n",
       " [1, 1, 2, 2],\n",
       " [1, 3, 1],\n",
       " [1, 2, 3],\n",
       " [1, 2, 2],\n",
       " [1, 2, 1, 2],\n",
       " [1, 2, 2, 2],\n",
       " [2, 1, 1, 2, 1],\n",
       " [1, 1, 4],\n",
       " [3, 3],\n",
       " [1, 1, 2, 2, 1],\n",
       " [1, 2, 1, 2],\n",
       " [8],\n",
       " [8],\n",
       " [2, 2, 2, 1],\n",
       " [1, 2, 2, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [2, 2, 1, 2],\n",
       " [1, 1, 3, 1],\n",
       " [1, 3, 3],\n",
       " [2, 2, 1, 2, 2],\n",
       " [2, 2, 1, 2],\n",
       " [1, 1, 2, 1, 1],\n",
       " [2, 1, 2, 1, 2],\n",
       " [1, 1, 1, 3],\n",
       " [4, 1],\n",
       " [1, 1, 3, 2],\n",
       " [1, 2, 3],\n",
       " [1, 1, 4],\n",
       " [2, 1, 2, 3],\n",
       " [2, 2, 1, 3],\n",
       " [2, 1, 3],\n",
       " [2, 1, 4],\n",
       " [3, 2, 1, 1],\n",
       " [2, 2, 3, 4],\n",
       " [2, 1, 4, 2],\n",
       " [1, 2, 1, 3],\n",
       " [2, 1, 2, 1],\n",
       " [1, 2, 1, 2],\n",
       " [1, 1, 1, 1, 2],\n",
       " [2, 2, 2, 1, 2],\n",
       " [2, 2, 1, 3],\n",
       " [3, 3, 1],\n",
       " [2, 2, 1, 2],\n",
       " [2, 3, 1],\n",
       " [3, 2, 2],\n",
       " [3, 1],\n",
       " [1, 1, 4],\n",
       " [2, 2, 2],\n",
       " [2, 2, 2],\n",
       " [2, 2, 1, 1],\n",
       " [2, 2, 2],\n",
       " [3, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 2, 1, 1, 1],\n",
       " [3, 4, 2, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [2, 1, 1, 2],\n",
       " [1, 2, 3, 1, 1],\n",
       " [1, 2, 1, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [3, 1, 1, 1],\n",
       " [3, 1, 1],\n",
       " [2, 1, 1, 1],\n",
       " [3, 1, 1],\n",
       " [3, 1, 1],\n",
       " [2, 1, 1, 1],\n",
       " [3, 1, 1],\n",
       " [3, 1, 1],\n",
       " [2, 1, 1, 1],\n",
       " [3, 1, 1],\n",
       " [2, 1, 3, 1],\n",
       " [1, 1, 1, 2],\n",
       " [1, 3, 2],\n",
       " [3, 1, 1, 2, 2],\n",
       " [2, 3, 3]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# among these spans, multiple spans have >1 lengths\n",
    "span_lengths_es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method 1. replace with none to multiple masks\n",
    "#### 1) combinatorially make all potential masking schemes (+1 for deletion case): (max_masks+1) ^ (num_spans) e.g. 4^4 \n",
    "#### 2) generate beam-sized candidates for each masking scheme : 1 + (beam_size) * ((max_masks+1) ^ (num_spans) - 1)\n",
    "#### 3) final reranking over all candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): huggingface.co:443\n",
      "https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /gpt2-large/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /gpt2-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /gpt2-large/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "# Set up for experiment\n",
    "## load tokenizer, models, define losses, etc.\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM, AutoTokenizer\n",
    "import new_module.losses as lossbuilder\n",
    "import joblib\n",
    "config = joblib.load('/data/hyeryung/mucoco/config.pkl')\n",
    "config['model_types'][1] = 'AutoModelForSequenceClassification'\n",
    "config['loss_weights'] = [0.1,1.0]\n",
    "\n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "mlm = AutoModelForMaskedLM.from_pretrained('roberta-base')\n",
    "class dummyArgs:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "build_loss_args = dummyArgs(**config[\"build_loss_dict\"])\n",
    "\n",
    "name2tokenizer = {}\n",
    "name2model = {}\n",
    "name2config = {}\n",
    "loss2tokenizer = {}\n",
    "embed_luts = []\n",
    "for i, model_path in enumerate(config[\"model_paths\"]):\n",
    "    if (\n",
    "        model_path not in name2model\n",
    "    ):  # making sure we are not loading the model twice in case some constraints use the same model.\n",
    "        try:\n",
    "            name2tokenizer[config[\"tokenizer_paths\"][i]] = AutoTokenizer.from_pretrained(\n",
    "                config[\"tokenizer_paths\"][i],\n",
    "                cache_dir=config[\"cache_dir\"],\n",
    "                use_fast=True,\n",
    "            )\n",
    "        except:\n",
    "            name2tokenizer[config[\"tokenizer_paths\"][i]] = AutoTokenizer.from_pretrained(\n",
    "                config[\"tokenizer_paths\"][i],\n",
    "                cache_dir=config[\"cache_dir\"],\n",
    "                use_fast=False,\n",
    "            )\n",
    "\n",
    "        name2config[model_path] = AutoConfig.from_pretrained(\n",
    "            model_path, cache_dir=config[\"cache_dir\"]\n",
    "        )\n",
    "\n",
    "        if config[\"model_types\"][i] == \"RobertaCustomForSequenceClassification\":\n",
    "            name2model[model_path] = lossbuilder.ModelWrapper(\n",
    "                RobertaCustomForSequenceClassification.from_pretrained(\n",
    "                    model_path,\n",
    "                    config=name2config[model_path],\n",
    "                    cache_dir=config[\"cache_dir\"],\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            name2model[model_path] = lossbuilder.ModelWrapper(\n",
    "                getattr(transformers, config[\"model_types\"][i]).from_pretrained(\n",
    "                    model_path,\n",
    "                    config=name2config[model_path],\n",
    "                    cache_dir=config[\"cache_dir\"],\n",
    "                )\n",
    "            )\n",
    "        name2model[model_path].eval()\n",
    "        name2model[model_path].to(config['device'])\n",
    "\n",
    "    input_embeds = name2model[model_path].get_input_embeddings()\n",
    "    if isinstance(input_embeds, torch.nn.Sequential):\n",
    "        input_embeds = input_embeds[0]\n",
    "    embed_luts.append(input_embeds)\n",
    "\n",
    "    if config[\"target_type\"] == \"embeds\":\n",
    "        embed_luts[-1].requires_grad = False\n",
    "\n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "mlm = None if config[\"method\"] == \"mlm-beamsearch-v2\" else AutoModelForMaskedLM.from_pretrained(\"roberta-base\").to(config['device'])\n",
    "\n",
    "lossfns = []\n",
    "for i, loss in enumerate(config[\"losses\"]):\n",
    "    lossfns.append(\n",
    "        lossbuilder.build_loss(\n",
    "            loss,\n",
    "            name2model[config[\"model_paths\"][i]],\n",
    "            name2tokenizer[config[\"tokenizer_paths\"][i]],\n",
    "            build_loss_args,\n",
    "        )\n",
    "    )\n",
    "    lossfns[i].tokenizer.add_special_tokens({\"mask_token\": mlm_tokenizer.mask_token})\n",
    "    loss2tokenizer[loss] = lossfns[i].tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "# Max tokens per span --> why 3? 90% percentile of \n",
    "max_tokens_per_span = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly<mask><mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask><mask> activities.<mask> \"broomstick<mask><mask> saga captivated the nation and left many stunned by the audacity of his crimes.\n",
      "test_sent with <mask> merged: holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.\n",
      "test_sent span lengths: [2, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Set up current example\n",
    "test_sent = all_masked_sentences[0]\n",
    "print(test_sent)\n",
    "source_text = intermediate_outputs_eda['prompt'][0]\n",
    "\n",
    "# merge masks\n",
    "test_sent_merged = re.sub(r\"(<mask>)+\", \"<mask>\", test_sent)\n",
    "print(f\"test_sent with <mask> merged: {test_sent_merged}\")\n",
    "# test sent span lengths\n",
    "test_sent_span_lengths = span_lengths_es[0]\n",
    "print(f\"test_sent span lengths: {test_sent_span_lengths}\")\n",
    "\n",
    "# Max number of mask tokens to replace each span\n",
    "max_mask_cnt_per_span = [max(x, max_tokens_per_span) for x in test_sent_span_lengths]\n",
    "\n",
    "# Get the span information of merged masks in the test sentence\n",
    "mask_spans = [x.span() for x in re.finditer('<mask>',test_sent_merged)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8699331283569336\n"
     ]
    }
   ],
   "source": [
    "# 비교군 : 기존 로직대로 생성했을 떄 \n",
    "# %%timeit\n",
    "start_time = time.time()\n",
    "masked_text = test_sent\n",
    "inputs = mlm_tokenizer(\n",
    "        masked_text, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    )\n",
    "inputs = inputs.to(config['device']) \n",
    "masked_sequence=inputs['input_ids']\n",
    "\n",
    "\n",
    "## make predictions for the masked indices\n",
    "with torch.no_grad():\n",
    "    logits = mlm(**inputs).logits\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "\n",
    "indices_in_mlm_tokens = (\n",
    "    inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    ").nonzero(as_tuple=True)\n",
    "\n",
    "## get top k tokens for each index\n",
    "predicted_token_ids = torch.topk(\n",
    "    logits[indices_in_mlm_tokens[0], indices_in_mlm_tokens[1], :],\n",
    "    k=config['k_per_location'],\n",
    "    dim=-1,\n",
    ")\n",
    "\n",
    "hypotheses_comparison = get_beam_hypotheses_v0(source_text, \n",
    "        masked_sequence, \n",
    "        indices_in_mlm_tokens,\n",
    "        predicted_token_ids.indices,\n",
    "        mlm_tokenizer, \n",
    "        lossfns,\n",
    "        config)\n",
    "\n",
    "final_hypotheses_comparison, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                    hypotheses_comparison,\n",
    "                                                                                                    lossfns,\n",
    "                                                                                                    config,\n",
    "                                                                                                    batch_size=32)\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his alleged criminal activities. The \"broomstick robber\" saga captivated the nation and left many stunned by the audacity of his crimes.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hypotheses_comparison[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 µs ± 5.35 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "# from itertools import product\n",
    "\n",
    "# # Create a generator for all combinations of mask counts at each span\n",
    "# mask_combinations = product(*(range(max_mask_cnt + 1) for max_mask_cnt in max_mask_cnt_per_span))\n",
    "\n",
    "# hypotheses = []\n",
    "# for mask_counts in mask_combinations:\n",
    "#     current_hyp = test_sent_merged[:mask_spans[0][0]]\n",
    "#     for i, count in enumerate(mask_counts):\n",
    "#         if i < len(mask_spans) - 1:\n",
    "#             # Add the selected number of masks and the segment of the sentence between spans\n",
    "#             current_hyp += \"<mask>\" * count + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]]\n",
    "#         else:\n",
    "#             # For the last span, add remaining part of the string\n",
    "#             current_hyp += \"<mask>\" * count + test_sent_merged[mask_spans[i][1]:]\n",
    "    \n",
    "#     hypotheses.append(current_hyp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569.0404033660889\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "queue = deque()\n",
    "queue.append(test_sent_merged[:mask_spans[0][0]])\n",
    "\n",
    "for i in range(len(mask_spans)):\n",
    "    curr_queue_size = len(queue)\n",
    "    for _ in range(curr_queue_size):        \n",
    "        base_hyp = queue.popleft()\n",
    "        for j in range(max_mask_cnt_per_span[i] + 1):\n",
    "            if i < len(mask_spans)-1:\n",
    "                curr_hyp = base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]]\n",
    "            else:\n",
    "                curr_hyp = base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:]\n",
    "            queue.append(curr_hyp)\n",
    "\n",
    "# hypotheses = list(queue)\n",
    "hypotheses = [[queue.popleft()]]  # first hypothesis has no <mask>\n",
    "while queue:\n",
    "    \n",
    "    masked_text = queue.popleft()\n",
    "\n",
    "    inputs = mlm_tokenizer(\n",
    "        masked_text, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    )\n",
    "    inputs = inputs.to(config['device']) \n",
    "    masked_sequence=inputs['input_ids']\n",
    "\n",
    "\n",
    "    ## make predictions for the masked indices\n",
    "    with torch.no_grad():\n",
    "        logits = mlm(**inputs).logits\n",
    "\n",
    "    special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "    logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "\n",
    "    indices_in_mlm_tokens = (\n",
    "        inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    "    ).nonzero(as_tuple=True)\n",
    "\n",
    "    ## get top k tokens for each index\n",
    "    predicted_token_ids = torch.topk(\n",
    "        logits[indices_in_mlm_tokens[0], indices_in_mlm_tokens[1], :],\n",
    "        k=config['k_per_location'],\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    hypotheses.extend(get_beam_hypotheses_v0(source_text, \n",
    "            masked_sequence, \n",
    "            indices_in_mlm_tokens,\n",
    "            predicted_token_ids.indices,\n",
    "            mlm_tokenizer, \n",
    "            lossfns,\n",
    "            config))\n",
    "    \n",
    "hypotheses_all = [sum(hypotheses, [])]\n",
    "\n",
    "final_hypotheses_, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                    hypotheses_all,\n",
    "                                                                                                    lossfns,\n",
    "                                                                                                    config,\n",
    "                                                                                                    batch_size=32)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.484006722768148"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "569.0404033660889/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly<mask><mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask><mask> activities.<mask> \"broomstick<mask><mask> saga captivated the nation and left many stunned by the audacity of his crimes.\n",
      "holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly intimidated staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his activities. The \"broomstick robber\" saga captivated the nation and left many stunned by the audacity of his crimes.\n"
     ]
    }
   ],
   "source": [
    "print(test_sent)\n",
    "print(final_hypotheses_[0])\n",
    "## 삭제 : for his<mask><mask> activities. -> for his activities.\n",
    "## variable replace : The man reportedly<mask><mask> staff (2 masks) -> The man reportedly intimidated staff (1 token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly intimidated staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his activities. The \"broomstick robber\" saga captivated the nation and left many stunned by the audacity of his crimes.\n",
      "holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his alleged criminal activities. The \"broomstick robber\" saga captivated the nation and left many stunned by the audacity of his crimes.\n"
     ]
    }
   ],
   "source": [
    "# [verb] staff  v.s. [verb] the staff : [verb] staff without \"the\" is correct. (gpt4o)\n",
    "# In this context, \"staff\" is treated as a collective noun, and using it without \"the\" is appropriate. Adding \"the\" would imply a specific group of staff members, but since the statement refers to the general group of staff and customers present at the supermarkets, omitting \"the\" is more natural and grammatically sound.\n",
    "# The use of \"the\" is not incorrect, but it's less common and can make the sentence sound slightly more formal or specific than necessary in this context.\n",
    "print(final_hypotheses_[0])\n",
    "print(final_hypotheses_comparison[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method 1-2. replace with none to multiple masks\n",
    "#### moving from one mask location to another ...\n",
    "#### 1) make all potential masking schemes (+1 for deletion case): max_mask + 1\n",
    "#### 2) generate beam-sized candidates for each masking scheme : 1 + (beam_size) * (max_masks)\n",
    "#### 3) reranking over all candidates \n",
    "#### 4) select beam-sized candidates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, hypotheses_data:List[str]):\n",
    "        self.hypotheses_data = hypotheses_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hypotheses_data)\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        return self.hypotheses_data[idx]\n",
    "    \n",
    "    def __getitems__(self, idx:List[int]):\n",
    "        return [self.hypotheses_data[j] for j in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A convicted German criminal known as the “broomstick robber” has been charged with blackmail for allegedly'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 2 할 떄, 뒷 문장도 다 넣어서 생성하게 할까? -> 일단 그렇게 하는게 기존과 같음 \n",
    "\n",
    "from collections import deque\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "\n",
    "queue = deque()\n",
    "queue.append(test_sent_merged[:mask_spans[0][0]])\n",
    "for i in range(len(mask_spans)):\n",
    "    # print('-'*20)\n",
    "    curr_queue_size = len(queue)\n",
    "    hypotheses=[]\n",
    "    # print(f'working on the {i}th span. current queue size: {curr_queue_size}')\n",
    "    for _ in range(curr_queue_size):   \n",
    "        base_hyp = queue.popleft()\n",
    "        # print(f'* base_hyp: {base_hyp}')\n",
    "        hypotheses.append([base_hyp]) # deletion case\n",
    "        \n",
    "        for j in range(1, max_mask_cnt_per_span[i] + 1):\n",
    "        # for j in range(1, 3):\n",
    "            # print(f\"   * appending {j} masks\")\n",
    "            # Set up sentence for MLM inference (note we append variable number mask and then the rest of the sentence where the other spans are masked)\n",
    "            curr_full_text_hyp = base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:]\n",
    "            # print(f\"-- curr_masked_text: {curr_full_text_hyp}\")\n",
    "            \n",
    "            # Tokenize & conduct MLM inference\n",
    "            inputs = mlm_tokenizer(\n",
    "                curr_full_text_hyp, return_tensors=\"pt\", padding=True, truncation=True\n",
    "            )\n",
    "            inputs = inputs.to(config['device']) \n",
    "            masked_sequence=inputs['input_ids']\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = mlm(**inputs).logits\n",
    "\n",
    "            # Choose top k among non-special tokens\n",
    "            logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "            indices_in_mlm_tokens = (\n",
    "                inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    "            ).nonzero(as_tuple=True) # indices_in_mlm_tokens is a tuple (A, B) where A indicates row ids, B indicates column ids\n",
    "            # print(f\"indices_in_mlm_tokens: {indices_in_mlm_tokens}\")\n",
    "            \n",
    "            # Since base_hyp has no mask, if we take indexes for the first j masks, we have all indexes that we want to make guesses for this time.\n",
    "            indices_in_mlm_tokens_0 = indices_in_mlm_tokens[0][:j]\n",
    "            indices_in_mlm_tokens_1 = indices_in_mlm_tokens[1][:j]\n",
    "            # print(f\"-- location of masks: {indices_in_mlm_tokens_1}\")\n",
    "            \n",
    "            # Get top k tokens for the j masks\n",
    "            predicted_token_ids = torch.topk(\n",
    "                logits[indices_in_mlm_tokens_0, indices_in_mlm_tokens_1, :],\n",
    "                k=config['k_per_location'],\n",
    "                dim=-1,\n",
    "            )            \n",
    "            # print(f\"-- top k tokens for each mask: {predicted_token_ids.indices}\")\n",
    "            \n",
    "            # When we do beam search, we only beam search up until the j masks.\n",
    "            masked_sequence = masked_sequence[:, :indices_in_mlm_tokens_1[-1]+1]\n",
    "            # print(f\"-- masked sequence we use for beam search: {masked_sequence}\")\n",
    "            # print(f\"masked_sequence: {masked_sequence}\")\n",
    "            \n",
    "            partial_hypotheses = get_beam_hypotheses_v0(source_text, \n",
    "                                masked_sequence, \n",
    "                                (indices_in_mlm_tokens_0, indices_in_mlm_tokens_1),\n",
    "                                predicted_token_ids.indices,\n",
    "                                mlm_tokenizer, \n",
    "                                lossfns,\n",
    "                                config)\n",
    "            # print(f\"-- result of beam search using the partial masked sequence: {partial_hypotheses}\")\n",
    "            hypotheses.extend(partial_hypotheses)\n",
    "\n",
    "    # print(\"   * all mask length explored\")\n",
    "    hypotheses_all = sum(hypotheses, [])\n",
    "    # print(f\"-- # of hypotheses for current ({i}th) span: {len(hypotheses_all)}\")\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span: {hypotheses_all}\")\n",
    "    \n",
    "    # Append snippet of text after current span and before next span before scoring\n",
    "    if i < len(mask_spans) -1 :\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "    else:\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span for scoring: {hypotheses_all}\") \n",
    "    \n",
    "    # Scoring the hypotheses and select top beam hypotheses\n",
    "    loss_weights = config['loss_weights']\n",
    "    curr_loss = torch.zeros(len(hypotheses_all)).to(config['device'])\n",
    "    data_loader = DataLoader(CustomDataset(hypotheses_all),batch_size=batch_size)\n",
    "\n",
    "    for lossid, lossname in enumerate(config[\"losses\"]):\n",
    "        lossvalues=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                lossvalue = lossfns[lossid].compute_gold_loss(\n",
    "                    source_text, batch,\n",
    "                    label_id=config['target_label_ids'][lossid],\n",
    "                )\n",
    "                lossvalues.append(lossvalue)\n",
    "                torch.cuda.empty_cache()\n",
    "        lossvalue = torch.cat(lossvalues,dim=0)\n",
    "        curr_loss += loss_weights[lossid] * lossvalue\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    top_beams = torch.topk(curr_loss, k=config['beam_size'], dim=-1, largest=False).indices\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses' indices: {top_beams}\")\n",
    "\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses for current ({i}th) span: {[hypotheses_all[ix] for ix in top_beams]}\")\n",
    "    \n",
    "    # print(f\"-- queue before extending current step's selected hypotheses: {queue}\")\n",
    "    queue.extend(hypotheses_all[ix] for ix in top_beams)\n",
    "    del hypotheses_all\n",
    "    # print(f\"-- queue after extending current step's selected hypotheses: {queue}\")\n",
    "    \n",
    "final_hypotheses, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                    [list(queue)],\n",
    "                                                                                                    lossfns,\n",
    "                                                                                                    config,\n",
    "                                                                                                    batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 추가 단축 --> 2초 밖에 안줄어서 슬프다..ㅎㅎ / 그래도 여기서 stop. 다른 test case에 대해서도 해보기. \n",
    "## step 2 할 떄, 뒷 문장도 다 넣어서 생성하게 할까? -> 일단 그렇게 하는게 기존과 같음 \n",
    "\n",
    "from collections import deque\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "\n",
    "queue = deque()\n",
    "queue.append(test_sent_merged[:mask_spans[0][0]])\n",
    "for i in range(len(mask_spans)):\n",
    "    # print('-'*20)\n",
    "    curr_queue_size = len(queue)\n",
    "    hypotheses=[list(queue)] # deletion case\n",
    "    # print(f'working on the {i}th span. current queue size: {curr_queue_size}')\n",
    "    \n",
    "    for j in range(1, max_mask_cnt_per_span[i] + 1):\n",
    "    # for j in range(1, 3):\n",
    "        # print(f\"   * appending {j} masks\")\n",
    "        # Set up sentence for MLM inference (note we append variable number mask and then the rest of the sentence where the other spans are masked)\n",
    "        curr_full_text_hyp = [base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:] for base_hyp in queue]\n",
    "        # print(f\"-- curr_masked_text: {curr_full_text_hyp}\")\n",
    "        \n",
    "        # Tokenize & conduct MLM inference\n",
    "        inputs = mlm_tokenizer(\n",
    "            curr_full_text_hyp, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "        inputs = inputs.to(config['device']) \n",
    "        masked_sequence=inputs['input_ids']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = mlm(**inputs).logits\n",
    "\n",
    "        # Choose top k among non-special tokens\n",
    "        logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "        indices_in_mlm_tokens = (\n",
    "            inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    "        ).nonzero(as_tuple=False) # if as_tuple=False, returns a tensor where column 1 indicates row indices, column 2 indicates column indices e.g. torch.Tensor([[0, 19],[0, 20], [0,38]])\n",
    "        # print(f\"-- location of masks including masks in the future spans: {indices_in_mlm_tokens}\")\n",
    "        \n",
    "        # For each hypothesis in curr_full_text_hyp, first j mask locations are relevant\n",
    "        indices_in_mlm_tokens = torch.cat([x[:j] for x in torch.chunk(indices_in_mlm_tokens, curr_queue_size)],dim=0)\n",
    "        indices_in_mlm_tokens_0 = indices_in_mlm_tokens[:,0]\n",
    "        indices_in_mlm_tokens_1 = indices_in_mlm_tokens[:,1]\n",
    "        # print(f\"-- location of masks (row indices): {indices_in_mlm_tokens_0}\")\n",
    "        # print(f\"-- location of masks (col indices): {indices_in_mlm_tokens_1}\")\n",
    "        \n",
    "        # Get top k tokens for the j masks\n",
    "        predicted_token_ids = torch.topk(\n",
    "            logits[indices_in_mlm_tokens_0, indices_in_mlm_tokens_1, :],\n",
    "            k=config['k_per_location'],\n",
    "            dim=-1,\n",
    "        )            \n",
    "        # print(f\"-- top k tokens for each mask in each hypothesis: {predicted_token_ids.indices}\")\n",
    "        \n",
    "        # After beam search, we want to get beam # of partial hypotheses.\n",
    "        # The partial hypotheses are preferably up until before the next mask span. As in below.         \n",
    "        # # Append snippet of text after current span and before next span before scoring\n",
    "        # if i < len(mask_spans) -1 :\n",
    "        #     hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "        # else:\n",
    "        #     hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "        # Right now we have masked_sequence which is a padded tensor of hypotheses that cover the entire sentence. parts that are at and after future mask spans are also concatenated.\n",
    "        # During beam search, the algorithm only considers context before a mask. So it doesn't matter if we add superflous parts. \n",
    "        # But it's just that when sentences are returned from the beam search, special tokens are eliminated so it's hard to know where is the next mask span.\n",
    "        # A workaround would be to cut the mask_sequence so that sentences only cover until the next mask span. In this case an issue is that each sentence would be of different length.\n",
    "        # We can work around by padding. \n",
    "        # print(torch.split(masked_sequence, 1, dim=0))\n",
    "\n",
    "        # When we do beam search, we only beam search up until the j masks.\n",
    "        # print(f\"-- shape of masked_sequence before slicing and padding: {masked_sequence.shape}\")\n",
    "        # print(f\"-- masked_sequence before slicing and padding: {masked_sequence}\")\n",
    "        \n",
    "        # for ix in range(masked_sequence.shape[0]):\n",
    "            # print(f\"indices_in_mlm_tokens_1[j*(ix+1)-1]+1: {indices_in_mlm_tokens_1[j*(ix+1)-1]+1}\")\n",
    "            # print(f\"x[:,:indices_in_mlm_tokens_1[j*(ix+1)-1]+1]: {masked_sequence[ix,:indices_in_mlm_tokens_1[j*(ix+1)-1]+1]}\")\n",
    "        \n",
    "        masked_sequence = [masked_sequence[ix, :indices_in_mlm_tokens_1[j*(ix+1)-1]+1] for ix in range(masked_sequence.shape[0])]\n",
    "        masked_sequence = torch.nn.utils.rnn.pad_sequence(masked_sequence, batch_first=True, padding_value=mlm_tokenizer.pad_token_id)\n",
    "        # masked_sequence = masked_sequence[:, :indices_in_mlm_tokens_1[-1]+1]\n",
    "        # print(f\"-- masked sequence we use for beam search: {masked_sequence}\")\n",
    "        # print(f\"-- shape of masked_sequence after slicing and padding: {masked_sequence.shape}\")\n",
    "        # print(f\"-- masked_sequence after slicing and padding: {masked_sequence}\")\n",
    "        \n",
    "        partial_hypotheses = get_beam_hypotheses_v0(source_text, \n",
    "                            masked_sequence, \n",
    "                            (indices_in_mlm_tokens_0, indices_in_mlm_tokens_1),\n",
    "                            predicted_token_ids.indices,\n",
    "                            mlm_tokenizer, \n",
    "                            lossfns,\n",
    "                            config)\n",
    "        \n",
    "        # print(f\"-- result of beam search using the partial masked sequence: {partial_hypotheses}\")\n",
    "        # print(f\"-- num of returned partial hypotheses after beam search: {len(partial_hypotheses)}\")\n",
    "        # print(f\"-- returned partial hypotheses after beam search: {partial_hypotheses}\")\n",
    "        \n",
    "        partial_hypotheses = sum(partial_hypotheses, [])\n",
    "        \n",
    "        # print(f\"-- num of partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {len(partial_hypotheses)}\")\n",
    "        # print(f\"-- partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {partial_hypotheses}\")\n",
    "        # Extend the partial hypotheses to hypotheses pool for current mask span\n",
    "        hypotheses.append(partial_hypotheses)\n",
    "\n",
    "    # print(\"   * all mask length explored\")\n",
    "    hypotheses_all = sum(hypotheses, [])\n",
    "    # print(f\"-- # of hypotheses for current ({i}th) span: {len(hypotheses_all)}\")\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span: {hypotheses_all}\")\n",
    "    \n",
    "    # # Append snippet of text after current span and before next span before scoring\n",
    "    if i < len(mask_spans) -1 :\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "    else:\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span for scoring: {hypotheses_all}\") \n",
    "    \n",
    "    # Scoring the hypotheses and select top beam hypotheses\n",
    "    loss_weights = config['loss_weights']\n",
    "    curr_loss = torch.zeros(len(hypotheses_all)).to(config['device'])\n",
    "    data_loader = DataLoader(CustomDataset(hypotheses_all),batch_size=batch_size)\n",
    "\n",
    "    for lossid, lossname in enumerate(config[\"losses\"]):\n",
    "        lossvalues=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                lossvalue = lossfns[lossid].compute_gold_loss(\n",
    "                    source_text, batch,\n",
    "                    label_id=config['target_label_ids'][lossid],\n",
    "                )\n",
    "                lossvalues.append(lossvalue)\n",
    "                torch.cuda.empty_cache()\n",
    "        lossvalue = torch.cat(lossvalues,dim=0)\n",
    "        curr_loss += loss_weights[lossid] * lossvalue\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    top_beams = torch.topk(curr_loss, k=config['beam_size'], dim=-1, largest=False).indices\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses' indices: {top_beams}\")\n",
    "\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses for current ({i}th) span: {[hypotheses_all[ix] for ix in top_beams]}\")\n",
    "    \n",
    "    # print(f\"-- queue before extending current step's selected hypotheses: {queue}\")\n",
    "    queue = deque([hypotheses_all[ix] for ix in top_beams])\n",
    "    del hypotheses_all\n",
    "    # print(f\"-- queue after extending current step's selected hypotheses: {queue}\")\n",
    "    \n",
    "final_hypotheses, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                    [list(queue)],\n",
    "                                                                                                    lossfns,\n",
    "                                                                                                    config,\n",
    "                                                                                                    batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[158, 159, 160, 161, 162, 163, 164, 165, 166]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ix for ix, x in enumerate(all_matching_prompts) if \"Other than that, it\\u2019s a bunch of \\u201cwho gives a\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "<mask><mask><mask><mask><mask><mask><mask><mask> Life can get busy and overwhelming, making it easy to brush off things that don't seem essential. Sometimes, we might find ourselves questioning the importance of certain matters or events in the grand scheme of things. Prioritizing and focusing on what truly matters to us can help us navigate through such moments of doubt or indifference. It's essential to remember that it's okay to let go of things that don't bring value or joy to our lives.\n",
      "Other than that, it’s a bunch of “who gives a\n",
      "crap anyway?” thoughts. Life can get busy and overwhelming, making it easy to brush off things that don't seem essential. Sometimes, we might find ourselves questioning the importance of certain matters or events in the grand scheme of things. Prioritizing and focusing on what truly matters to us can help us navigate through such moments of doubt or indifference. It's essential to remember that it's okay to let go of things that don't bring value or joy to our lives.\n",
      "test_sent with <mask> merged: <mask> Life can get busy and overwhelming, making it easy to brush off things that don't seem essential. Sometimes, we might find ourselves questioning the importance of certain matters or events in the grand scheme of things. Prioritizing and focusing on what truly matters to us can help us navigate through such moments of doubt or indifference. It's essential to remember that it's okay to let go of things that don't bring value or joy to our lives.\n",
      "test_sent span lengths: [8]\n"
     ]
    }
   ],
   "source": [
    "tmp = [str(x) for x in span_lengths_es]\n",
    "test_case_idx = tmp.index('[3, 4, 2, 1]')\n",
    "test_case_idx = 164\n",
    "print(test_case_idx)\n",
    "# Set up current example\n",
    "test_sent = all_masked_sentences[test_case_idx]\n",
    "print(test_sent)\n",
    "source_text = all_matching_prompts[test_case_idx]\n",
    "print(source_text)\n",
    "original_text = all_original_sentences[test_case_idx]\n",
    "print(original_text)\n",
    "\n",
    "# merge masks\n",
    "test_sent_merged = re.sub(r\"(<mask>)+\", \"<mask>\", test_sent)\n",
    "print(f\"test_sent with <mask> merged: {test_sent_merged}\")\n",
    "# test sent span lengths\n",
    "test_sent_span_lengths = span_lengths_es[test_case_idx]\n",
    "print(f\"test_sent span lengths: {test_sent_span_lengths}\")\n",
    "\n",
    "# Max number of mask tokens to replace each span\n",
    "max_mask_cnt_per_span = [max(x, max_tokens_per_span) for x in test_sent_span_lengths]\n",
    "\n",
    "# Get the span information of merged masks in the test sentence\n",
    "mask_spans = [x.span() for x in re.finditer('<mask>',test_sent_merged)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.18488359451294\n"
     ]
    }
   ],
   "source": [
    "# 시간 추가 단축 --> 2초 밖에 안줄어서 슬프다..ㅎㅎ / 그래도 여기서 stop. 다른 test case에 대해서도 해보기. \n",
    "batch_size=64\n",
    "start_time = time.time()\n",
    "from collections import deque\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "\n",
    "queue = deque()\n",
    "queue.append(test_sent_merged[:mask_spans[0][0]])\n",
    "for i in range(len(mask_spans)):\n",
    "    # print('-'*20)\n",
    "    curr_queue_size = len(queue)\n",
    "    hypotheses=[list(queue)] # deletion case\n",
    "    # print(f'working on the {i}th span. current queue size: {curr_queue_size}')\n",
    "    \n",
    "    for j in range(1, max_mask_cnt_per_span[i] + 1):\n",
    "    # for j in range(1, 3):\n",
    "        # print(f\"   * appending {j} masks\")\n",
    "        # Set up sentence for MLM inference (note we append variable number mask and then the rest of the sentence where the other spans are masked)\n",
    "        curr_full_text_hyp = [base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:] for base_hyp in queue]\n",
    "        # print(f\"-- curr_masked_text: {curr_full_text_hyp}\")\n",
    "        \n",
    "        # Tokenize & conduct MLM inference\n",
    "        inputs = mlm_tokenizer(\n",
    "            curr_full_text_hyp, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "        inputs = inputs.to(config['device']) \n",
    "        masked_sequence=inputs['input_ids']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = mlm(**inputs).logits\n",
    "\n",
    "        # Choose top k among non-special tokens\n",
    "        logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "        indices_in_mlm_tokens = (\n",
    "            inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    "        ).nonzero(as_tuple=False) # if as_tuple=False, returns a tensor where column 1 indicates row indices, column 2 indicates column indices e.g. torch.Tensor([[0, 19],[0, 20], [0,38]])\n",
    "        # print(f\"-- location of masks including masks in the future spans: {indices_in_mlm_tokens}\")\n",
    "        \n",
    "        # For each hypothesis in curr_full_text_hyp, first j mask locations are relevant\n",
    "        indices_in_mlm_tokens = torch.cat([x[:j] for x in torch.chunk(indices_in_mlm_tokens, curr_queue_size)],dim=0)\n",
    "        indices_in_mlm_tokens_0 = indices_in_mlm_tokens[:,0]\n",
    "        indices_in_mlm_tokens_1 = indices_in_mlm_tokens[:,1]\n",
    "        # print(f\"-- location of masks (row indices): {indices_in_mlm_tokens_0}\")\n",
    "        # print(f\"-- location of masks (col indices): {indices_in_mlm_tokens_1}\")\n",
    "        \n",
    "        # Get top k tokens for the j masks\n",
    "        predicted_token_ids = torch.topk(\n",
    "            logits[indices_in_mlm_tokens_0, indices_in_mlm_tokens_1, :],\n",
    "            k=config['k_per_location'],\n",
    "            dim=-1,\n",
    "        )            \n",
    "        # print(f\"-- top k tokens for each mask in each hypothesis: {predicted_token_ids.indices}\")\n",
    "        \n",
    "        # After beam search, we want to get beam # of partial hypotheses.\n",
    "        # The partial hypotheses are preferably up until before the next mask span. As in below.         \n",
    "        # # Append snippet of text after current span and before next span before scoring\n",
    "        # if i < len(mask_spans) -1 :\n",
    "        #     hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "        # else:\n",
    "        #     hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "        # Right now we have masked_sequence which is a padded tensor of hypotheses that cover the entire sentence. parts that are at and after future mask spans are also concatenated.\n",
    "        # During beam search, the algorithm only considers context before a mask. So it doesn't matter if we add superflous parts. \n",
    "        # But it's just that when sentences are returned from the beam search, special tokens are eliminated so it's hard to know where is the next mask span.\n",
    "        # A workaround would be to cut the mask_sequence so that sentences only cover until the next mask span. In this case an issue is that each sentence would be of different length.\n",
    "        # We can work around by padding. \n",
    "        # print(torch.split(masked_sequence, 1, dim=0))\n",
    "\n",
    "        # When we do beam search, we only beam search up until the j masks.\n",
    "        # print(f\"-- shape of masked_sequence before slicing and padding: {masked_sequence.shape}\")\n",
    "        # print(f\"-- masked_sequence before slicing and padding: {masked_sequence}\")\n",
    "        \n",
    "        # for ix in range(masked_sequence.shape[0]):\n",
    "            # print(f\"indices_in_mlm_tokens_1[j*(ix+1)-1]+1: {indices_in_mlm_tokens_1[j*(ix+1)-1]+1}\")\n",
    "            # print(f\"x[:,:indices_in_mlm_tokens_1[j*(ix+1)-1]+1]: {masked_sequence[ix,:indices_in_mlm_tokens_1[j*(ix+1)-1]+1]}\")\n",
    "        \n",
    "        masked_sequence = [masked_sequence[ix, :indices_in_mlm_tokens_1[j*(ix+1)-1]+1] for ix in range(masked_sequence.shape[0])]\n",
    "        masked_sequence = torch.nn.utils.rnn.pad_sequence(masked_sequence, batch_first=True, padding_value=mlm_tokenizer.pad_token_id)\n",
    "        # masked_sequence = masked_sequence[:, :indices_in_mlm_tokens_1[-1]+1]\n",
    "        # print(f\"-- masked sequence we use for beam search: {masked_sequence}\")\n",
    "        # print(f\"-- shape of masked_sequence after slicing and padding: {masked_sequence.shape}\")\n",
    "        # print(f\"-- masked_sequence after slicing and padding: {masked_sequence}\")\n",
    "        \n",
    "        partial_hypotheses = get_beam_hypotheses_v0(source_text, \n",
    "                            masked_sequence, \n",
    "                            (indices_in_mlm_tokens_0, indices_in_mlm_tokens_1),\n",
    "                            predicted_token_ids.indices,\n",
    "                            mlm_tokenizer, \n",
    "                            lossfns,\n",
    "                            config)\n",
    "        \n",
    "        # print(f\"-- result of beam search using the partial masked sequence: {partial_hypotheses}\")\n",
    "        # print(f\"-- num of returned partial hypotheses after beam search: {len(partial_hypotheses)}\")\n",
    "        # print(f\"-- returned partial hypotheses after beam search: {partial_hypotheses}\")\n",
    "        \n",
    "        partial_hypotheses = sum(partial_hypotheses, [])\n",
    "        \n",
    "        # print(f\"-- num of partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {len(partial_hypotheses)}\")\n",
    "        # print(f\"-- partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {partial_hypotheses}\")\n",
    "        # Extend the partial hypotheses to hypotheses pool for current mask span\n",
    "        hypotheses.append(partial_hypotheses)\n",
    "\n",
    "    # print(\"   * all mask length explored\")\n",
    "    hypotheses_all = sum(hypotheses, [])\n",
    "    # print(f\"-- # of hypotheses for current ({i}th) span: {len(hypotheses_all)}\")\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span: {hypotheses_all}\")\n",
    "    \n",
    "    # # Append snippet of text after current span and before next span before scoring\n",
    "    if i < len(mask_spans) -1 :\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "    else:\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span for scoring: {hypotheses_all}\") \n",
    "    \n",
    "    # Scoring the hypotheses and select top beam hypotheses\n",
    "    loss_weights = config['loss_weights']\n",
    "    curr_loss = torch.zeros(len(hypotheses_all)).to(config['device'])\n",
    "    data_loader = DataLoader(CustomDataset(hypotheses_all),batch_size=batch_size)\n",
    "\n",
    "    for lossid, lossname in enumerate(config[\"losses\"]):\n",
    "        lossvalues=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                lossvalue = lossfns[lossid].compute_gold_loss(\n",
    "                    source_text, batch,\n",
    "                    label_id=config['target_label_ids'][lossid],\n",
    "                )\n",
    "                lossvalues.append(lossvalue)\n",
    "                torch.cuda.empty_cache()\n",
    "        lossvalue = torch.cat(lossvalues,dim=0)\n",
    "        curr_loss += loss_weights[lossid] * lossvalue\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    top_beams = torch.topk(curr_loss, k=config['beam_size'], dim=-1, largest=False).indices\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses' indices: {top_beams}\")\n",
    "\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses for current ({i}th) span: {[hypotheses_all[ix] for ix in top_beams]}\")\n",
    "    \n",
    "    # print(f\"-- queue before extending current step's selected hypotheses: {queue}\")\n",
    "    queue = deque([hypotheses_all[ix] for ix in top_beams])\n",
    "    del hypotheses_all\n",
    "    # print(f\"-- queue after extending current step's selected hypotheses: {queue}\")\n",
    "    \n",
    "final_hypotheses, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                    [list(queue)],\n",
    "                                                                                                    lossfns,\n",
    "                                                                                                    config,\n",
    "                                                                                                    batch_size=32)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 91])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 108, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 91, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 92])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 109, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 92, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 93])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 110, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 93, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 94])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 111, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 94, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 95])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 112, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 95, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 96])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 113, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 96, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 97])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 114, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 97, 50265])\n",
      "-- shape of full text hypotheses after being tokenized and converted to input ids: torch.Size([1, 98])\n",
      "-- shape of source text after being tokenized and converted to input ids: torch.Size([1, 17])\n",
      "-- shape of logits before removing source text part: torch.Size([1, 115, 50265])\n",
      "-- shape of logits after removing source text part: torch.Size([1, 98, 50265])\n"
     ]
    }
   ],
   "source": [
    "# candidate generation 할 때 source text도 넣으면 어떨지 해보기 \n",
    "# 시간 추가 단축 --> 2초 밖에 안줄어서 슬프다..ㅎㅎ / 그래도 여기서 stop. 다른 test case에 대해서도 해보기. \n",
    "## step 2 할 떄, 뒷 문장도 다 넣어서 생성하게 할까? -> 일단 그렇게 하는게 기존과 같음 \n",
    "\n",
    "from collections import deque\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "\n",
    "queue = deque()\n",
    "queue.append(test_sent_merged[:mask_spans[0][0]])\n",
    "for i in range(len(mask_spans)):\n",
    "    # print('-'*20)\n",
    "    curr_queue_size = len(queue)\n",
    "    hypotheses=[list(queue)] # deletion case\n",
    "    # print(f'working on the {i}th span. current queue size: {curr_queue_size}')\n",
    "    \n",
    "    for j in range(1, max_mask_cnt_per_span[i] + 1):\n",
    "    # for j in range(1, 3):\n",
    "        # print(f\"   * appending {j} masks\")\n",
    "        # Set up sentence for MLM inference (note we append variable number mask and then the rest of the sentence where the other spans are masked)\n",
    "        curr_full_text_hyp = [base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:] + mlm_tokenizer.eos_token for base_hyp in queue]\n",
    "        # print(f\"-- curr_masked_text: {curr_full_text_hyp}\")\n",
    "        \n",
    "        # Tokenize & conduct MLM inference\n",
    "        inputs = mlm_tokenizer(\n",
    "            curr_full_text_hyp, return_tensors=\"pt\", padding=True, truncation=True, add_special_tokens=False\n",
    "        )\n",
    "        inputs = inputs.to(config['device']) \n",
    "        masked_sequence=inputs['input_ids']\n",
    "        print(f\"-- shape of full text hypotheses after being tokenized and converted to input ids: {inputs['input_ids'].shape}\")\n",
    "        \n",
    "        prompt_enc=mlm_tokenizer(mlm_tokenizer.bos_token + source_text,add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).to(config['device'])\n",
    "        prompt_enc['input_ids']=prompt_enc['input_ids'].expand(curr_queue_size,-1)\n",
    "        prompt_enc['attention_mask']=prompt_enc['attention_mask'].expand(curr_queue_size,-1)\n",
    "        print(f\"-- shape of source text after being tokenized and converted to input ids: {prompt_enc['input_ids'].shape}\")\n",
    "        \n",
    "        input_tokens = torch.cat([prompt_enc.input_ids, inputs.input_ids], dim=1).to(config['device'])\n",
    "        attention_masks = torch.cat([prompt_enc.attention_mask, inputs.attention_mask], dim=1).to(config['device'])\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        #     logits = mlm(**inputs).logits\n",
    "        with torch.no_grad():\n",
    "            logits = mlm(input_ids = input_tokens, \n",
    "                         attention_mask = attention_masks).logits\n",
    "\n",
    "        # Choose top k among non-special tokens\n",
    "        # print(f\"-- shape of logits before removing source text part: {logits.shape}\")\n",
    "        logits = logits[:, prompt_enc.input_ids.shape[1]:]\n",
    "        # print(f\"-- shape of logits after removing source text part: {logits.shape}\")\n",
    "        logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "        indices_in_mlm_tokens = (\n",
    "            inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    "        ).nonzero(as_tuple=False) # if as_tuple=False, returns a tensor where column 1 indicates row indices, column 2 indicates column indices e.g. torch.Tensor([[0, 19],[0, 20], [0,38]])\n",
    "        # print(f\"-- location of masks including masks in the future spans: {indices_in_mlm_tokens}\")\n",
    "        \n",
    "        # For each hypothesis in curr_full_text_hyp, first j mask locations are relevant\n",
    "        indices_in_mlm_tokens = torch.cat([x[:j] for x in torch.chunk(indices_in_mlm_tokens, curr_queue_size)],dim=0)\n",
    "        indices_in_mlm_tokens_0 = indices_in_mlm_tokens[:,0]\n",
    "        indices_in_mlm_tokens_1 = indices_in_mlm_tokens[:,1]\n",
    "        # print(f\"-- location of masks (row indices): {indices_in_mlm_tokens_0}\")\n",
    "        # print(f\"-- location of masks (col indices): {indices_in_mlm_tokens_1}\")\n",
    "        \n",
    "        \n",
    "        # Get top k tokens for the j masks\n",
    "        predicted_token_ids = torch.topk(\n",
    "            logits[indices_in_mlm_tokens_0, indices_in_mlm_tokens_1, :],\n",
    "            k=config['k_per_location'],\n",
    "            dim=-1,\n",
    "        )            \n",
    "        # print(f\"-- top k tokens for each mask in each hypothesis: {predicted_token_ids.indices}\")\n",
    "        \n",
    "        # After beam search, we want to get beam # of partial hypotheses.\n",
    "        # The partial hypotheses are preferably up until before the next mask span. As in below.         \n",
    "        # # Append snippet of text after current span and before next span before scoring\n",
    "        # if i < len(mask_spans) -1 :\n",
    "        #     hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "        # else:\n",
    "        #     hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "        # Right now we have masked_sequence which is a padded tensor of hypotheses that cover the entire sentence. parts that are at and after future mask spans are also concatenated.\n",
    "        # During beam search, the algorithm only considers context before a mask. So it doesn't matter if we add superflous parts. \n",
    "        # But it's just that when sentences are returned from the beam search, special tokens are eliminated so it's hard to know where is the next mask span.\n",
    "        # A workaround would be to cut the mask_sequence so that sentences only cover until the next mask span. In this case an issue is that each sentence would be of different length.\n",
    "        # We can work around by padding. \n",
    "        # print(torch.split(masked_sequence, 1, dim=0))\n",
    "\n",
    "        # When we do beam search, we only beam search up until the j masks.\n",
    "        # print(f\"-- shape of masked_sequence before slicing and padding: {masked_sequence.shape}\")\n",
    "        # print(f\"-- masked_sequence before slicing and padding: {masked_sequence}\")\n",
    "        \n",
    "        # for ix in range(masked_sequence.shape[0]):\n",
    "            # print(f\"indices_in_mlm_tokens_1[j*(ix+1)-1]+1: {indices_in_mlm_tokens_1[j*(ix+1)-1]+1}\")\n",
    "            # print(f\"x[:,:indices_in_mlm_tokens_1[j*(ix+1)-1]+1]: {masked_sequence[ix,:indices_in_mlm_tokens_1[j*(ix+1)-1]+1]}\")\n",
    "        \n",
    "        masked_sequence = [masked_sequence[ix, :indices_in_mlm_tokens_1[j*(ix+1)-1]+1] for ix in range(masked_sequence.shape[0])]\n",
    "        masked_sequence = torch.nn.utils.rnn.pad_sequence(masked_sequence, batch_first=True, padding_value=mlm_tokenizer.pad_token_id)\n",
    "        # masked_sequence = masked_sequence[:, :indices_in_mlm_tokens_1[-1]+1]\n",
    "        # print(f\"-- masked sequence we use for beam search: {masked_sequence}\")\n",
    "        # print(f\"-- shape of masked_sequence after slicing and padding: {masked_sequence.shape}\")\n",
    "        # print(f\"-- masked_sequence after slicing and padding: {masked_sequence}\")\n",
    "        \n",
    "        partial_hypotheses = get_beam_hypotheses_v0(source_text, \n",
    "                            masked_sequence, \n",
    "                            (indices_in_mlm_tokens_0, indices_in_mlm_tokens_1),\n",
    "                            predicted_token_ids.indices,\n",
    "                            mlm_tokenizer, \n",
    "                            lossfns,\n",
    "                            config)\n",
    "        \n",
    "        # print(f\"-- result of beam search using the partial masked sequence: {partial_hypotheses}\")\n",
    "        # print(f\"-- num of returned partial hypotheses after beam search: {len(partial_hypotheses)}\")\n",
    "        # print(f\"-- returned partial hypotheses after beam search: {partial_hypotheses}\")\n",
    "        \n",
    "        partial_hypotheses = sum(partial_hypotheses, [])\n",
    "        \n",
    "        # print(f\"-- num of partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {len(partial_hypotheses)}\")\n",
    "        # print(f\"-- partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {partial_hypotheses}\")\n",
    "        # Extend the partial hypotheses to hypotheses pool for current mask span\n",
    "        hypotheses.append(partial_hypotheses)\n",
    "\n",
    "    # print(\"   * all mask length explored\")\n",
    "    hypotheses_all = sum(hypotheses, [])\n",
    "    # print(f\"-- # of hypotheses for current ({i}th) span: {len(hypotheses_all)}\")\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span: {hypotheses_all}\")\n",
    "    \n",
    "    # # Append snippet of text after current span and before next span before scoring\n",
    "    if i < len(mask_spans) -1 :\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "    else:\n",
    "        hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "    # print(f\"-- entire list of hypotheses for current ({i}th) span for scoring: {hypotheses_all}\") \n",
    "    \n",
    "    # Scoring the hypotheses and select top beam hypotheses\n",
    "    loss_weights = config['loss_weights']\n",
    "    curr_loss = torch.zeros(len(hypotheses_all)).to(config['device'])\n",
    "    data_loader = DataLoader(CustomDataset(hypotheses_all),batch_size=batch_size)\n",
    "\n",
    "    for lossid, lossname in enumerate(config[\"losses\"]):\n",
    "        lossvalues=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                lossvalue = lossfns[lossid].compute_gold_loss(\n",
    "                    source_text, batch,\n",
    "                    label_id=config['target_label_ids'][lossid],\n",
    "                )\n",
    "                lossvalues.append(lossvalue)\n",
    "                torch.cuda.empty_cache()\n",
    "        lossvalue = torch.cat(lossvalues,dim=0)\n",
    "        curr_loss += loss_weights[lossid] * lossvalue\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    top_beams = torch.topk(curr_loss, k=config['beam_size'], dim=-1, largest=False).indices\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses' indices: {top_beams}\")\n",
    "\n",
    "    # print(f\"-- selected {config['beam_size']} hypotheses for current ({i}th) span: {[hypotheses_all[ix] for ix in top_beams]}\")\n",
    "    \n",
    "    # print(f\"-- queue before extending current step's selected hypotheses: {queue}\")\n",
    "    queue = deque([hypotheses_all[ix] for ix in top_beams])\n",
    "    del hypotheses_all\n",
    "    # print(f\"-- queue after extending current step's selected hypotheses: {queue}\")\n",
    "    \n",
    "final_hypotheses, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                    [list(queue)],\n",
    "                                                                                                    lossfns,\n",
    "                                                                                                    config,\n",
    "                                                                                                    batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Other than that, it’s a bunch of “who gives a… Life can get busy and overwhelming, making it easy to brush off things that don't seem essential. Sometimes, we might find ourselves questioning the importance of certain matters or events in the grand scheme of things. Prioritizing and focusing on what truly matters to us can help us navigate through such moments of doubt or indifference. It's essential to remember that it's okay to let go of things that don't bring value or joy to our lives.\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text + final_hypotheses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([20.516], device='cuda:0'),\n",
       " tensor([True], device='cuda:0'),\n",
       " tensor([[  204.301,     0.086]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 함수로 패키징하기\n",
    "\n",
    "\n",
    "def analyze_span_lengths_and_count(text):\n",
    "    mask_matches = list(re.finditer('<mask>', text))\n",
    "\n",
    "    mask_info_dict= defaultdict(list)\n",
    "    prev_mask = None\n",
    "    span_count = 0\n",
    "    curr_span_length = 1\n",
    "    for i, mask in enumerate(mask_matches):\n",
    "        \n",
    "        if i == 0:\n",
    "            mask_info_dict[span_count].append(i)\n",
    "            \n",
    "        else:\n",
    "            if prev_mask.span()[1] == mask.span()[0]:\n",
    "                mask_info_dict[span_count].append(i)\n",
    "                curr_span_length += 1\n",
    "            else:\n",
    "                span_count += 1\n",
    "                mask_info_dict[span_count].append(i)\n",
    "                curr_span_length = 1\n",
    "        prev_mask = mask\n",
    "\n",
    "    span_lengths = []\n",
    "    for span_id, span_len in mask_info_dict.items():\n",
    "        \n",
    "        span_lengths.append(len(span_len))\n",
    "    return mask_info_dict, span_lengths\n",
    "\n",
    "# Prerequisite\n",
    "mask_info_dicts = []\n",
    "span_lengths_es = []\n",
    "for test_sent in all_masked_sentences:\n",
    "    \n",
    "    mask_info_dict, span_lengths = analyze_span_lengths_and_count(test_sent)\n",
    "    mask_info_dicts.append(mask_info_dict)\n",
    "    span_lengths_es.append(span_lengths)\n",
    "\n",
    "# Arguments\n",
    "test_sent = all_masked_sentences[test_case_idx]\n",
    "source_text = all_matching_prompts[test_case_idx]\n",
    "test_sent_span_lengths = span_lengths_es[test_case_idx]\n",
    "\n",
    "\n",
    "def editing_with_delete_variable_replace(source_text:str, test_sent:str, test_sent_span_lengths:List[int], \n",
    "                                         mlm:AutoModelForMaskedLM, mlm_tokenizer:AutoTokenizer, \n",
    "                                         lossfns:List[lossbuilder.BaseLoss], config: dict, batch_size:int=64) -> \\\n",
    "                                             Tuple[List[str],torch.FloatTensor,torch.BoolTensor,torch.FloatTensor]:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    params: \n",
    "        source_text: a prompt text \n",
    "        test_sent: a masked text returned by LocateMachine     \n",
    "        test_sent_span_lengths: a list of span lenghts for each mask span in the test_sent\n",
    "        mlm:\n",
    "        mlm_tokenizer:\n",
    "        lossfns: \n",
    "        config:\n",
    "        batch_size:             \n",
    "    \n",
    "    returns:\n",
    "        hypotheses: list of one best hypothesis(editing result)\n",
    "        best_weighted_loss: torch.FloatTensor of weighted loss for the best hypothesis.\n",
    "        best_allsat: torch.ByteTensor of indicator(1,0) whether the best hypothesis satisfy cutoff (min_epsilons) for constraint energy score.\n",
    "        best_logging_loss: torch.FloatTensor of shape (num samples, 2) of fluency energy score and constraint energy score for each best hypothesis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # merge masks\n",
    "    test_sent_merged = re.sub(r\"(<mask>)+\", \"<mask>\", test_sent)\n",
    "    \n",
    "    # Max number of mask tokens to replace each span\n",
    "    max_mask_cnt_per_span = [max(x, config['max_tokens_per_span']) for x in test_sent_span_lengths]\n",
    "\n",
    "    # Get the span information of merged masks in the test sentence\n",
    "    mask_spans = [x.span() for x in re.finditer('<mask>',test_sent_merged)]\n",
    "\n",
    "    special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "\n",
    "    queue = []\n",
    "    queue.append(test_sent_merged[:mask_spans[0][0]])\n",
    "    for i in range(len(mask_spans)):\n",
    "        curr_queue_size = len(queue)\n",
    "        hypotheses=[list(queue)] # deletion case\n",
    "        # print(f'working on the {i}th span. current queue size: {curr_queue_size}')\n",
    "        \n",
    "        for j in range(1, max_mask_cnt_per_span[i] + 1):\n",
    "        # for j in range(1, 3):\n",
    "            # print(f\"   * appending {j} masks\")\n",
    "            # Set up sentence for MLM inference (note we append variable number mask and then the rest of the sentence where the other spans are masked)\n",
    "            curr_full_text_hyp = [base_hyp + \"<mask>\" * j + test_sent_merged[mask_spans[i][1]:] for base_hyp in queue]\n",
    "            # print(f\"-- curr_masked_text: {curr_full_text_hyp}\")\n",
    "            \n",
    "            # Tokenize & conduct MLM inference\n",
    "            inputs = mlm_tokenizer(\n",
    "                curr_full_text_hyp, return_tensors=\"pt\", padding=True, truncation=True\n",
    "            )\n",
    "            inputs = inputs.to(config['device']) \n",
    "            masked_sequence=inputs['input_ids']\n",
    "            \n",
    "            if config['consider_prompt_for_cand_gen']:\n",
    "            \n",
    "                prompt_enc=mlm_tokenizer(mlm_tokenizer.bos_token + source_text,add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).to(config['device'])\n",
    "                prompt_enc['input_ids']=prompt_enc['input_ids'].expand(curr_queue_size,-1)\n",
    "                prompt_enc['attention_mask']=prompt_enc['attention_mask'].expand(curr_queue_size,-1)\n",
    "                # print(f\"-- shape of source text after being tokenized and converted to input ids: {prompt_enc['input_ids'].shape}\")\n",
    "                \n",
    "                input_tokens = torch.cat([prompt_enc.input_ids, inputs.input_ids], dim=1).to(config['device'])\n",
    "                attention_masks = torch.cat([prompt_enc.attention_mask, inputs.attention_mask], dim=1).to(config['device'])\n",
    "                \n",
    "                # with torch.no_grad():\n",
    "                #     logits = mlm(**inputs).logits\n",
    "                with torch.no_grad():\n",
    "                    logits = mlm(input_ids = input_tokens, \n",
    "                                attention_mask = attention_masks).logits\n",
    "\n",
    "                # Choose top k among non-special tokens\n",
    "                # print(f\"-- shape of logits before removing source text part: {logits.shape}\")\n",
    "                logits = logits[:, prompt_enc.input_ids.shape[1]:]\n",
    "                \n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    logits = mlm(**inputs).logits\n",
    "\n",
    "            # Choose top k among non-special tokens\n",
    "            logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "            indices_in_mlm_tokens = (\n",
    "                inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    "            ).nonzero(as_tuple=False) # if as_tuple=False, returns a tensor where column 1 indicates row indices, column 2 indicates column indices e.g. torch.Tensor([[0, 19],[0, 20], [0,38]])\n",
    "            # print(f\"-- location of masks including masks in the future spans: {indices_in_mlm_tokens}\")\n",
    "            \n",
    "            # For each hypothesis in curr_full_text_hyp, first j mask locations are relevant\n",
    "            indices_in_mlm_tokens = torch.cat([x[:j] for x in torch.chunk(indices_in_mlm_tokens, curr_queue_size)],dim=0)\n",
    "            indices_in_mlm_tokens_0 = indices_in_mlm_tokens[:,0]\n",
    "            indices_in_mlm_tokens_1 = indices_in_mlm_tokens[:,1]\n",
    "            # print(f\"-- location of masks (row indices): {indices_in_mlm_tokens_0}\")\n",
    "            # print(f\"-- location of masks (col indices): {indices_in_mlm_tokens_1}\")\n",
    "            \n",
    "            # Get top k tokens for the j masks\n",
    "            predicted_token_ids = torch.topk(\n",
    "                logits[indices_in_mlm_tokens_0, indices_in_mlm_tokens_1, :],\n",
    "                k=config['k_per_location'],\n",
    "                dim=-1,\n",
    "            )            \n",
    "            # print(f\"-- top k tokens for each mask in each hypothesis: {predicted_token_ids.indices}\")\n",
    "\n",
    "            # When we do beam search, we only beam search up until the j masks.\n",
    "            # print(f\"-- shape of masked_sequence before slicing and padding: {masked_sequence.shape}\")\n",
    "            # print(f\"-- masked_sequence before slicing and padding: {masked_sequence}\")\n",
    "            \n",
    "            masked_sequence = [masked_sequence[ix, :indices_in_mlm_tokens_1[j*(ix+1)-1]+1] for ix in range(masked_sequence.shape[0])]\n",
    "            masked_sequence = torch.nn.utils.rnn.pad_sequence(masked_sequence, batch_first=True, padding_value=mlm_tokenizer.pad_token_id)\n",
    "            # print(f\"-- shape of masked_sequence after slicing and padding: {masked_sequence.shape}\")\n",
    "            # print(f\"-- masked_sequence after slicing and padding: {masked_sequence}\")\n",
    "            \n",
    "            partial_hypotheses = get_beam_hypotheses_v0(source_text, \n",
    "                                masked_sequence, \n",
    "                                (indices_in_mlm_tokens_0, indices_in_mlm_tokens_1),\n",
    "                                predicted_token_ids.indices,\n",
    "                                mlm_tokenizer, \n",
    "                                lossfns,\n",
    "                                config)\n",
    "            \n",
    "            # print(f\"-- num of returned partial hypotheses after beam search: {len(partial_hypotheses)}\")\n",
    "            # print(f\"-- returned partial hypotheses after beam search: {partial_hypotheses}\")\n",
    "            \n",
    "            partial_hypotheses = sum(partial_hypotheses, [])\n",
    "            \n",
    "            # print(f\"-- num of partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {len(partial_hypotheses)}\")\n",
    "            # print(f\"-- partial hypotheses after unraveling disregarding the grouping by initial hypothesis: {partial_hypotheses}\")\n",
    "            # Extend the partial hypotheses to hypotheses pool for current mask span\n",
    "            hypotheses.append(partial_hypotheses)\n",
    "\n",
    "        # print(\"   * all mask length explored\")\n",
    "        hypotheses_all = sum(hypotheses, [])\n",
    "        # print(f\"-- # of hypotheses for current ({i}th) span: {len(hypotheses_all)}\")\n",
    "        # print(f\"-- entire list of hypotheses for current ({i}th) span: {hypotheses_all}\")\n",
    "        \n",
    "        # # Append snippet of text after current span and before next span before scoring\n",
    "        if i < len(mask_spans) -1 :\n",
    "            hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:mask_spans[i+1][0]] for x in hypotheses_all]\n",
    "        else:\n",
    "            hypotheses_all = [x + test_sent_merged[mask_spans[i][1]:] for x in hypotheses_all]\n",
    "        # print(f\"-- entire list of hypotheses for current ({i}th) span for scoring: {hypotheses_all}\") \n",
    "        \n",
    "        # Scoring the hypotheses and select top beam hypotheses\n",
    "        loss_weights = config['loss_weights']\n",
    "        curr_loss = torch.zeros(len(hypotheses_all)).to(config['device'])\n",
    "        data_loader = DataLoader(CustomDataset(hypotheses_all),batch_size=batch_size)\n",
    "\n",
    "        for lossid, lossname in enumerate(config[\"losses\"]):\n",
    "            lossvalues=[]\n",
    "            with torch.no_grad():\n",
    "                for batch in data_loader:\n",
    "                    lossvalue = lossfns[lossid].compute_gold_loss(\n",
    "                        source_text, batch,\n",
    "                        label_id=config['target_label_ids'][lossid],\n",
    "                    )\n",
    "                    lossvalues.append(lossvalue)\n",
    "                    torch.cuda.empty_cache()\n",
    "            lossvalue = torch.cat(lossvalues,dim=0)\n",
    "            curr_loss += loss_weights[lossid] * lossvalue\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        top_beams = torch.topk(curr_loss, k=config['beam_size'], dim=-1, largest=False).indices\n",
    "        # print(f\"-- selected {config['beam_size']} hypotheses' indices: {top_beams}\")\n",
    "        # print(f\"-- selected {config['beam_size']} hypotheses for current ({i}th) span: {[hypotheses_all[ix] for ix in top_beams]}\")\n",
    "        queue = [hypotheses_all[ix] for ix in top_beams]\n",
    "        del hypotheses_all\n",
    "        # print(f\"-- queue after extending current step's selected hypotheses: {queue}\")\n",
    "        \n",
    "    final_hypotheses, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_ = final_reranking(source_text,\n",
    "                                                                                                        [list(queue)],\n",
    "                                                                                                        lossfns,\n",
    "                                                                                                        config,\n",
    "                                                                                                        batch_size=32)\n",
    "    return final_hypotheses, new_best_weighted_loss_, new_best_allsat_, new_best_logging_loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method 2. autoregressively decode multiple tokens for each span\n",
    "\n",
    "#### observation: model doesn't easily output the next gold token. (might be hard to use it as ending signal.) maybe need a hyperparameter max_masks like above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = AutoModelForMaskedLM.from_pretrained('roberta-large')\n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly<mask><mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask><mask> activities.<mask> \"broomstick<mask><mask> saga captivated the nation and left many stunned by the audacity of his crimes.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_tokens = mlm_tokenizer(test_sent_merged,return_tensors=\"pt\",add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = torch.where(torch.Tensor(test_sent_tokens) == mlm_tokenizer.mask_token_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_short = ' '.join(test_sent.split()[:20])\n",
    "## merge masks\n",
    "test_sent_short_merged = re.sub(r\"(<mask>)+\", \"<mask>\", test_sent_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_short_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "grammar_model = AutoModelForSequenceClassification.from_pretrained('textattack/roberta-base-CoLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
       "         31890,    25,    10,  1751,     4,    20,   313,  2288, 50264,   813,\n",
       "             8,   916,   150,  5783,   418,     8,  7398,   257,  6058,     4,\n",
       "           572,    10,   251,   803,     6,     5,   249,  2312,     7,  1349,\n",
       "           123,   159,     8,   836,  1103,   136,   123,    13,    39, 50264,\n",
       "          1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466, 13363,\n",
       "         23907,     5,  1226,     8,   314,   171, 12144,    30,     5,  9818,\n",
       "         18583,     9,    39,  3474,     4]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_lengths[cursor_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  3711,     5,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  4487,   258,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  8057,  1400,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  3711,     5,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  4487,   258,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  8057, 12647,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  3711,     5,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  4487,   258,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4],\n",
      "        [25176,    62,    10,  6755,     9, 21356,   634,    10, 39546, 19650,\n",
      "         31890,    25,    10,  1751,     4,    20,   313,  2288,  8057, 12647,\n",
      "           813,     8,   916,   150,  5783,   418,     8,  7398,   257,  6058,\n",
      "             4,   572,    10,   251,   803,     6,     5,   249,  2312,     7,\n",
      "          1349,   123,   159,     8,   836,  1103,   136,   123,    13,    39,\n",
      "         50264,  1713,     4, 50264,    22,   428,  4294, 19650, 50264, 17466,\n",
      "         13363, 23907,     5,  1226,     8,   314,   171, 12144,    30,     5,\n",
      "          9818, 18583,     9,    39,  3474,     4]])\n",
      "tensor([[25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        ...,\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4]])\n",
      "tensor([[25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        ...,\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4]])\n",
      "tensor([[25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        ...,\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4]])\n",
      "tensor([[25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        ...,\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4],\n",
      "        [25176,    62,    10,  ...,    39,  3474,     4]])\n"
     ]
    }
   ],
   "source": [
    "span_lengths = span_lengths_es[0]\n",
    "cursor_idx = 0\n",
    "cursor = locations[1][cursor_idx]\n",
    "cursor_offset = 0\n",
    "\n",
    "comprehensive_hypotheses = []\n",
    "while True:\n",
    "    with torch.no_grad():\n",
    "        comprehensive_hypotheses.append(torch.cat((test_sent_tokens[:, :cursor], test_sent_tokens[:, cursor+1:]), dim=-1))\n",
    "        \n",
    "        predictions = mlm(test_sent_tokens).logits\n",
    "        predictions[:, :, [0,1,2,3,50264]] = -10000\n",
    "        top3 = torch.topk(predictions[:, cursor,:], k=3, dim=-1).indices\n",
    "        comprehensive_hypotheses.append(torch.cat((torch.tile(test_sent_tokens[:, :cursor], dims= (3,1)), top3.reshape(-1,1), torch.tile(test_sent_tokens[:, cursor+1:], dims= (3,1))), dim=-1))\n",
    "        hypotheses = torch.cat((torch.tile(test_sent_tokens[:, :cursor], dims= (3,1)), top3.reshape(-1,1), torch.tile(test_sent_tokens[:, cursor:], dims= (3,1))), dim=-1)\n",
    "        cursor_offset += 1\n",
    "        \n",
    "        iteration_count = max(span_lengths[cursor_idx], 5)\n",
    "        \n",
    "        for _ in range(iteration_count):\n",
    "            hypotheses_texts = mlm_tokenizer.batch_decode(hypotheses)\n",
    "            predictions = mlm(hypotheses).logits\n",
    "            top3 = torch.topk(predictions[:, cursor + cursor_offset], k=3, dim=-1).indices\n",
    "            print(torch.cat((torch.tile(hypotheses[:, :cursor + cursor_offset], dims= (3,1)), top3.reshape(-1,1), torch.tile(hypotheses[:, cursor + cursor_offset+1:], dims= (3,1))), dim=-1))\n",
    "            hypotheses_scores = torch.softmax(grammar_model(torch.cat((torch.tile(hypotheses[:, :cursor + cursor_offset], dims= (3,1)), top3.reshape(-1,1), torch.tile(hypotheses[:, cursor + cursor_offset+1:], dims= (3,1))), dim=-1)).logits,dim=-1)\n",
    "            # print(hypotheses_scores[: ,1])\n",
    "            # break\n",
    "            \n",
    "            \n",
    "            comprehensive_hypotheses.append(torch.cat((torch.tile(hypotheses[:, :cursor + cursor_offset], dims= (3,1)), top3.reshape(-1,1), torch.tile(hypotheses[:, cursor + cursor_offset+1:], dims= (3,1))), dim=-1))\n",
    "            hypotheses = torch.cat((torch.tile(hypotheses[:, :cursor + cursor_offset], dims= (3,1)), top3.reshape(-1,1), torch.tile(hypotheses[:, cursor + cursor_offset:], dims= (3,1))), dim=-1)\n",
    "            cursor_offset += 1\n",
    "            if (hypotheses[:, cursor+cursor_offset-1] == hypotheses[:, cursor+cursor_offset]).sum() > 0:\n",
    "                hypotheses = hypotheses[torch.randint(0, len(hypotheses), (10,)), :]\n",
    "                break\n",
    "            else:\n",
    "                hypotheses = hypotheses[torch.randint(0, len(hypotheses), (10,)), :]\n",
    "            \n",
    "        \n",
    "        \n",
    "        break\n",
    "        \n",
    "        test_sent_tokens()\n",
    "        test_sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.'],\n",
       " ['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.'],\n",
       " ['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.'],\n",
       " ['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both management staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket sales staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the shop staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.'],\n",
       " ['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales shop staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store management staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store floor staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket counter staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket\\' staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store management staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket management staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both supermarket sales staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.'],\n",
       " ['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales security, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management guard staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store management security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\' staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store security, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales security and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security guard staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security counter staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales floor staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store management and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store security and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both sales security including staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store management security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store security guard staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.'],\n",
       " ['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office female staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s cleaning staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management,, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store,\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security counter security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security, female staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales floor cleaning staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management guard the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s shop staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management, store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store, security staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security counter\\'s staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security, and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales floor, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management guard service staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s checkout staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office store staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the supermarket\\'s sales staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management, female staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both store store,, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket store\\'s office sales staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security counter service staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket security,, staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store supermarket sales floor and staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       "  'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both the management guard the staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.']]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mlm_tokenizer.batch_decode(x) for x in comprehensive_hypotheses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted store<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly threatened the<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly attacked both<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.',\n",
       " 'holding up a string of supermarkets using a broomstick disguised as a gun. The man reportedly assaulted supermarket<mask> staff and customers while demanding money and valuables. After a long investigation, the police managed to track him down and bring charges against him for his<mask> activities.<mask> \"broomstick<mask> saga captivated the nation and left many stunned by the audacity of his crimes.']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_tokenizer.batch_decode(hypotheses_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<mask><mask> know can actually hurt us.<mask><mask><mask> can lead to<mask><mask><mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> alreadyWe<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> doKnowing<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> shouldNot<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> weWe<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> tooKnowing<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> youNot<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> toWe<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> knowingKnowing<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\",\n",
       " \"<s> havingNot<mask> know can actually hurt us.<mask> can lead to<mask> missed opportunities, and even dangerous situations. It's important to seek knowledge and be open to learning in order to avoid unnecessary harm or mistakes. Remember, sometimes the things we don't know are exactly what we need to discover to grow and make better choices in the future.</s>\"]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_tokenizer.batch_decode(hypotheses_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<re.Match object; span=(93, 99), match='<mask>'>,\n",
       "              <re.Match object; span=(99, 105), match='<mask>'>],\n",
       "             1: [<re.Match object; span=(265, 271), match='<mask>'>,\n",
       "              <re.Match object; span=(271, 277), match='<mask>'>],\n",
       "             2: [<re.Match object; span=(289, 295), match='<mask>'>],\n",
       "             3: [<re.Match object; span=(307, 313), match='<mask>'>,\n",
       "              <re.Match object; span=(313, 319), match='<mask>'>]})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 319)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<re.Match object; span=(93, 99), match='<mask>'>,\n",
       "              <re.Match object; span=(99, 105), match='<mask>'>,\n",
       "              <re.Match object; span=(265, 271), match='<mask>'>,\n",
       "              <re.Match object; span=(271, 277), match='<mask>'>,\n",
       "              <re.Match object; span=(289, 295), match='<mask>'>,\n",
       "              <re.Match object; span=(307, 313), match='<mask>'>,\n",
       "              <re.Match object; span=(313, 319), match='<mask>'>]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
