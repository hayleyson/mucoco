{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/data/hyeryung/mucoco')\n",
    "\n",
    "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from new_module.locate.new_locate_utils import LocateMachine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel(outputs_df):\n",
    "    outputs_df=outputs_df.explode('generations',ignore_index=True)\n",
    "    outputs_df['prompt']=outputs_df['prompt'].apply(lambda x: x['text'])\n",
    "    outputs_df['generations']=outputs_df['generations'].apply(lambda x: x['text'] if isinstance(x, dict) else x)\n",
    "    outputs_df = outputs_df.dropna().reset_index(drop=True)\n",
    "    return outputs_df\n",
    "toxic_gen=pd.read_json('new_module/data/toxicity-avoidance/dev_set.jsonl',lines=True)\n",
    "toxic_gen=unravel(toxic_gen)\n",
    "prompt = '“I went to use the bathroom, and I went in and Lance was bent'\n",
    "prediction = toxic_gen.loc[toxic_gen['prompt']==prompt,'generations'].tolist()\n",
    "ckpt_path = '/data/hyeryung/loc_edit/models/roberta-base-jigsaw-toxicity-classifier-energy-training/step_1000_best_checkpoint/'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(ckpt_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt_path)\n",
    "device='cuda'\n",
    "model = model.to(device)\n",
    "loc_machine=LocateMachine(model,tokenizer)\n",
    "res = loc_machine.locate_main(prediction, \"attention\", max_num_tokens = 6, unit=\"word\", num_layer=10, label_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_tokenizer = AutoTokenizer.from_pretrained('roberta-base',cache_dir='/data/hyeryung/hf_cache')\n",
    "mlm = AutoModelForMaskedLM.from_pretrained('roberta-base',cache_dir='/data/hyeryung/hf_cache')\n",
    "mlm = mlm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_text = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace tokens at the indices with mask tokens\n",
    "inputs = mlm_tokenizer(\n",
    "    masked_text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "inputs = inputs.to(device) \n",
    "# inputs = mlm_tokenizer(\n",
    "#     source_text + ' ' + masked_text[0], return_tensors=\"pt\", add_special_tokens=False\n",
    "# )\n",
    "\n",
    "## make predictions for the masked indices\n",
    "with torch.no_grad():\n",
    "    logits = mlm(**inputs).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "logits[:, :, special_token_ids] = -float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_in_mlm_tokens = (\n",
    "    inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    ").nonzero(as_tuple=True)\n",
    "# print(f\"indices_in_mlm_tokens: {indices_in_mlm_tokens}\")\n",
    "## get top k tokens for each index\n",
    "\n",
    "predicted_token_ids = torch.topk(\n",
    "    logits[indices_in_mlm_tokens[0], indices_in_mlm_tokens[1], :],\n",
    "    k=10,\n",
    "    dim=-1,\n",
    ")\n",
    "# print(f\"predicted_token_ids: {predicted_token_ids}\")\n",
    "# print(f\"mlm_tokenizer.batch_decode(predicted_token_ids.indices): {mlm_tokenizer.batch_decode(predicted_token_ids.indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_ids.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_ids.indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_token_ids: torch.return_types.topk(\n",
      "values=tensor([[22.0476, 19.4729, 17.5394, 16.8642, 16.5963, 16.4827, 16.4021, 15.7711,\n",
      "         15.7436, 15.3570],\n",
      "        [17.5601, 16.3528, 15.0402, 14.9633, 14.3649, 13.8561, 13.2594, 13.2089,\n",
      "         12.6610, 12.5642],\n",
      "        [16.7789, 15.7252, 15.5652, 15.4932, 15.3546, 15.3041, 15.2817, 15.1390,\n",
      "         14.8545, 14.6381],\n",
      "        [16.9867, 16.6328, 16.1767, 14.9714, 14.3802, 13.4213, 13.3534, 13.3342,\n",
      "         12.8598, 12.8383],\n",
      "        [15.5927, 15.5903, 15.5631, 14.8100, 14.4180, 14.1002, 13.6288, 13.5641,\n",
      "         13.5315, 13.0986],\n",
      "        [16.8475, 16.7198, 16.0989, 15.9949, 15.4332, 15.2327, 15.2147, 14.9328,\n",
      "         14.8248, 14.5735],\n",
      "        [19.4643, 14.3413, 13.1266, 12.6918, 12.6008, 12.3762, 11.8818, 11.5772,\n",
      "         11.5281, 11.4883],\n",
      "        [17.3266, 15.7880, 15.7409, 15.6494, 15.2200, 14.8165, 14.7254, 14.6882,\n",
      "         14.5433, 14.4847],\n",
      "        [16.9962, 16.8003, 16.3852, 16.3049, 15.7828, 14.8172, 14.3738, 14.3228,\n",
      "         14.3083, 14.1886],\n",
      "        [13.7294, 11.5412, 10.8240, 10.7314, 10.7028, 10.6764, 10.5329, 10.4109,\n",
      "         10.3960, 10.3690],\n",
      "        [12.3987, 11.9212, 10.4466, 10.1989,  9.6715,  9.6135,  9.2713,  8.3205,\n",
      "          8.2772,  8.1494],\n",
      "        [20.3395, 17.1361, 16.0284, 14.1271, 13.9386, 13.5283, 13.4905, 13.4451,\n",
      "         13.3406, 13.3271],\n",
      "        [15.3060, 14.7931, 13.6338, 13.4726, 13.4477, 13.0987, 13.0713, 12.9350,\n",
      "         12.8565, 12.7045],\n",
      "        [21.6066, 17.7277, 17.2978, 15.2125, 14.3531, 14.2456, 13.9140, 13.6551,\n",
      "         13.4436, 13.1048],\n",
      "        [17.5683, 15.8340, 15.3837, 14.9424, 14.8776, 14.6397, 14.6173, 14.5269,\n",
      "         14.5191, 14.4529],\n",
      "        [17.2929, 16.9789, 16.3205, 16.1346, 16.1313, 15.8705, 15.8305, 15.7945,\n",
      "         15.7890, 15.7714],\n",
      "        [16.6591, 16.4555, 15.5120, 15.3955, 15.2928, 15.0606, 14.9854, 14.8208,\n",
      "         14.7260, 14.2846],\n",
      "        [24.6838, 22.2196, 20.0829, 19.6098, 18.6050, 17.4756, 17.2337, 16.9556,\n",
      "         16.9251, 16.8624],\n",
      "        [17.3613, 17.2660, 17.2039, 16.6825, 16.3908, 16.3624, 16.1745, 16.1668,\n",
      "         16.0909, 15.8996],\n",
      "        [16.5434, 15.6583, 14.6893, 13.6877, 13.3963, 12.7079, 12.4097, 12.1087,\n",
      "         12.0791, 11.9534],\n",
      "        [11.6818, 11.3892, 11.2418, 10.7842, 10.6130, 10.5801, 10.5325, 10.4319,\n",
      "         10.3238, 10.2934],\n",
      "        [14.6520, 10.6053, 10.2869, 10.2206, 10.1680,  9.7241,  9.6235,  9.4395,\n",
      "          9.4208,  9.3407],\n",
      "        [16.2670, 16.1860, 12.2441, 12.0107, 11.9568, 11.8927, 11.7062, 11.6845,\n",
      "         11.5221, 11.4659],\n",
      "        [16.2611, 15.6528, 15.5850, 15.3666, 15.0552, 14.9438, 14.8739, 14.7708,\n",
      "         14.6664, 14.6562],\n",
      "        [16.7940, 16.0715, 15.6949, 14.3513, 14.2239, 12.6533, 12.2404, 11.7762,\n",
      "         11.7043, 11.6140],\n",
      "        [12.5030, 12.1752, 11.3853, 11.0454, 10.9880, 10.8681, 10.7428, 10.7190,\n",
      "         10.7164, 10.6158],\n",
      "        [12.4775, 10.6382,  9.4757,  9.4126,  9.2984,  9.1551,  9.1359,  8.7835,\n",
      "          8.7765,  8.6265],\n",
      "        [14.8725, 10.6246,  9.6712,  9.6377,  9.5931,  9.5598,  9.5452,  9.4959,\n",
      "          9.4917,  9.4481],\n",
      "        [18.0430, 16.4545, 16.2739, 14.1019, 14.0798, 13.7798, 13.4499, 13.2706,\n",
      "         12.9771, 12.3293],\n",
      "        [16.2178, 14.4060, 14.0525, 13.2931, 13.2857, 13.1219, 12.9970, 12.7741,\n",
      "         12.7433, 12.6224],\n",
      "        [11.0056,  8.4309,  8.1386,  7.9530,  7.8284,  7.7673,  7.2747,  7.0072,\n",
      "          6.9334,  6.8611],\n",
      "        [ 8.4579,  7.3155,  6.8890,  6.8741,  6.7990,  6.7346,  6.7270,  6.7043,\n",
      "          6.6640,  6.5345],\n",
      "        [13.3470, 11.2756, 11.1037, 10.9579,  9.2129,  8.9679,  8.7225,  8.6266,\n",
      "          8.3710,  8.1272],\n",
      "        [12.5272, 12.3023, 12.1785, 11.9845, 11.7178, 11.6290, 11.4701, 11.3804,\n",
      "         11.2989, 11.0957],\n",
      "        [17.4838, 14.7471, 12.7699, 11.9957, 10.8344, 10.7814, 10.6511, 10.4972,\n",
      "         10.3356, 10.1236],\n",
      "        [12.5862, 12.2585, 12.1265, 12.0491, 12.0333, 11.9309, 11.8144, 11.6493,\n",
      "         11.2648, 11.2431],\n",
      "        [15.4437, 15.3970, 15.3796, 14.3433, 14.0274, 13.8893, 13.5711, 13.4968,\n",
      "         13.4756, 13.3448],\n",
      "        [14.8397, 14.2946, 14.2432, 13.6779, 13.4320, 13.2952, 13.0454, 13.0384,\n",
      "         12.9852, 12.9375],\n",
      "        [17.3366, 17.2938, 17.2633, 17.0872, 16.7387, 16.7199, 16.6693, 16.4655,\n",
      "         16.2365, 16.1801],\n",
      "        [13.8143, 12.5842, 12.5532, 12.4577, 12.3116, 12.1870, 11.8876, 11.8222,\n",
      "         11.8101, 11.7884],\n",
      "        [11.9764, 11.8356, 11.0066, 11.0048, 10.9544, 10.5593, 10.3371, 10.1163,\n",
      "         10.1064, 10.0791],\n",
      "        [10.1244,  9.8185,  9.8136,  9.7552,  9.6990,  9.4315,  9.2682,  9.2578,\n",
      "          9.0533,  9.0467],\n",
      "        [10.3246, 10.3117, 10.2452,  9.3077,  9.2941,  9.2631,  9.2600,  9.0213,\n",
      "          8.9470,  8.7906],\n",
      "        [13.1737, 12.1326, 11.5879, 11.5153, 11.2998, 10.9739, 10.7371, 10.4959,\n",
      "         10.3613, 10.0577],\n",
      "        [18.1189, 17.6685, 17.5668, 16.5649, 16.5332, 16.4984, 16.4581, 16.2756,\n",
      "         16.2651, 16.2184],\n",
      "        [12.1741, 11.5570, 11.4887,  9.9604,  9.9159,  9.6920,  9.6651,  9.2638,\n",
      "          9.2059,  9.1644],\n",
      "        [14.8374, 14.2960, 13.2226, 12.0285, 10.6259, 10.5887, 10.4392, 10.4063,\n",
      "         10.2194, 10.2073],\n",
      "        [17.5327, 13.8236, 13.5184, 13.4858, 13.3646, 13.3524, 13.2270, 13.1555,\n",
      "         13.1448, 12.7813],\n",
      "        [17.0002, 14.9120, 14.3164, 13.8453, 12.5836, 12.4139, 12.3873, 12.1105,\n",
      "         11.9802, 11.9759],\n",
      "        [16.0269, 12.7591, 12.2586, 11.7645, 10.4903, 10.1939, 10.0674, 10.0284,\n",
      "          9.8827,  9.8295],\n",
      "        [13.6261, 12.2448,  9.6000,  9.5228,  9.0972,  9.0584,  8.9690,  8.8170,\n",
      "          8.7639,  8.4920],\n",
      "        [11.6912, 10.9697, 10.7246, 10.2914, 10.2655, 10.0594,  9.6215,  9.5316,\n",
      "          9.5197,  9.4886],\n",
      "        [14.6190, 13.6906, 13.4823, 13.1197, 13.0796, 12.9315, 12.9179, 12.8872,\n",
      "         12.8727, 12.5557],\n",
      "        [15.6871, 15.1593, 13.7373, 13.3152, 12.2546, 11.7941, 11.4437, 11.0900,\n",
      "         10.9021, 10.7618],\n",
      "        [13.0073, 12.2181, 12.1756, 11.3281, 11.2876, 11.1551, 11.1233, 11.1039,\n",
      "         10.8946, 10.6629],\n",
      "        [11.6256, 11.4828, 11.2422, 11.1773, 11.0506, 11.0234, 10.9395, 10.8891,\n",
      "         10.8563, 10.6002],\n",
      "        [14.4815, 13.5182,  9.9793,  9.8677,  9.3634,  9.2744,  8.8969,  8.8018,\n",
      "          8.7192,  8.6465],\n",
      "        [19.2828, 13.4236, 13.2601, 13.1129, 12.9068, 12.8670, 12.8370, 12.7302,\n",
      "         12.7177, 12.5860],\n",
      "        [12.0505, 11.7634, 11.5489, 11.3869, 11.3336, 11.2840, 11.2032, 11.2020,\n",
      "         10.9349, 10.8301],\n",
      "        [12.4332, 12.0853, 11.8002, 11.5481, 11.3784, 11.1415, 10.9458, 10.7536,\n",
      "         10.7411, 10.6720],\n",
      "        [10.8997,  9.7332,  8.9318,  8.7648,  8.5686,  8.5231,  8.2146,  8.1864,\n",
      "          8.0756,  8.0754],\n",
      "        [ 9.2460,  8.9909,  8.8651,  8.3054,  8.3053,  8.0316,  7.8765,  7.4020,\n",
      "          7.3568,  7.3073],\n",
      "        [ 9.4998,  9.4989,  9.3606,  8.8060,  8.3204,  8.1605,  8.0850,  7.6194,\n",
      "          7.5446,  7.4015],\n",
      "        [ 9.8854,  9.1884,  9.0537,  8.7679,  8.3014,  8.0413,  7.7634,  7.6151,\n",
      "          7.5579,  7.5433],\n",
      "        [11.0511, 10.8366, 10.3990, 10.1026,  9.5487,  9.5048,  9.4536,  9.2226,\n",
      "          9.1748,  9.1358]], device='cuda:0'),\n",
      "indices=tensor([[  100,   894,  1213,   170, 11243,  4763,   243,  1620,  2515, 15216],\n",
      "        [   21,  1682,  2145,   437,  2294,   554,   489,    58,  1381,   524],\n",
      "        [14575,   206,   912,  3581,  8016,   517,   422, 22093,  1067,  2145],\n",
      "        [    4,   142,     8,     6,    25,    77,    53,    14,    99,   454],\n",
      "        [  106,   123, 18424,  6820,    82,  1925,    24,  6941, 21715, 14006],\n",
      "        [  123,  9589,   106,  1375,    24,   667,  2185,  9701, 17587,   878],\n",
      "        [    4,   328,   734,  1555,  1666,  1174,     6,   479,    72,    35],\n",
      "        [29374,   383,  5418, 15684,  1420,  5582, 23332, 37047, 10317, 14341],\n",
      "        [27827,   100,   894,  6785, 18891, 22616,  9690, 15173,  8987,   170],\n",
      "        [  101,  1462,  7758,  8180,  1613,    98, 11339,   235,   269, 34449],\n",
      "        [    4,    35,   116,  1174,   328,   734,  1555,  1666,   162,    72],\n",
      "        [  894,   700,   100,  8773, 10567, 12083, 25244, 33667, 15827, 14009],\n",
      "        [  376,   439, 20185,  1348, 13503,  3148,  2294,  1224,  1410, 21654],\n",
      "        [   39,    10,   127,    65,   123,   277,     5,    42,    14,   110],\n",
      "        [ 2549,   652,  6399,   865,  3124,  6085,  9304,  9377,  7524,  8040],\n",
      "        [ 3124,   124,  2985,  6181,   865,   652, 14599,  9377,  5397, 18781],\n",
      "        [  865,  2549,   652, 32461,  3124,   124,  6399,  6181,  9377, 14262],\n",
      "        [  113,   100,   894,  2515,  1213, 46353,   170, 46150, 47096, 11243],\n",
      "        [  100,  6785,   894, 15216, 11243, 33724, 13721,  2515, 29375, 22174],\n",
      "        [  127,     5,    10,   162,    39,    69,    24,    14,    42,   402],\n",
      "        [  865,  1883, 21342,  9304, 16179,  1420,  3298,  1028, 10654,   464],\n",
      "        [    6, 21342,  3298,   865,   631,  1883,  6148,  1555, 10654, 30241],\n",
      "        [   79,    37,  1436,  1259,  1547,  1604,  2505,  1454,  3452,  2250],\n",
      "        [32424,   560, 40900, 35349, 43414, 13837,  9591, 19256,  5632, 27300],\n",
      "        [   38,    37,    24,    89,    79,   960,    14,    99,  3370,   961],\n",
      "        [   11,  2190,    10,  2429,    95,   878,     5,    15,  1826,   127],\n",
      "        [  162,   123,  8265,    24,    69,   409,    89,   159,  2400,   124],\n",
      "        [    4,   328,   116,  1666,  1174,     6,   734,  1555,   479,   162],\n",
      "        [   37,    24,    79,    38,  5907,  3370,   961,  4909,   951,    51],\n",
      "        [  243,   133,   100,  1711,  2264,   713,  2409,   170,   970,   894],\n",
      "        [   21,    24,     5,    58,     6,    18,     4,    10,    56,   243],\n",
      "        [   24,    21,    11,    89,  2721,  2131,  8080,   929,    14,    66],\n",
      "        [    4,   328,   116,    35,     6,   742,    72,  1666,   734,  1174],\n",
      "        [ 2721,  2770,  1969,  1307,  2131,  5802,  3997, 14011, 12058,  2933],\n",
      "        [    4,   328,    35,   116,  1174,   734,   479,  1666,    72,  1555],\n",
      "        [ 3820, 14633,  2913,     6,   455,  5802, 10905,  1104,  1969,  6474],\n",
      "        [ 4682,     6,    19,    30,    13,    35,    93,   227,     9,    31],\n",
      "        [ 9310, 12045, 17465, 16433, 11471, 34034,  3535, 11824,  3716,  1929],\n",
      "        [  179,   415, 12473,   560,  1121, 40900,  9591, 10777,  3750, 27227],\n",
      "        [ 2468,  3148,   547,   551,  1654, 15158,  8473,  1432,  2037,  7249],\n",
      "        [   30,     7,    11,    66,    19,    88,   159,    62,    10,   124],\n",
      "        [    5,    10,    66,    30,    39,     7,   514,    11,    19,     9],\n",
      "        [   11,    39,     9,    30,     5,  7727,    19,     7,   514,  2498],\n",
      "        [   39,    18,  7727,   127,     9,     8,     5, 11025,    69,  6966],\n",
      "        [ 4148,  2409,  1121, 21674,  2765,  3684,  1708,  3750,  7605,  2264],\n",
      "        [  253,   169,   177,    86,   569,  1151,   477, 10299,  1079,   822],\n",
      "        [   35,     4,   116,     6,  1666,    93,   328,  1174,   734,  1555],\n",
      "        [   37,    38,    24,    10,    14,    52,  3370,    42,    47,   961],\n",
      "        [   21,    18,     6,    58,    95,  1682,  2173,   214,     8,   437],\n",
      "        [  828,    55,  2125,     9,  1823,  1280, 15836,   422,  9049, 10084],\n",
      "        [    9,    55,    10,  1823,     8,     5,    12,    50,   103,     7],\n",
      "        [   86,    24,   173,   123,  1007,  1351,   402,  1524,  2682, 12989],\n",
      "        [ 1174,   894,   734,  2515,     6,  1711, 10567,  7516,   578,  8773],\n",
      "        [    5,   127,    10,    84,    24,    39,    14,    41,    65,     6],\n",
      "        [ 1011,  3242,  6325, 29432, 20604, 19015,  5405,  1028,  3403,  3188],\n",
      "        [10802,  8411, 13670, 33138,  2473,  1028, 19015, 15686,   865, 15459],\n",
      "        [    4,    35,   734,  1174,  1555,   328,     6,  1666,    72,   131],\n",
      "        [48584,    17, 49093, 47639, 48555,   176, 43251,   246,  2744,  4056],\n",
      "        [ 1275,  5718,  1104,  5009,   249,  3579,  2440,   200,    78,  6907],\n",
      "        [   11,    15,    25, 11291,    23,    19,   137,    71,     6,     7],\n",
      "        [    5,    10,     6,     8,    11,     7,    25,    15,   639,    23],\n",
      "        [    5,     6,     8,    25,   514,     9,    10,   150,     7,   512],\n",
      "        [    8,     5,     6,    25,     9,    19,   150,    24,    10,   514],\n",
      "        [    5,     8,    24,     6,    16,   514,    63,     9,    19,    10],\n",
      "        [   16,     8,   137,    71,   514,     6,    24,   150,   450,     9]],\n",
      "       device='cuda:0'))\n",
      "mlm_tokenizer.batch_decode(predicted_token_ids.indices): ['IHeTheyWeEveryonePeopleItAsSheEverybody', \" was kept remember'm stopped started keep were tried am\", ' breathe think stop sleep breath move run scream talk remember', '. because and, as when but that what until', ' them him footsteps voices people blood it tears gunshots bullets', ' him breathing them moving it trying myself crying praying running', '.!... …...…,..\":', ' handcuffs things clothes headphones hands shoes restraints goggles boots gloves', 'SomethingIHeJustsomethingThingsMoreEverythingjustWe', ' like dead mad dying gone so laughing right really pissed', '.:?…!... …... me.\"', 'HeheIDavidJohnPaulRobertMatthewMikeMichael', ' came went smiled reached laughed pushed stopped turned moved squeezed', ' his a my one him another the this that your', ' hair face shirt hand arm mouth pants stomach pocket lap', ' arm back leg breast hand face throat stomach neck thigh', ' hand hair face vagina arm back shirt breast stomach palm', '\"IHeSheThey\"…We\"\\'\"...Everyone', 'IJustHeEverybodyEveryoneStartLikeSheSomeoneStop', ' my the a me his her it that this something', ' hand door towel pants stall hands bag phone keys change', ', towel bag hand thing door button … keysbrush', ' she he Johnson Smith Brown Williams Davis Jones Anderson Jackson', 'behindtoHitsawBehindaroundhitfoundwithgrab', ' I he it there she everything that what everybody everyone', ' in fighting a killing just running the on holding my', ' me him scared it her away there down pain back', '.!?...…,... …. me', ' he it she I nobody everybody everyone somebody someone they', 'ItTheIThatWhatThisAndWeThereHe', \" was it the were,'s. a hadIt\", ' it was in there beautiful hot bathroom room that out', '.!?:,].\"......…', ' beautiful amazing perfect huge hot empty incredible unbelievable gorgeous dark', '.!:?…........\" …', ' filled decorated covered, full empty bare white perfect lit', ' except, with by for: — between of from', ' shower sink tub couch toilet sinks showers bath pool floor', 'inatintotoInHithitOverAtonto', ' pulled pushed held taken forced washed swept followed caught grabbed', ' by to in out with into down up a back', ' the a out by his to water in with of', ' in his of by the wet with to water wearing', \" his's wet my of and the yoga her swim\", 'OnAndInAboutByAllButAtFromWhat', ' end way game time video moment point meantime rest film', ':.?,... —!…... …', ' he I it a that we everybody this you everyone', \" was's, were just kept guy're and'm\", ' bit more piece of extra amount chunk run spark burst', ' of more a extra and the- or some to', ' time it work him energy effort something practice stuff rhythm', '…He...She,ThatJohnOh—David', ' the my a our it his that an one,', ' ball pitch bat slider fastball glove switch phone baseball radio', ' fingers finger imagination fingertips eyes phone glove tongue hand thumb', '.:...… …!,....\";', '��●********************************�2�3+�', ' red yellow white damaged police stolen blue second first pink', ' in on as floating at with before after, to', ' the a, and in to as on behind at', ' the, and as water of a while to car', ' and the, as of with while it a water', ' the and it, is water its of with a', ' is and before after water, it while seen of']\n"
     ]
    }
   ],
   "source": [
    "## replace tokens at the indices with mask tokens\n",
    "inputs = mlm_tokenizer(\n",
    "    masked_text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "inputs = inputs.to(device) \n",
    "# inputs = mlm_tokenizer(\n",
    "#     source_text + ' ' + masked_text[0], return_tensors=\"pt\", add_special_tokens=False\n",
    "# )\n",
    "\n",
    "## make predictions for the masked indices\n",
    "with torch.no_grad():\n",
    "    logits = mlm(**inputs).logits\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "indices_in_mlm_tokens = (\n",
    "    inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    ").nonzero(as_tuple=True)\n",
    "\n",
    "## get top k tokens for each index\n",
    "predicted_token_ids = torch.topk(\n",
    "    logits[indices_in_mlm_tokens[0], indices_in_mlm_tokens[1], :],\n",
    "    k=10,\n",
    "    dim=-1,\n",
    ")\n",
    "print(f\"predicted_token_ids: {predicted_token_ids}\")\n",
    "print(f\"mlm_tokenizer.batch_decode(predicted_token_ids.indices): {mlm_tokenizer.batch_decode(predicted_token_ids.indices)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from itertools import chain\n",
    "import math\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "os.chdir('/data/hyeryung/mucoco')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "from copy import deepcopy\n",
    "import new_module.losses as lossbuilder\n",
    "import new_module.losses_old as lossbuilder_old\n",
    "import wandb\n",
    "# from new_module.decode_utils import (\n",
    "#     beam_rerank_v0,\n",
    "#     beam_rerank_v1,\n",
    "#     beam_rerank_v2,\n",
    "#     combi_rerank,\n",
    "# )\n",
    "from new_module.new_decode_utils import get_beam_hypotheses, get_combi_hypotheses, final_reranking\n",
    "from new_module.evaluate_wandb import evaluate_main\n",
    "from new_module.locate.new_locate_utils import LocateMachine\n",
    "from new_module.locate.locate_utils import locate_main\n",
    "from new_module.utils.robertacustom import RobertaCustomForSequenceClassification\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(os.environ.get(\"LOGGING_LEVEL\", logging.DEBUG))\n",
    "import joblib\n",
    "config = joblib.load('config.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1830\n",
      "https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhayleyson\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "Popen(['git', 'cat-file', '--batch-check'], cwd=/data/hyeryung/mucoco, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/hyeryung/mucoco/wandb/run-20240409_091728-oqxjgbse</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hayleyson/toxicity-decoding/runs/oqxjgbse' target=\"_blank\">sandy-frost-185</a></strong> to <a href='https://wandb.ai/hayleyson/toxicity-decoding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hayleyson/toxicity-decoding' target=\"_blank\">https://wandb.ai/hayleyson/toxicity-decoding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hayleyson/toxicity-decoding/runs/oqxjgbse' target=\"_blank\">https://wandb.ai/hayleyson/toxicity-decoding/runs/oqxjgbse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): huggingface.co:443\n",
      "https://huggingface.co:443 \"HEAD /gpt2-large/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /gpt2-large/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /gpt2-large/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "main_start_time = time.time()\n",
    "\n",
    "if not config.get(\"model_tag\", None):\n",
    "    if \"energy-training\" in config[\"model_paths\"][1]:\n",
    "        config[\"model_tag\"] = \"em\"\n",
    "    else:\n",
    "        config[\"model_tag\"] = \"clsf\"\n",
    "\n",
    "    if (config[\"task\"] == \"formality\") and (\"gyafc\" in config[\"model_paths\"][1]):\n",
    "        config[\"model_tag\"] += \"-gyafc\"\n",
    "\n",
    "if config[\"resume\"]:\n",
    "    logger.info(\"resuming from a previous run\")\n",
    "    run = wandb.init(\n",
    "        project=config[\"wandb_project\"],\n",
    "        entity=config[\"wandb_entity\"],\n",
    "        id=config[\"wandb_run_id\"],\n",
    "        resume=\"must\",\n",
    "    )\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        project=config[\"wandb_project\"],\n",
    "        entity=config[\"wandb_entity\"],\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "run_id = run.path.split(\"/\")[-1]\n",
    "display_name = f\"{run_id}\"\n",
    "\n",
    "\n",
    "outdir = os.path.join(config[\"output_dir_prefix\"], display_name)\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "outfile = f\"{outdir}/outputs_epsilon{config['min_epsilons'][0]}.txt\"\n",
    "run.summary[\"outfile_path\"] = outfile\n",
    "\n",
    "\n",
    "class dummyArgs:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "build_loss_args = dummyArgs(**config[\"build_loss_dict\"])\n",
    "\n",
    "## load data\n",
    "if (config[\"task\"] == \"toxicity\") or (config[\"task\"] == \"sentiment\"):\n",
    "    source_dataset = [\n",
    "        json.loads(l)[config[\"jsonl_primary_key\"]][config[\"jsonl_secondary_key\"]]\n",
    "        for l in open(config[\"source_data\"])\n",
    "    ]\n",
    "    generation_dataset = [\n",
    "        json.loads(l)[\"generations\"] for l in open(config[\"source_data\"])\n",
    "    ]\n",
    "elif (config[\"task\"] == \"formality\") or (config[\"task\"] == \"sentiment-lewis-compr\"):\n",
    "    with open(config[\"source_data\"], \"r\") as f:\n",
    "        generation_dataset = [line.rstrip('\\n') for line in f.readlines()]\n",
    "    source_dataset = [\"\" for l in generation_dataset]\n",
    "\n",
    "# check if outfile exists\n",
    "if (config[\"resume\"]) and (os.path.exists(outfile)):\n",
    "\n",
    "    with open(outfile, \"r\") as f:\n",
    "        existing_gens = [x.rstrip(\"\\n\") for x in f.readlines()]\n",
    "    resume_idx = len(existing_gens)\n",
    "    if resume_idx == len(source_dataset):\n",
    "        logger.debug(\"output file is already complete. skipping this run.\")\n",
    "        raise\n",
    "    elif resume_idx < len(source_dataset):\n",
    "        logger.info(\n",
    "            f\"output file already exists but is incomplete. resuming from index: {resume_idx}\"\n",
    "        )\n",
    "        outf = open(outfile, \"a\")\n",
    "        int_outf = open(outfile+\".intermediate\", \"a\")\n",
    "    else:\n",
    "        logger.critical(\n",
    "            f\"output file seems to be corrupted. The file length is {resume_idx}, where the size of source_dataset is {len(source_dataset)}\"\n",
    "        )\n",
    "        raise\n",
    "else:\n",
    "    resume_idx = 0\n",
    "    outf = open(outfile, \"w\")\n",
    "    int_outf = open(outfile+\".intermediate\", \"w\")\n",
    "\n",
    "\n",
    "## load tokenizer, models, define losses\n",
    "name2tokenizer = {}\n",
    "name2model = {}\n",
    "name2config = {}\n",
    "loss2tokenizer = {}\n",
    "embed_luts = []\n",
    "\n",
    "for i, model_path in enumerate(config[\"model_paths\"]):\n",
    "    if (\n",
    "        model_path not in name2model\n",
    "    ):  # making sure we are not loading the model twice in case some constraints use the same model.\n",
    "        try:\n",
    "            name2tokenizer[config[\"tokenizer_paths\"][i]] = AutoTokenizer.from_pretrained(\n",
    "                config[\"tokenizer_paths\"][i],\n",
    "                cache_dir=config[\"cache_dir\"],\n",
    "                use_fast=True,\n",
    "            )\n",
    "        except:\n",
    "            name2tokenizer[config[\"tokenizer_paths\"][i]] = AutoTokenizer.from_pretrained(\n",
    "                config[\"tokenizer_paths\"][i],\n",
    "                cache_dir=config[\"cache_dir\"],\n",
    "                use_fast=False,\n",
    "            )\n",
    "\n",
    "        name2config[model_path] = AutoConfig.from_pretrained(\n",
    "            model_path, cache_dir=config[\"cache_dir\"]\n",
    "        )\n",
    "\n",
    "        if config[\"model_types\"][i] == \"RobertaCustomForSequenceClassification\":\n",
    "            name2model[model_path] = lossbuilder.ModelWrapper(\n",
    "                RobertaCustomForSequenceClassification.from_pretrained(\n",
    "                    model_path,\n",
    "                    config=name2config[model_path],\n",
    "                    cache_dir=config[\"cache_dir\"],\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            name2model[model_path] = lossbuilder.ModelWrapper(\n",
    "                getattr(transformers, config[\"model_types\"][i]).from_pretrained(\n",
    "                    model_path,\n",
    "                    config=name2config[model_path],\n",
    "                    cache_dir=config[\"cache_dir\"],\n",
    "                )\n",
    "            )\n",
    "        name2model[model_path].eval()\n",
    "        name2model[model_path].to(config['device'])\n",
    "\n",
    "    input_embeds = name2model[model_path].get_input_embeddings()\n",
    "    if isinstance(input_embeds, torch.nn.Sequential):\n",
    "        input_embeds = input_embeds[0]\n",
    "    embed_luts.append(input_embeds)\n",
    "\n",
    "    if config[\"target_type\"] == \"embeds\":\n",
    "        embed_luts[-1].requires_grad = False\n",
    "\n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "mlm = None if config[\"method\"] == \"mlm-beamsearch-v2\" else AutoModelForMaskedLM.from_pretrained(\"roberta-base\").to(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lossfns = []\n",
    "for i, loss in enumerate(config[\"losses\"]):\n",
    "    lossfns.append(\n",
    "        lossbuilder.build_loss(\n",
    "            loss,\n",
    "            name2model[config[\"model_paths\"][i]],\n",
    "            name2tokenizer[config[\"tokenizer_paths\"][i]],\n",
    "            build_loss_args,\n",
    "        )\n",
    "    )\n",
    "    lossfns[i].tokenizer.add_special_tokens({\"mask_token\": mlm_tokenizer.mask_token})\n",
    "    loss2tokenizer[loss] = lossfns[i].tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_weights = [1 - wandb.config.closs_weight, wandb.config.closs_weight]\n",
    "interrupted = False\n",
    "# for text_id in range(len(source_dataset))[resume_idx:]:\n",
    "text_id = 0\n",
    "source_text = source_dataset[text_id]\n",
    "if source_text == \"\":\n",
    "    source_text = lossfns[0].tokenizer.bos_token\n",
    "\n",
    "if (config[\"task\"] == \"toxicity\") or (config[\"task\"] == \"sentiment\"):\n",
    "    AR_prediction_all = [x[\"text\"] for x in generation_dataset[text_id]]\n",
    "    # predicted_batches = [x[\"tokens\"] for x in generation_dataset[text_id]]\n",
    "    # predicted_batches = [\n",
    "    #     torch.tensor([x], dtype=torch.long, device=config[\"device\"])\n",
    "    #     for x in predicted_batches\n",
    "    # ]\n",
    "    \n",
    "elif (config[\"task\"] == \"formality\") or (\n",
    "    config[\"task\"] == \"sentiment-lewis-compr\"\n",
    "):\n",
    "    AR_prediction_all = [generation_dataset[text_id]]\n",
    "\n",
    "curr_num_samples = len(AR_prediction_all)\n",
    "\n",
    "curr_loss = torch.zeros(len(AR_prediction_all)).to(config['device'])\n",
    "logging_loss = torch.zeros((len(AR_prediction_all),2)).to(config['device'])\n",
    "edit_yn = torch.ones(len(AR_prediction_all), dtype=torch.bool).to(config['device'])\n",
    "        \n",
    "for lossid, lossname in enumerate(config[\"losses\"]):\n",
    "    with torch.no_grad():\n",
    "        lossvalue = lossfns[lossid].compute_gold_loss(\n",
    "            source_text, AR_prediction_all,\n",
    "            label_id=config['target_label_ids'][lossid],\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "    curr_loss += loss_weights[lossid] * lossvalue\n",
    "    logging_loss[:, lossid] = lossvalue.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define an object to locate problematic phrases\n",
    "locator = LocateMachine(lossfns[1].model, lossfns[1].tokenizer)\n",
    "\n",
    "label_ids = config[\"target_label_ids\"]  # target label's ids for each loss\n",
    "\n",
    "run.summary[\"prep_time\"] = time.time() - main_start_time\n",
    "## beginning of main logic\n",
    "decode_start_time = time.time()\n",
    "# text_id = 0\n",
    "if config[\"resume\"]:\n",
    "    num_skipped = run.summary.get(\"num_skipped\", 0)\n",
    "    num_edited = run.summary.get(\"num_edited\", 0)\n",
    "    num_decoded_tokens = run.summary.get(\"num_decoded_tokens\", 0)\n",
    "else:\n",
    "    num_skipped = 0\n",
    "    num_edited = 0\n",
    "    num_decoded_tokens = 0\n",
    "\n",
    "\n",
    "loss_weights = [1 - wandb.config.closs_weight, wandb.config.closs_weight]\n",
    "interrupted = False\n",
    "# for text_id in range(len(source_dataset))[resume_idx:]:\n",
    "text_id = 0\n",
    "source_text = source_dataset[text_id]\n",
    "if source_text == \"\":\n",
    "    source_text = lossfns[0].tokenizer.bos_token\n",
    "\n",
    "if (config[\"task\"] == \"toxicity\") or (config[\"task\"] == \"sentiment\"):\n",
    "    AR_prediction_all = [x[\"text\"] for x in generation_dataset[text_id]]\n",
    "    # predicted_batches = [x[\"tokens\"] for x in generation_dataset[text_id]]\n",
    "    # predicted_batches = [\n",
    "    #     torch.tensor([x], dtype=torch.long, device=config[\"device\"])\n",
    "    #     for x in predicted_batches\n",
    "    # ]\n",
    "    \n",
    "elif (config[\"task\"] == \"formality\") or (\n",
    "    config[\"task\"] == \"sentiment-lewis-compr\"\n",
    "):\n",
    "    AR_prediction_all = [generation_dataset[text_id]]\n",
    "\n",
    "curr_num_samples = len(AR_prediction_all)\n",
    "\n",
    "       \n",
    "running_text = best_text = deepcopy(AR_prediction_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_text = locator.locate_main(running_text, \n",
    "                        method = config['locate_method'], \n",
    "                        max_num_tokens = wandb.config.num_edit_token_per_step, \n",
    "                        unit = config['locate_unit'], \n",
    "                        num_layer = -2, #penultimate\n",
    "                        label_id = config['target_label_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace tokens at the indices with mask tokens\n",
    "                \n",
    "inputs = mlm_tokenizer(\n",
    "    masked_text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "inputs = inputs.to(config['device']) \n",
    "masked_sequence=inputs['input_ids']\n",
    "\n",
    "\n",
    "## make predictions for the masked indices\n",
    "with torch.no_grad():\n",
    "    logits = mlm(**inputs).logits\n",
    "\n",
    "special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "logits[:, :, special_token_ids] = -float(\"inf\")\n",
    "\n",
    "\n",
    "indices_in_mlm_tokens = (\n",
    "    inputs.input_ids == mlm_tokenizer.mask_token_id\n",
    ").nonzero(as_tuple=True)\n",
    "\n",
    "## get top k tokens for each index\n",
    "predicted_token_ids = torch.topk(\n",
    "    logits[indices_in_mlm_tokens[0], indices_in_mlm_tokens[1], :],\n",
    "    k=config['k_per_location'],\n",
    "    dim=-1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([ 7, 11, 16, 17, 18, 24,  4,  7, 10, 11, 19, 20, 32, 33, 34],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_in_mlm_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[15.873, 15.323, 15.225, 14.497, 13.819, 13.768, 13.668, 13.610, 13.591,\n",
       "         13.532],\n",
       "        [16.084, 14.017, 13.802, 13.463, 13.243, 13.119, 12.944, 12.736, 12.726,\n",
       "         12.509],\n",
       "        [13.976, 13.951, 13.586, 13.123, 12.936, 12.907, 12.618, 12.576, 12.389,\n",
       "         12.001],\n",
       "        [13.024, 12.771, 12.487, 12.358, 12.161, 12.140, 12.063, 11.893, 11.850,\n",
       "         11.711],\n",
       "        [19.656, 15.377, 13.710, 12.652, 12.214, 11.788, 11.575, 11.137, 11.029,\n",
       "         10.996],\n",
       "        [17.550, 15.963, 15.902, 15.694, 15.647, 15.253, 14.809, 14.134, 14.113,\n",
       "         14.093],\n",
       "        [14.363, 13.436, 13.361, 12.893, 12.522, 12.464, 12.321, 12.178, 12.031,\n",
       "         12.012],\n",
       "        [14.046, 13.532, 12.594, 12.472, 12.042, 11.971, 11.491, 11.430, 11.399,\n",
       "         11.374],\n",
       "        [15.141, 13.798, 13.274, 13.216, 13.098, 13.055, 13.001, 12.656, 12.628,\n",
       "         12.502],\n",
       "        [13.540, 12.035, 11.279, 10.751,  9.803,  9.763,  9.549,  9.433,  9.333,\n",
       "          9.217],\n",
       "        [15.362, 15.195, 14.715, 14.530, 14.451, 13.890, 13.872, 13.601, 13.488,\n",
       "         13.362],\n",
       "        [17.135, 12.983, 12.517, 12.347, 12.244, 12.154, 11.956, 11.674, 11.251,\n",
       "         11.042],\n",
       "        [13.140, 13.102, 12.391, 12.138, 11.281, 10.910, 10.851, 10.747, 10.302,\n",
       "         10.202],\n",
       "        [10.875,  9.223,  9.040,  8.359,  8.329,  8.245,  7.968,  7.907,  7.899,\n",
       "          7.781],\n",
       "        [12.388,  9.648,  8.532,  8.324,  8.293,  8.144,  8.072,  7.843,  7.672,\n",
       "          7.660]], device='cuda:0'),\n",
       "indices=tensor([[   82,    47,   106,   201,   390,  1652,  1159,  2799, 28263, 21304],\n",
       "        [ 5458,   402,  1126,  4158,  1789,   982,  2127,  2878,  4215,   749],\n",
       "        [  697,   582,   213,   173,  3116,  1032,   432,  2807,   120,   244],\n",
       "        [   13,  2512,    19,    62,     7,   149,    66,    31,    11,  2185],\n",
       "        [    4,   116,   328,  1174,   734,   479,  1555,  1666,    72,     6],\n",
       "        [  109,   146,  1032,  4190,  3116,   652,  2073,   697,   907,  1166],\n",
       "        [  596,  9069,  2143, 14223,  1840,   141, 15410,   117, 30722,    30],\n",
       "        [  596,   203,     6,  7105, 26536,  9069,   141, 34912,  2143,  1840],\n",
       "        [  907,    28,   120, 16531,   109, 17605,  3529,  3211, 10064,   657],\n",
       "        [   24,   402,    55,    62,   357,  2185, 24217,     6,   106,    42],\n",
       "        [ 2888,  2441,  1012,  2014,   340,  3742,  1400, 15263,  3748,  2384],\n",
       "        [    6,   111,    93,   126,   734,  1555,  1174,   480,  2441,  1400],\n",
       "        [   45,   416,    10,    98,     5,    41,   202,    11,   350,  4940],\n",
       "        [    4,    24, 12103,   328, 30603,    65,    89,  1050,     7,  2378],\n",
       "        [    4,   328,    35,    24, 44660,    43,   734,  1592, 46225,   322]],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' dirt. Unfortunately the majority of<mask> end up in<mask> that you had to<mask><mask><mask> My only recourse is to<mask> it myself. What would be the happy tale of my life then?',\n",
       " ' wearing games and<mask> ****ing<mask> do I hate horse wearing games.',\n",
       " \" fetishes: it just makes me want to<mask><mask> every time I see it on the<mask><mask> even though it's not worth a thing because I am<mask><mask><mask>\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace tokens at the indices with mask tokens\n",
    "\n",
    "indices_in_mlm_tokens_old = []\n",
    "predicted_token_ids_old = []\n",
    "for masked_text_ in masked_text:\n",
    "    \n",
    "    ## replace tokens at the indices with mask tokens\n",
    "    inputs_old = mlm_tokenizer(\n",
    "        masked_text_, return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs_old = inputs_old.to(config['device'])\n",
    "    ## make predictions for the masked indices\n",
    "    with torch.no_grad():\n",
    "        logits_old = mlm(**inputs_old).logits\n",
    "    indices_in_mlm_tokens_old_ = (\n",
    "        inputs_old.input_ids == mlm_tokenizer.mask_token_id\n",
    "    )[0].nonzero(as_tuple=True)[0]\n",
    "    # print(f\"indices_in_mlm_tokens: {indices_in_mlm_tokens}\")\n",
    "    ## get top k tokens for each index\n",
    "    \n",
    "    ## make logits for special tokens -inf.\n",
    "    special_token_ids = mlm_tokenizer.convert_tokens_to_ids(mlm_tokenizer.all_special_tokens)\n",
    "    logits_old[:, :, special_token_ids] = -np.inf\n",
    "    \n",
    "    predicted_token_ids_old_ = torch.topk(\n",
    "        logits_old[0, indices_in_mlm_tokens_old_],\n",
    "        k=wandb.config.k_per_location,\n",
    "        dim=-1,\n",
    "    )\n",
    "    indices_in_mlm_tokens_old.append(indices_in_mlm_tokens_old_)\n",
    "    predicted_token_ids_old.append(predicted_token_ids_old_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([ 7, 11, 16, 17, 18, 24,  4,  7, 10, 11, 19, 20, 32, 33, 34],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_in_mlm_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 7, 11, 16, 17, 18, 24], device='cuda:0'),\n",
       " tensor([4, 7], device='cuda:0'),\n",
       " tensor([10, 11, 19, 20, 32, 33, 34], device='cuda:0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_in_mlm_tokens_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   82,    47,   106,   201,   390,  1652,  1159,  2799, 28263, 21304],\n",
       "        [ 5458,   402,  1126,  4158,  1789,   982,  2127,  2878,  4215,   749],\n",
       "        [  697,   582,   213,   173,  3116,  1032,   432,  2807,   120,   244],\n",
       "        [   13,  2512,    19,    62,     7,   149,    66,    31,    11,  2185],\n",
       "        [    4,   116,   328,  1174,   734,   479,  1555,  1666,    72,     6],\n",
       "        [  109,   146,  1032,  4190,  3116,   652,  2073,   697,   907,  1166],\n",
       "        [  596,  9069,  2143, 14223,  1840,   141, 15410,   117, 30722,    30],\n",
       "        [  596,   203,     6,  7105, 26536,  9069,   141, 34912,  2143,  1840],\n",
       "        [  907,    28,   120, 16531,   109, 17605,  3529,  3211, 10064,   657],\n",
       "        [   24,   402,    55,    62,   357,  2185, 24217,     6,   106,    42],\n",
       "        [ 2888,  2441,  1012,  2014,   340,  3742,  1400, 15263,  3748,  2384],\n",
       "        [    6,   111,    93,   126,   734,  1555,  1174,   480,  2441,  1400],\n",
       "        [   45,   416,    10,    98,     5,    41,   202,    11,   350,  4940],\n",
       "        [    4,    24, 12103,   328, 30603,    65,    89,  1050,     7,  2378],\n",
       "        [    4,   328,    35,    24, 44660,    43,   734,  1592, 46225,   322]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x.indices for x in predicted_token_ids_old],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   82,    47,   106,   201,   390,  1652,  1159,  2799, 28263, 21304],\n",
       "        [ 5458,   402,  1126,  4158,  1789,   982,  2127,  2878,  4215,   749],\n",
       "        [  697,   582,   213,   173,  3116,  1032,   432,  2807,   120,   244],\n",
       "        [   13,  2512,    19,    62,     7,   149,    66,    31,    11,  2185],\n",
       "        [    4,   116,   328,  1174,   734,   479,  1555,  1666,    72,     6],\n",
       "        [  109,   146,  1032,  4190,  3116,   652,  2073,   697,   907,  1166],\n",
       "        [  596,  9069,  2143, 14223,  1840,   141, 15410,   117, 30722,    30],\n",
       "        [  596,   203,     6,  7105, 26536,  9069,   141, 34912,  2143,  1840],\n",
       "        [  907,    28,   120, 16531,   109, 17605,  3529,  3211, 10064,   657],\n",
       "        [   24,   402,    55,    62,   357,  2185, 24217,     6,   106,    42],\n",
       "        [ 2888,  2441,  1012,  2014,   340,  3742,  1400, 15263,  3748,  2384],\n",
       "        [    6,   111,    93,   126,   734,  1555,  1174,   480,  2441,  1400],\n",
       "        [   45,   416,    10,    98,     5,    41,   202,    11,   350,  4940],\n",
       "        [    4,    24, 12103,   328, 30603,    65,    89,  1050,     7,  2378],\n",
       "        [    4,   328,    35,    24, 44660,    43,   734,  1592, 46225,   322]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_ids.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x.indices for x in predicted_token_ids_old],dim=0) == predicted_token_ids.indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc-edit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
