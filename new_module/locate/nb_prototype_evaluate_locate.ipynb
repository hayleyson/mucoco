{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7a97b9a0-ba55-47b0-8e16-f7706480e0ef",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Prototyping code for evaluating the accuracy of locating tokens to edit against ground truth.\n",
    "For metrics, MRR (mean reciprocal rank),Average Precision,and F1 score is used.\n",
    "Other candidate metrics include AUC and Recall @ K.\n",
    "The unit of calculating the metric is \"token\" at the moment.\n",
    "But it will expand to \"character\" and \"word\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fcc9928-ae73-4d42-9454-d1dd00cc7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/s3/hyeryung/mucoco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e321d5-5442-4ed0-9b40-161d13b1ac00",
   "metadata": {},
   "source": [
    "### Prepare dataset (predictions & labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "438ed037-4864-4b8d-9ae8-80a9ec0b8f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read predicted file\n",
    "pred_path = \"new_module/data/toxicity-avoidance/testset_gpt2_2500_locate_grad.jsonl\"\n",
    "predictions = pd.read_json(pred_path, lines=True)\n",
    "\n",
    "predictions = predictions[['prompt','text','pred_indices_grad_norm', 'pred_scores_grad_norm']].copy()\n",
    "predictions = predictions.rename(columns={'pred_indices_grad_norm':'pred',\n",
    "                                         'pred_scores_grad_norm':'pred_scores'})\n",
    "\n",
    "## clean text column -> remove \"<|endoftext|>\" text\n",
    "predictions['text']=predictions['text'].str.replace(\"<|endoftext|>\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5534cb77-dcc4-4a5e-b152-50540f1e47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read ground truth file\n",
    "label_path = \"new_module/data/toxicity-avoidance/testset_gpt2_2500.jsonl\"\n",
    "labels = pd.read_json(label_path, lines=True)\n",
    "\n",
    "## unravel the file \n",
    "labels['prompt']=labels['prompt'].apply(lambda x: x['text'])\n",
    "\n",
    "labels = labels.explode('generations')\n",
    "\n",
    "labels['text']=labels['generations'].apply(lambda x: x['text'])\n",
    "labels['tokens']=labels['generations'].apply(lambda x: x['tokens'])\n",
    "\n",
    "labels['locate_labels']=labels['generations'].apply(lambda x: x.get('locate_labels', np.nan))\n",
    "\n",
    "del labels['generations']\n",
    "\n",
    "labels = labels.rename(columns={'locate_labels':'labels'})\n",
    "labels = labels.dropna(subset='labels')\n",
    "\n",
    "## correct minor errors -> remove trailing pad_token in the generations.\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/shared/s3/lab07/hyeryung/loc_edit/roberta-base-jigsaw-toxicity-classifier-with-gpt2-large-embeds-energy-training/step_2800_best_checkpoint\")\n",
    "def count_pad_token(x):\n",
    "    return np.sum(np.array(x)==tokenizer.pad_token_id)\n",
    "def remove_pad_token(x):\n",
    "    return list(np.array(x)[np.array(x)!=tokenizer.pad_token_id])\n",
    "def remove_label_for_pad_token(row, colname):\n",
    "    return list(np.array(row[colname])[np.array(row['tokens'])!=tokenizer.pad_token_id])\n",
    "## \n",
    "# tokens\n",
    "# 0    111\n",
    "# 1      3\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "has_pad_token = labels['tokens'].apply(count_pad_token) > 0\n",
    "labels.loc[has_pad_token, 'labels'] = labels.loc[has_pad_token,:].apply(lambda x: remove_label_for_pad_token(x, 'labels'),axis=1).values\n",
    "labels.loc[has_pad_token, 'tokens'] = labels.loc[has_pad_token, 'tokens'].apply(remove_pad_token)\n",
    "\n",
    "# del labels['tokens']\n",
    "\n",
    "## similarly, clean text column -> remove \"<|endoftext|>\" text\n",
    "labels['text']=labels['text'].str.replace(\"<|endoftext|>\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afd186d1-475c-4728-94df-7605b5b545e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## join predictions & labels \n",
    "predictions = pd.merge(predictions, labels, on=['prompt','text'],how='left')\n",
    "predictions = predictions.drop_duplicates(subset=['prompt','text'],keep=False)\n",
    "\n",
    "## duplicate existed. -> erroneous -> removed\n",
    "## predictions.loc[predictions['prompt']==\"According to the criminal complaint, Edah kicked the child's foot and hit her hand in a classroom at P.S. 76\"]\n",
    "# \tprompt\tgen\tlocated_indices\tlocate_labels\n",
    "# 68\tAccording to the criminal complaint, Edah kick...\t. He continued to hit the child with his shoes...\t[9, 11]\t[0, 0, 0, 0, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 1, 0]\n",
    "# 69\tAccording to the criminal complaint, Edah kick...\t.\t[]\t[]\n",
    "# 70\tAccording to the criminal complaint, Edah kick...\t.\t[]\t[0]\n",
    "# 71\tAccording to the criminal complaint, Edah kick...\t.\t[]\t[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a107bb88-5a6b-4f0f-866a-1e5984ead26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_scores</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me just start by saying I hate horse</td>\n",
       "      <td>wearing games and holy ****ing shit do I hate ...</td>\n",
       "      <td>[0, 1, 3, 6]</td>\n",
       "      <td>[0.071512118, 0.0715002939, 0.0, 0.0715443864,...</td>\n",
       "      <td>[5762, 1830, 290, 11386, 25998, 278, 7510, 466...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A convicted German criminal known as the “broo...</td>\n",
       "      <td>using a fake penis to blackmail a woman over t...</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>[0.0625393689, 0.06213719400000001, 0.06333862...</td>\n",
       "      <td>[1262, 257, 8390, 16360, 284, 32625, 257, 2415...</td>\n",
       "      <td>[0, 0, 0.6666666666666661, 0.6666666666666661,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“When I graduate with a PhD, I won’t even</td>\n",
       "      <td>bother with those damn students‛.</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[0.124858886, 0.1245534196, 0.124941431, 0.126...</td>\n",
       "      <td>[11393, 351, 883, 12270, 2444, 447, 249, 13]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want an actual “thug” perspective on fo...</td>\n",
       "      <td>the fact that the word Black‏ella’ hates on ʳC...</td>\n",
       "      <td>[12, 17, 18, 19, 20, 21]</td>\n",
       "      <td>[0.0268657655, 0.025949863700000003, 0.0255995...</td>\n",
       "      <td>[262, 1109, 326, 262, 1573, 2619, 447, 237, 12...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Or rather, he was upset that the students on t...</td>\n",
       "      <td>wanted to die and kill now. He was worried abo...</td>\n",
       "      <td>[0, 1, 2, 4, 5, 9]</td>\n",
       "      <td>[0.0314874984, 0.0322747119, 0.0320502259, 0.0...</td>\n",
       "      <td>[2227, 284, 4656, 290, 1494, 783, 13, 679, 373...</td>\n",
       "      <td>[0.33333333333333304, 0.33333333333333304, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0           Let me just start by saying I hate horse   \n",
       "1  A convicted German criminal known as the “broo...   \n",
       "2          “When I graduate with a PhD, I won’t even   \n",
       "3  If you want an actual “thug” perspective on fo...   \n",
       "4  Or rather, he was upset that the students on t...   \n",
       "\n",
       "                                                text  \\\n",
       "0  wearing games and holy ****ing shit do I hate ...   \n",
       "1  using a fake penis to blackmail a woman over t...   \n",
       "2                  bother with those damn students‛.   \n",
       "3  the fact that the word Black‏ella’ hates on ʳC...   \n",
       "4  wanted to die and kill now. He was worried abo...   \n",
       "\n",
       "                       pred  \\\n",
       "0              [0, 1, 3, 6]   \n",
       "1                 [2, 3, 4]   \n",
       "2                    [3, 4]   \n",
       "3  [12, 17, 18, 19, 20, 21]   \n",
       "4        [0, 1, 2, 4, 5, 9]   \n",
       "\n",
       "                                         pred_scores  \\\n",
       "0  [0.071512118, 0.0715002939, 0.0, 0.0715443864,...   \n",
       "1  [0.0625393689, 0.06213719400000001, 0.06333862...   \n",
       "2  [0.124858886, 0.1245534196, 0.124941431, 0.126...   \n",
       "3  [0.0268657655, 0.025949863700000003, 0.0255995...   \n",
       "4  [0.0314874984, 0.0322747119, 0.0320502259, 0.0...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [5762, 1830, 290, 11386, 25998, 278, 7510, 466...   \n",
       "1  [1262, 257, 8390, 16360, 284, 32625, 257, 2415...   \n",
       "2       [11393, 351, 883, 12270, 2444, 447, 249, 13]   \n",
       "3  [262, 1109, 326, 262, 1573, 2619, 447, 237, 12...   \n",
       "4  [2227, 284, 4656, 290, 1494, 783, 13, 679, 373...   \n",
       "\n",
       "                                              labels  \n",
       "0         [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0.6666666666666661, 0.6666666666666661,...  \n",
       "2                           [0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0.33333333333333304, 0.33333333333333304, 0.3...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a656ba7-a86a-4906-a238-2a420e343d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## double check that there's no rows with mismatched length of labels and predictions\n",
    "assert len(predictions.loc[predictions['labels'].apply(len) != predictions['pred_scores'].apply(len), :])==0\n",
    "\n",
    "# index=103\n",
    "# print(len(predictions.loc[index,'tokens']))\n",
    "# print(len(predictions.loc[index,'pred_scores']))\n",
    "# print(len(predictions.loc[index,'labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de99fe05-55c9-4bdc-92a6-8e5d6d1396ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert list of indices into a list of binary labels of length len(seq)\n",
    "def index2binary(row):\n",
    "    return [1 if i in row['pred'] else 0 for i in range(len(row['labels']))]\n",
    "    \n",
    "predictions['pred_binary']=predictions.apply(index2binary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12fffe62-fd03-4111-a678-27a31a80d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## binarize labels \n",
    "predictions['labels_binary'] = predictions['labels'].apply(lambda x: [1 if i >= 0.5 else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "990ac33c-67e8-46b3-83eb-96b48f6fca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_scores</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pred_binary</th>\n",
       "      <th>labels_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me just start by saying I hate horse</td>\n",
       "      <td>wearing games and holy ****ing shit do I hate ...</td>\n",
       "      <td>[0, 1, 3, 6]</td>\n",
       "      <td>[0.071512118, 0.0715002939, 0.0, 0.0715443864,...</td>\n",
       "      <td>[5762, 1830, 290, 11386, 25998, 278, 7510, 466...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A convicted German criminal known as the “broo...</td>\n",
       "      <td>using a fake penis to blackmail a woman over t...</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>[0.0625393689, 0.06213719400000001, 0.06333862...</td>\n",
       "      <td>[1262, 257, 8390, 16360, 284, 32625, 257, 2415...</td>\n",
       "      <td>[0, 0, 0.6666666666666661, 0.6666666666666661,...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“When I graduate with a PhD, I won’t even</td>\n",
       "      <td>bother with those damn students‛.</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[0.124858886, 0.1245534196, 0.124941431, 0.126...</td>\n",
       "      <td>[11393, 351, 883, 12270, 2444, 447, 249, 13]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want an actual “thug” perspective on fo...</td>\n",
       "      <td>the fact that the word Black‏ella’ hates on ʳC...</td>\n",
       "      <td>[12, 17, 18, 19, 20, 21]</td>\n",
       "      <td>[0.0268657655, 0.025949863700000003, 0.0255995...</td>\n",
       "      <td>[262, 1109, 326, 262, 1573, 2619, 447, 237, 12...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Or rather, he was upset that the students on t...</td>\n",
       "      <td>wanted to die and kill now. He was worried abo...</td>\n",
       "      <td>[0, 1, 2, 4, 5, 9]</td>\n",
       "      <td>[0.0314874984, 0.0322747119, 0.0320502259, 0.0...</td>\n",
       "      <td>[2227, 284, 4656, 290, 1494, 783, 13, 679, 373...</td>\n",
       "      <td>[0.33333333333333304, 0.33333333333333304, 0.3...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0           Let me just start by saying I hate horse   \n",
       "1  A convicted German criminal known as the “broo...   \n",
       "2          “When I graduate with a PhD, I won’t even   \n",
       "3  If you want an actual “thug” perspective on fo...   \n",
       "4  Or rather, he was upset that the students on t...   \n",
       "\n",
       "                                                text  \\\n",
       "0  wearing games and holy ****ing shit do I hate ...   \n",
       "1  using a fake penis to blackmail a woman over t...   \n",
       "2                  bother with those damn students‛.   \n",
       "3  the fact that the word Black‏ella’ hates on ʳC...   \n",
       "4  wanted to die and kill now. He was worried abo...   \n",
       "\n",
       "                       pred  \\\n",
       "0              [0, 1, 3, 6]   \n",
       "1                 [2, 3, 4]   \n",
       "2                    [3, 4]   \n",
       "3  [12, 17, 18, 19, 20, 21]   \n",
       "4        [0, 1, 2, 4, 5, 9]   \n",
       "\n",
       "                                         pred_scores  \\\n",
       "0  [0.071512118, 0.0715002939, 0.0, 0.0715443864,...   \n",
       "1  [0.0625393689, 0.06213719400000001, 0.06333862...   \n",
       "2  [0.124858886, 0.1245534196, 0.124941431, 0.126...   \n",
       "3  [0.0268657655, 0.025949863700000003, 0.0255995...   \n",
       "4  [0.0314874984, 0.0322747119, 0.0320502259, 0.0...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [5762, 1830, 290, 11386, 25998, 278, 7510, 466...   \n",
       "1  [1262, 257, 8390, 16360, 284, 32625, 257, 2415...   \n",
       "2       [11393, 351, 883, 12270, 2444, 447, 249, 13]   \n",
       "3  [262, 1109, 326, 262, 1573, 2619, 447, 237, 12...   \n",
       "4  [2227, 284, 4656, 290, 1494, 783, 13, 679, 373...   \n",
       "\n",
       "                                              labels  \\\n",
       "0         [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0.6666666666666661, 0.6666666666666661,...   \n",
       "2                           [0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0.33333333333333304, 0.33333333333333304, 0.3...   \n",
       "\n",
       "                                         pred_binary  \\\n",
       "0         [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1   [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                           [0, 0, 0, 1, 1, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "4  [1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                       labels_binary  \n",
       "0         [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1   [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2                           [0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "25521d34-5fc7-47c5-b937-ba15f7f3aa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "23.104347826086958\n",
      "4.113043478260869\n",
      "93.6\n",
      "18.660869565217393\n",
      "17.16521739130435\n",
      "3.226086956521739\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape[0])\n",
    "print(predictions['tokens'].apply(len).mean())\n",
    "print(predictions['labels_binary'].apply(sum).mean())\n",
    "print(predictions['char'].apply(len).mean())\n",
    "print(predictions['labels_char_binary'].apply(sum).mean())\n",
    "print(predictions['words'].apply(len).mean())\n",
    "print(predictions['labels_word_binary'].apply(sum).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f332cf7-7a80-4d88-bb8e-141deba50bf9",
   "metadata": {},
   "source": [
    "### Calculate Token-level Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c63dd449-60ce-42d9-a157-d2d2d2abb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1-score\n",
    "from sklearn.metrics import f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "def apply_f1(row):\n",
    "    return f1_score(row['labels_binary'],row['pred_binary'], zero_division=np.nan)\n",
    "    \n",
    "predictions['f1']=predictions.apply(apply_f1,axis=1)\n",
    "\n",
    "def apply_f2(row):\n",
    "    return fbeta_score(row['labels_binary'],row['pred_binary'], beta=2, zero_division=np.nan)\n",
    "    \n",
    "predictions['f2']=predictions.apply(apply_f2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c4a82cf-02c0-4c5d-bb61-2fe3c4b957f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4878977795860248"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34e948da-1b5f-4edc-92a4-2b609b62cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5443033897597268"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['f2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "401ece30-e2c0-4dad-8257-46ad708be100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rr(row):\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "def rr(out, labels, k = 6): #implement mean reciprocal rank\n",
    "    idx_array = stats.rankdata(-out, axis=-1, method='min')\n",
    "    # print(idx_array)\n",
    "    labels = np.where(labels==1)[0].astype(int)\n",
    "    # print(labels)\n",
    "    rank = np.take_along_axis(idx_array, labels, axis=-1)\n",
    "    # print(rank)\n",
    "    rr=1/rank.min() if rank.min() <= k else 0.\n",
    "    return rr\n",
    "def get_rr(row):\n",
    "    if sum(row['labels_binary'])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return rr(np.array(row['pred_scores']),np.array(row['labels_binary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bbc9d31-36eb-465a-8774-aa5f40a26f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['rr']=predictions.apply(get_rr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b400c3b3-abd5-41ca-85f3-745148e090ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948019801980198"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['rr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c58a89-1043-4ce1-aba8-71e9d328b00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ccb4c18c-9ae6-4769-a87a-6db41f1623a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AP\n",
    "from sklearn.metrics import f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "def apply_ap(row):\n",
    "    if sum(row['labels_binary'])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return average_precision_score(row['labels_binary'],row['pred_scores'])\n",
    "    \n",
    "predictions['ap']=predictions.apply(apply_ap,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17194043-5e1b-4d7e-87f5-f2cc5856893a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7970635444988667"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['ap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93baa4d9-b50f-4eda-86f0-60b8d61da272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ea0c59e-debc-42d8-b9e6-22902acbfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary metric\n",
    "## ToDo : double check if mean F1, mean F2 is a thing. -> Not sure.. Ask Jong?\n",
    "## double checked what happens if true label is none. ap -> np.nan, rr -> np.nan, f1 -> np.nan, f2 -> np.nan\n",
    "mf1 = predictions['f1'].mean()\n",
    "mf2 = predictions['f2'].mean()\n",
    "mrr = predictions['rr'].mean()\n",
    "map = predictions['ap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a8c7a07-2261-4f03-8fb2-cdff6f723584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf1: 0.4879, mf2: 0.5443, mrr: 0.9480, map: 0.7971\n"
     ]
    }
   ],
   "source": [
    "print(f\"mf1: {mf1:.4f}, mf2: {mf2:.4f}, mrr: {mrr:.4f}, map: {map:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124b084-e62c-4868-b64d-86f068662d22",
   "metadata": {},
   "source": [
    "# Expand to character & word metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7696092-c1ce-4fa1-b788-8696dada379c",
   "metadata": {},
   "source": [
    "### Token ↔︎ Word ↔︎ Char 이 가능한 mapping 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c3dc126-8ce9-4613-a8c8-009737de084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ToDo : expand to character & word metrics.\n",
    "## word metric\n",
    "## 관련해서 읽었던 literature\n",
    "## Treviso et al. (2021) : since all of our models use subword tokenization, to get explanations for an entire word, we tried aggregating the scores of its word pieces by taking the sum, mean, or max, and we found that taking the sum performs better overall.to get explanations for an entire word we follow Treviso et al and sum the scores of its word pieces.\n",
    "## -> evaluate 방식에 대한 내용이라기 보다, 어떻게 token level의 prediction을 word level로 합쳤는지에 대한 내용임 \n",
    "\n",
    "## 먼저 아래 같은 mapping을 정의한 후 이를 이용하여, pred와 label을 바꾼다.\n",
    "# tok2char=dict(int=tuple)\n",
    "# word2tok=dict(int=tuple)\n",
    "# word2char=dict(int=tuple)\n",
    "# tok2word=dict(int=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e263e1e8-e699-4bb5-bbc8-870178a1ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping 정의 코드\n",
    "sample_text = predictions[['text','tokens']].copy()\n",
    "\n",
    "sample_text['char']=sample_text['text'].apply(list)\n",
    "sample_text['char_index']=sample_text['char'].apply(lambda x: list(range(len(x))))\n",
    "assert (sample_text['char'].apply(len) != sample_text['char_index'].apply(len)).sum() == 0\n",
    "\n",
    "# sample_text['token']=sample_text['text'].apply(lambda x: tokenizer.encode(x,add_special_tokens=False))\n",
    "sample_text['tokens_index']=sample_text['tokens'].apply(lambda x: list(range(len(x))))\n",
    "\n",
    "sample_text['words']=sample_text['text'].str.split()\n",
    "sample_text['words_index']=sample_text['words'].apply(lambda x: list(range(len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "31cd2021-449a-44de-9f3f-b1ced7fbb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tok2char(row: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    A function to convert a list of tokens into a mapping between each token's index and its corresponding character offsets.\n",
    "    @param row: A row from dataframe\n",
    "    @return tok2char: A dictionary with token's location index as keys and tuples of corresponding character offsets as values.\n",
    "\n",
    "    Example:\n",
    "    row=pd.Series()\n",
    "    row['tokens']=[86, 6648, 1830, 290, 11386, 25998, 278, 7510, 466, 314, 5465, 8223, 5762, 1830, 13]\n",
    "    tok2char=get_tok2char(row)\n",
    "    tok2char\n",
    "    {0: (0,),\n",
    "     1: (1, 2, 3, 4, 5, 6),\n",
    "     2: (7, 8, 9, 10, 11, 12),\n",
    "     3: (13, 14, 15, 16),\n",
    "     ...\n",
    "     13: (59, 60, 61, 62, 63, 64),\n",
    "     14: (65,)}\n",
    "    \"\"\"\n",
    "    global tokenizer\n",
    "    \n",
    "    tok2char=dict()\n",
    "    token_offsets=[0]\n",
    "    \n",
    "    for i in range(1,len(row['tokens'])+1):\n",
    "        decoded=tokenizer.decode(row['tokens'][:i])\n",
    "        token_offsets.append(len(decoded))\n",
    "        tok2char[i-1]=tuple(range(token_offsets[i-1],token_offsets[i]))\n",
    "    return tok2char\n",
    "\n",
    "def get_word2char(row: pd.Series, ws: str) -> dict:\n",
    "    \"\"\"\n",
    "    A function to convert a list of words into a mapping between each word's index and its corresponding character offsets.\n",
    "    @param row: A row from dataframe\n",
    "    @return word2char: A dictionary with word's location index as keys and tuples of corresponding character offsets as values.\n",
    "\n",
    "    Caveat:\n",
    "    This code assumes that words are separated by only one type of whitespace, e.g. space.\n",
    "\n",
    "    Example:\n",
    "    row=pd.Series()\n",
    "    row['words']=['wearing', 'games', 'and', 'holy', '****ing', 'shit', 'do', 'I', 'hate', 'horse', 'wearing', 'games.']\n",
    "    word2char=get_word2char(row)\n",
    "    word2char\n",
    "    {0: (0, 1, 2, 3, 4, 5, 6),\n",
    "     1: (7, 8, 9, 10, 11, 12),...\n",
    "     9: (45, 46, 47, 48, 49, 50),\n",
    "     10: (51, 52, 53, 54, 55, 56, 57, 58),\n",
    "     11: (59, 60, 61, 62, 63, 64, 65)}\n",
    "    \"\"\"\n",
    "    \n",
    "    word_offsets=[0]\n",
    "    word2char=dict()\n",
    "    for i in range(1,len(row['words'])+1):\n",
    "        decoded=ws.join(row['words'][:i])\n",
    "        word_offsets.append(len(decoded))\n",
    "        word2char[i-1]=tuple(range(word_offsets[i-1],word_offsets[i]))\n",
    "    return word2char\n",
    "\n",
    "## group token indices that belong to the same word\n",
    "\n",
    "def get_word2tok(row: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    A function that take a list of words and a corresponding list of tokens \n",
    "    into a mapping between each word's index and its corresponding token indexes.\n",
    "    @param row: A row from dataframe\n",
    "    @return word2char: A dictionary with word's location index as keys and tuples of corresponding token location indexes as values.\n",
    "\n",
    "    Example:\n",
    "    row=pd.Series()\n",
    "    row['words']=['wearing', 'games', 'and', 'holy', '****ing', 'shit', 'do', 'I', 'hate', 'horse', 'wearing', 'games.']\n",
    "    row['tokens']=[86, 6648, 1830, 290, 11386, 25998, 278, 7510, 466, 314, 5465, 8223, 5762, 1830, 13]\n",
    "    word2tok=get_word2tok(row)\n",
    "    word2tok\n",
    "    {0: [0, 1],\n",
    "     1: [2],\n",
    "     2: [3],\n",
    "     ...\n",
    "     10: [12],\n",
    "     11: [13, 14]}\n",
    "    \"\"\"\n",
    "    global tokenizer\n",
    "    \n",
    "    jl, jr, k = 0, 0, 0\n",
    "    grouped_tokens = []\n",
    "    while jr <= len(row['tokens'])+1 and k < len(row['words']):\n",
    "        # print(f\"{jl}, {jr}, {k}: {tokenizer.decode(row['tokens'][jl:jr]).strip()}\")\n",
    "        if tokenizer.decode(row['tokens'][jl:jr]).strip() == row['words'][k]:\n",
    "            grouped_tokens.append(list(range(jl,jr)))\n",
    "            k += 1\n",
    "            jl = jr\n",
    "            jr += 1\n",
    "        else:\n",
    "            jr += 1\n",
    "    word2tok = dict(zip(range(len(grouped_tokens)), grouped_tokens))\n",
    "    return word2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d87d17b7-94eb-4224-afbf-d05ff8f8bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text['tok2char']=sample_text.apply(get_tok2char,axis=1)\n",
    "\n",
    "sample_text['word2char']=sample_text.apply(lambda x: get_word2char(x, \" \"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "29f48f16-1444-4875-9ce5-213cdfe917d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text['word2tok']=sample_text.apply(lambda x: get_word2tok(x),axis=1)\n",
    "\n",
    "def kv_swap(x):\n",
    "\n",
    "    return_dict=dict()\n",
    "    for k,v in x.items():\n",
    "        for item in v:\n",
    "            return_dict[item]=k\n",
    "    return return_dict\n",
    "\n",
    "sample_text['tok2word']=sample_text['word2tok'].apply(kv_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ca8f6ade-cd35-4b5a-b9ee-a5d7ce27a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kv_swap(x):\n",
    "\n",
    "    return_dict=dict()\n",
    "    for k,v in x.items():\n",
    "        for item in v:\n",
    "            return_dict[item]=k\n",
    "    return return_dict\n",
    "\n",
    "sample_text['char2tok']=sample_text['tok2char'].apply(kv_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "668073d6-9e0f-4e80-a13d-942cf70af949",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predictions에 다시 merge\n",
    "predictions = pd.merge(predictions, sample_text[['text','words','char','tok2char', 'word2char', 'word2tok','tok2word', 'char2tok']],on='text',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e3a19278-8763-4795-8d6f-d2de71efb1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_scores</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pred_binary</th>\n",
       "      <th>labels_binary</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>...</th>\n",
       "      <th>labels_word_binary</th>\n",
       "      <th>f1_word</th>\n",
       "      <th>f2_word</th>\n",
       "      <th>pred_scores_word</th>\n",
       "      <th>ap_word</th>\n",
       "      <th>rr_word</th>\n",
       "      <th>pred_char</th>\n",
       "      <th>pred_char_binary</th>\n",
       "      <th>labels_char_binary</th>\n",
       "      <th>char2tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me just start by saying I hate horse</td>\n",
       "      <td>wearing games and holy ****ing shit do I hate ...</td>\n",
       "      <td>[0, 1, 3, 6]</td>\n",
       "      <td>[0.071512118, 0.0715002939, 0.0, 0.0715443864,...</td>\n",
       "      <td>[5762, 1830, 290, 11386, 25998, 278, 7510, 466...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[0.071512118, 0.0715002939, 0.0, 0.0715443864,...</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A convicted German criminal known as the “broo...</td>\n",
       "      <td>using a fake penis to blackmail a woman over t...</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>[0.0625393689, 0.06213719400000001, 0.06333862...</td>\n",
       "      <td>[1262, 257, 8390, 16360, 284, 32625, 257, 2415...</td>\n",
       "      <td>[0, 0, 0.6666666666666661, 0.6666666666666661,...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>[0.0625393689, 0.06213719400000001, 0.06333862...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0           Let me just start by saying I hate horse   \n",
       "1  A convicted German criminal known as the “broo...   \n",
       "\n",
       "                                                text          pred  \\\n",
       "0  wearing games and holy ****ing shit do I hate ...  [0, 1, 3, 6]   \n",
       "1  using a fake penis to blackmail a woman over t...     [2, 3, 4]   \n",
       "\n",
       "                                         pred_scores  \\\n",
       "0  [0.071512118, 0.0715002939, 0.0, 0.0715443864,...   \n",
       "1  [0.0625393689, 0.06213719400000001, 0.06333862...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [5762, 1830, 290, 11386, 25998, 278, 7510, 466...   \n",
       "1  [1262, 257, 8390, 16360, 284, 32625, 257, 2415...   \n",
       "\n",
       "                                              labels  \\\n",
       "0         [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0.6666666666666661, 0.6666666666666661,...   \n",
       "\n",
       "                                        pred_binary  \\\n",
       "0        [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                      labels_binary   f1        f2  ...  \\\n",
       "0        [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]  0.5  0.500000  ...   \n",
       "1  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  0.8  0.909091  ...   \n",
       "\n",
       "                              labels_word_binary   f1_word   f2_word  \\\n",
       "0           [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]  0.571429  0.625000   \n",
       "1  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  0.800000  0.909091   \n",
       "\n",
       "                                    pred_scores_word   ap_word rr_word  \\\n",
       "0  [0.071512118, 0.0715002939, 0.0, 0.0715443864,...  0.791667     1.0   \n",
       "1  [0.0625393689, 0.06213719400000001, 0.06333862...  1.000000     1.0   \n",
       "\n",
       "                                           pred_char  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "\n",
       "                                    pred_char_binary  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                  labels_char_binary  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                            char2tok  \n",
       "0  {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: ...  \n",
       "1  {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: ...  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7b25f-d64c-47b6-ae3b-c91a7bce78ab",
   "metadata": {},
   "source": [
    "### Calculate Word-level Metrics\n",
    "1. Word 단위에서 pred, pred_scores, labels를 만들기\n",
    "2. 기존 함수 이용하여 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "058f3218-44f0-4e39-ada3-925cd0263ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_word(row):\n",
    "\n",
    "    return sorted(list(set([row['tok2word'][id] for id in row['pred']])))\n",
    "\n",
    "predictions['pred_word']=predictions.apply(get_pred_word,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7ec3073-86b2-437f-8822-ebe6f831c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_word_binary(row):\n",
    "\n",
    "    return [1 if id in row['pred_word'] else 0 for id in range(len(row['words']))]\n",
    "\n",
    "predictions['pred_word_binary']=predictions.apply(get_pred_word_binary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa57726b-76ea-4830-80dc-5b5f9e4cab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE. For Ski-ml Lab data, there exists word level labels.\n",
    "def get_labels_word_binary(row):\n",
    "\n",
    "    labels_token_index = np.where(np.array(row['labels_binary'])==1)[0]\n",
    "    labels_word_index = list(set([row['tok2word'][id] for id in labels_token_index]))\n",
    "    return [1 if id in labels_word_index else 0 for id in range(len(row['words']))]\n",
    "predictions['labels_word_binary']=predictions.apply(get_labels_word_binary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f166f5f-c8ac-441c-9ffe-da19931e5d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ebf2ecb9-7af8-48e8-99fb-9962fdde644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_scores_word(row,method='sum'):\n",
    "    return_list=[]\n",
    "    if method=='sum':\n",
    "        func=np.sum\n",
    "    elif method=='max':\n",
    "        func=np.max\n",
    "    elif method=='mean':\n",
    "        func=np.mean\n",
    "    for word_id in range(len(row['words'])):\n",
    "        return_list.append(func(np.array(row['pred_scores'])[row['word2tok'][word_id]]))\n",
    "    return return_list\n",
    "\n",
    "# predictions['pred_scores_word']=predictions.apply(get_pred_scores_word, axis=1)\n",
    "predictions['pred_scores_word']=predictions.apply(lambda x: get_pred_scores_word(x,method='max'), axis=1) \n",
    "## Treviso는 sum을 사용했는데, max로 실험도 해봄. 어떤것이 가장 합리적일까? sum은 word의 길이에 depend하지는 않을까? 하는 우려가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dfc48ca7-066c-4090-b8e8-919a1bcba760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1-score\n",
    "from sklearn.metrics import f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "def apply_f1_word(row):\n",
    "    return f1_score(row['labels_word_binary'],row['pred_word_binary'], zero_division=np.nan)\n",
    "    \n",
    "predictions['f1_word']=predictions.apply(apply_f1_word,axis=1)\n",
    "\n",
    "def apply_f2_word(row):\n",
    "    return fbeta_score(row['labels_word_binary'],row['pred_word_binary'], beta=2, zero_division=np.nan)\n",
    "    \n",
    "predictions['f2_word']=predictions.apply(apply_f2_word,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bc097c9a-f24c-4156-bcbe-1fb2a303e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AP\n",
    "from sklearn.metrics import f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "def apply_ap_word(row):\n",
    "    if sum(row['labels_word_binary'])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return average_precision_score(row['labels_word_binary'],row['pred_scores_word'])\n",
    "    \n",
    "predictions['ap_word']=predictions.apply(apply_ap_word,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c8f60eae-50ce-49a7-986b-2ce1fbaecdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rr_word(row):\n",
    "    if sum(row['labels_word_binary'])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return rr(np.array(row['pred_scores_word']),np.array(row['labels_word_binary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dea62787-6401-48ee-80e2-546023c40e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['rr_word']=predictions.apply(get_rr_word,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f27fce-77cf-468d-ab80-2f3bf71ccaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "443da041-a40d-4a1a-b655-73b5b2a30b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary metric\n",
    "## ToDo : double check if mean F1, mean F2 is a thing. -> Not sure.. Ask Jong?\n",
    "## double checked what happens if true label is none. ap -> np.nan, rr -> np.nan, f1 -> np.nan, f2 -> np.nan\n",
    "mf1 = predictions['f1_word'].mean()\n",
    "mf2 = predictions['f2_word'].mean()\n",
    "mrr = predictions['rr_word'].mean()\n",
    "map = predictions['ap_word'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "758ddcfb-7052-4ffa-ba9c-00c8b5e4d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf1: 0.5021, mf2: 0.5617, mrr: 0.9546, map: 0.8276\n"
     ]
    }
   ],
   "source": [
    "print(f\"mf1: {mf1:.4f}, mf2: {mf2:.4f}, mrr: {mrr:.4f}, map: {map:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777c504-ac60-47b1-b4a1-0ae3b60a65ed",
   "metadata": {},
   "source": [
    "### Calculate Character-level Metrics\n",
    "1. Character 단위에서 pred, pred_scores, labels를 만들기\n",
    "2. 기존 함수 이용하여 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "27e16cf9-3499-4442-bb6d-92e0ea08ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_char(row):\n",
    "    \n",
    "    return sorted(list(set(sum([list(row['tok2char'][id]) for id in row['pred']],[]))))\n",
    "\n",
    "predictions['pred_char']=predictions.apply(get_pred_char,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0d90f1f2-8451-40ed-a1b7-a2202d394def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_char_binary(row):\n",
    "\n",
    "    return [1 if id in row['pred_char'] else 0 for id in range(len(row['char']))]\n",
    "\n",
    "predictions['pred_char_binary']=predictions.apply(get_pred_char_binary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b24cc78b-73c3-472e-b75a-a55d79a144d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_char_binary(row):\n",
    "\n",
    "    labels_token_index = np.where(np.array(row['labels_binary'])==1)[0]\n",
    "    labels_char_index = list(set(sum([list(row['tok2char'][id]) for id in labels_token_index],[])))\n",
    "    return [1 if id in labels_char_index else 0 for id in range(len(row['char']))]\n",
    "predictions['labels_char_binary']=predictions.apply(get_labels_char_binary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "59d98792-ed91-41e9-8f1b-ca98d3287371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_scores_char(row):\n",
    "    \"\"\"\n",
    "    Each character gets the score of the token it belongs.\n",
    "    \"\"\"\n",
    "    return_list=[]\n",
    "    for char_id in range(len(row['char'])):\n",
    "        return_list.append(row['pred_scores'][row['char2tok'][char_id]])\n",
    "    return return_list\n",
    "\n",
    "predictions['pred_scores_char']=predictions.apply(lambda x: get_pred_scores_char(x), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "472dabdb-43cb-40ff-9fad-00119e808177",
   "metadata": {},
   "outputs": [],
   "source": [
    "## F1-score\n",
    "from sklearn.metrics import f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "def apply_f1_char(row):\n",
    "    return f1_score(row['labels_char_binary'],row['pred_char_binary'], zero_division=np.nan)\n",
    "    \n",
    "predictions['f1_char']=predictions.apply(apply_f1_char,axis=1)\n",
    "\n",
    "def apply_f2_char(row):\n",
    "    return fbeta_score(row['labels_char_binary'],row['pred_char_binary'], beta=2, zero_division=np.nan)\n",
    "    \n",
    "predictions['f2_char']=predictions.apply(apply_f2_char,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c57dace0-a9b4-4c7a-b960-5065db8731aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AP\n",
    "from sklearn.metrics import f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "def apply_ap_char(row):\n",
    "    if sum(row['labels_char_binary'])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return average_precision_score(row['labels_char_binary'],row['pred_scores_char'])\n",
    "    \n",
    "predictions['ap_char']=predictions.apply(apply_ap_char,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "61e9a3f7-9d40-4b17-869a-32d7c0940a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rr_char(row):\n",
    "    if sum(row['labels_char_binary'])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return rr(np.array(row['pred_scores_char']),np.array(row['labels_char_binary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0fa9f930-705d-4871-8be5-8677ccaf0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['rr_char']=predictions.apply(get_rr_char,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c4ba7-19fc-48fb-83d7-e1793dd3cc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8b373737-497f-4520-be6f-2095b727d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary metric\n",
    "## ToDo : double check if mean F1, mean F2 is a thing. -> Not sure.. Ask Jong?\n",
    "## double checked what happens if true label is none. ap -> np.nan, rr -> np.nan, f1 -> np.nan, f2 -> np.nan\n",
    "mf1 = predictions['f1_char'].mean()\n",
    "mf2 = predictions['f2_char'].mean()\n",
    "mrr = predictions['rr_char'].mean()\n",
    "map = predictions['ap_char'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "afafe999-9015-4f1e-a493-812817ebdba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf1: 0.5268, mf2: 0.5829, mrr: 0.9231, map: 0.8396\n"
     ]
    }
   ],
   "source": [
    "print(f\"mf1: {mf1:.4f}, mf2: {mf2:.4f}, mrr: {mrr:.4f}, map: {map:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
