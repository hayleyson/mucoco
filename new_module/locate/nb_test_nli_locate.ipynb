{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI 데이터에 대해서 locate을 실행해본 코드\n",
    "locate한 부분을 mask해서 그러고 났을 때 contradiction probability가 어떻게 달라지는지를 \n",
    "\n",
    "locate accuracy 대신 써보려고 시도했었다. \n",
    "\n",
    "그런데 그 방식이 엄밀하게 locate accuracy를 대신할 수 있는가에 대해서는 고민이 더 필요한 상황임.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hyeryung/.conda/envs/loc-edit/lib/python3.8/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from new_module.locate.new_locate_utils import LocateMachine\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/data/hyeryung/mucoco')\n",
    "import yaml\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import get_linear_schedule_with_warmup, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "from new_module.em_training.nli.models import EncoderModel\n",
    "from new_module.em_training.nli.data_handling import load_nli_data, load_nli_test_data, NLI_Dataset, NLI_DataLoader\n",
    "from new_module.em_training.nli.train import *\n",
    "from new_module.em_training.nli.train_modules import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ext_model = AutoModelForSequenceClassification.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
    "ext_model = ext_model.to(device)\n",
    "ext_tokenizer = AutoTokenizer.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## nli dataset load\n",
    "## nli model load\n",
    "## locate utils 불러와서, nli model을 backprop했을 때 locate되는 instance 분석 (random 30개)\n",
    "\n",
    "model_path = \"models/nli/roberta_large_snli_mnli_anli_train_dev_with_finegrained_finegrained_labels_negative_log_odds/1726245570/best_model.pth\"\n",
    "config = load_config('new_module/em_training/config.yaml')\n",
    "config['device'] = device\n",
    "\n",
    "model = EncoderModel(config)\n",
    "model = model.to(config['device'])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "config['model_path'] = model_path\n",
    "\n",
    "# nli_model = AutoModelForSequenceClassification.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
    "# nli_tokenizer = AutoTokenizer.from_pretrained(\"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\")\n",
    "\n",
    "nli_model = model\n",
    "nli_tokenizer = model.tokenizer\n",
    "nli_dataset = load_dataset('stanfordnlp/snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config['energynet']['energy_col'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    task = 'nli'\n",
    "\n",
    "locator = LocateMachine(nli_model, nli_tokenizer, Args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get test examples\n",
    "random.seed(999)\n",
    "\n",
    "contradiction_indexes = [i for i, x in enumerate(nli_dataset['test']['label']) if x == 2]\n",
    "\n",
    "random_indexes = random.sample(contradiction_indexes, 30)\n",
    "\n",
    "test_examples = nli_dataset['test'][random_indexes]\n",
    "\n",
    "test_examples_tuples = list(zip(*(test_examples['premise'], test_examples['hypothesis'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: Girl wearing white shirt sings on stage while playing guitar\n",
      "Hypothesis: A man play the triangle.\n",
      "\n",
      "\n",
      "Premise: White dog playing in the snow.\n",
      "Hypothesis: The snow is purple.\n",
      "\n",
      "\n",
      "Premise: Three children hold a boy's arms down while another boy in a hat shoots a water gun at him.\n",
      "Hypothesis: The three girls hold the boy down while his girlfriend shoots water at him.\n",
      "\n",
      "\n",
      "Premise: A boy in a hat and glasses is playing a guitar.\n",
      "Hypothesis: A boy is playing piano.\n",
      "\n",
      "\n",
      "Premise: A police person is on a motorcycle on the side of a street.\n",
      "Hypothesis: The fireman is sitting in his truck.\n",
      "\n",
      "\n",
      "Premise: A lady and a man in a hat watch baseball from the stands.\n",
      "Hypothesis: A couple are riding a rollercoaster.\n",
      "\n",
      "\n",
      "Premise: A group of young boys wearing track jackets stretch their legs on a gym floor as they sit in a circle.\n",
      "Hypothesis: A group of boys are studying for a test.\n",
      "\n",
      "\n",
      "Premise: A woman with a white blanket over her head is holding a baby wrapped in a blue, pink, and yellow blanket.\n",
      "Hypothesis: The blanket is black.\n",
      "\n",
      "\n",
      "Premise: The man in the black shirt is showing the man in the orange shirt something that he has for sale.\n",
      "Hypothesis: A man is being served a dish in a restaurant.\n",
      "\n",
      "\n",
      "Premise: A soft focus picture of a little girl wearing an orange sweater.\n",
      "Hypothesis: A girl is wearing a yellow sweater.\n",
      "\n",
      "\n",
      "Premise: Two kids in black trunks bouncing on a wet trampoline.\n",
      "Hypothesis: Two kids are building a trampoline from scratch.\n",
      "\n",
      "\n",
      "Premise: Five rodeo contestants wait their turn.\n",
      "Hypothesis: Two rodeo contestants wait their turn.\n",
      "\n",
      "\n",
      "Premise: Six seated men converse and one man fiddles with an interesting contraption.\n",
      "Hypothesis: Women are sitting around a table drinking coffee.\n",
      "\n",
      "\n",
      "Premise: San Fransisco 49ers football field with cheerleaders and a packed stadium.\n",
      "Hypothesis: The football game got cancelled and the field is empty.\n",
      "\n",
      "\n",
      "Premise: Two women are getting their pictures taken with a man in his underwear.\n",
      "Hypothesis: The is one woman in the picture.\n",
      "\n",
      "\n",
      "Premise: A father and son are in a field of yellow flowers.\n",
      "Hypothesis: People are moving a sofa.\n",
      "\n",
      "\n",
      "Premise: A young cowboy is riding bucking bronco in an arena.\n",
      "Hypothesis: A cowboy is swimming in the arena\n",
      "\n",
      "\n",
      "Premise: Some people are standing on a city sidewalk at night and waiting to get on a double-decker bus.\n",
      "Hypothesis: People wait to get on a boat at night.\n",
      "\n",
      "\n",
      "Premise: a boy in a blue uniform is standing next to a boy in red and a boy in yellow and they are holding baseball gloves.\n",
      "Hypothesis: The three boys swing baseball bats\n",
      "\n",
      "\n",
      "Premise: Three men are carrying a red bag into a boat with another person and boat in the background.\n",
      "Hypothesis: A person drives away in a winnebago.\n",
      "\n",
      "\n",
      "Premise: A woman in a headscarf sitting in front of a loom.\n",
      "Hypothesis: the woman is standing\n",
      "\n",
      "\n",
      "Premise: A group of people wait to cross the street in new york\n",
      "Hypothesis: People waiting in line at an amusement park.\n",
      "\n",
      "\n",
      "Premise: A girl is swinging, rather high, on a swing with blue ropes with lots of trees in the background.\n",
      "Hypothesis: A girl is swinging, rather high, on a swing with white ropes.\n",
      "\n",
      "\n",
      "Premise: Here is a picture of a man waiting for the bus to pick him up and he is hiding his face.\n",
      "Hypothesis: The man is driving himself somewhere.\n",
      "\n",
      "\n",
      "Premise: Cheerleaders in blue performing on a football field underneath a yellow football goal post.\n",
      "Hypothesis: The San Francisco 49ers cheerleaders perform in a dark basement.\n",
      "\n",
      "\n",
      "Premise: Mother and daughter are meeting for the first time.\n",
      "Hypothesis: The mother and daughter are fighitn.\n",
      "\n",
      "\n",
      "Premise: Painter re-creates old works of art in a museum.\n",
      "Hypothesis: A painter creating an original work of art.\n",
      "\n",
      "\n",
      "Premise: Man in plaid shirt sings into microphone while playing an acoustic guitar.\n",
      "Hypothesis: A man is walking.\n",
      "\n",
      "\n",
      "Premise: Three young girls in winter clothing and hats look at disposable cameras they are holding.\n",
      "Hypothesis: The temperature is a scalding 100 degrees fahrenheit.\n",
      "\n",
      "\n",
      "Premise: A man with his finger in his mouth is standing outside of an RV.\n",
      "Hypothesis: The man is inside his RV.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in test_examples_tuples:\n",
    "    \n",
    "    print(\"Premise:\", example[0])\n",
    "    print(\"Hypothesis:\", example[1])\n",
    "    print(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = locator.locate_main(test_examples_tuples, 'grad_norm', max_num_tokens = 100, unit=\"word\", label_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample에 대한 output score 확인\n",
    "tokens = nli_tokenizer(test_examples_tuples, return_tensors='pt', padding=True, truncation=True)\n",
    "tokens = tokens.to(config['device'])\n",
    "try:\n",
    "    outputs = nli_model(**tokens)\n",
    "    logits, hidden_states = outputs['logits'], outputs['hidden_states']\n",
    "except:\n",
    "    logits, hidden_states = nli_model(**tokens)\n",
    "\n",
    "if config['energynet']['output_form'] in ['2dim_vec', '3dim_vec']: \n",
    "    probas_before_masking = torch.softmax(logits, dim=1)\n",
    "else:\n",
    "    probas_before_masking = logits\n",
    "\n",
    "class_before_masking = torch.argmax(probas_before_masking,dim=-1)\n",
    "probas_before_masking = probas_before_masking[:, config['energynet']['energy_col']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample에 대한 external model의 output score 확인\n",
    "\n",
    "tokens = ext_tokenizer(test_examples_tuples, return_tensors='pt', padding=True, truncation=True)\n",
    "tokens = tokens.to(config['device'])\n",
    "outputs = ext_model(**tokens)\n",
    "logits = outputs['logits']\n",
    "probas_before_masking_ext = torch.softmax(logits, dim=1)\n",
    "class_before_masking_ext = torch.argmax(probas_before_masking_ext,dim=-1)\n",
    "probas_before_masking_ext = probas_before_masking_ext[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## masking 된 샘플에 대한 energy score 확인\n",
    "tokens_after_masking = nli_tokenizer(result, add_special_tokens=False, return_tensors='pt', padding=True, truncation=True)\n",
    "tokens_after_masking = tokens_after_masking.to(config['device'])\n",
    "\n",
    "try:\n",
    "    outputs = nli_model(**tokens_after_masking)\n",
    "    logits_after_masking, _ = outputs['logits'], outputs['hidden_states']\n",
    "except:\n",
    "    logits_after_masking, _ = nli_model(**tokens_after_masking)\n",
    "    \n",
    "if config['energynet']['output_form'] in ['2dim_vec', '3dim_vec']: \n",
    "    probas_after_masking = torch.softmax(logits_after_masking, dim=1)\n",
    "else:\n",
    "    probas_after_masking = logits_after_masking\n",
    "\n",
    "class_after_masking = torch.argmax(probas_after_masking,dim=-1)\n",
    "probas_after_masking = probas_after_masking[:, config['energynet']['energy_col']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## masking 된 샘플에 대한 external model의 energy score 확인\n",
    "tokens_after_masking = ext_tokenizer(result, add_special_tokens=False, return_tensors='pt', padding=True, truncation=True)\n",
    "tokens_after_masking = tokens_after_masking.to(config['device'])\n",
    "\n",
    "outputs = ext_model(**tokens_after_masking)\n",
    "logits_after_masking = outputs['logits']\n",
    "    \n",
    "probas_after_masking_ext = torch.softmax(logits_after_masking, dim=1)\n",
    "class_after_masking_ext = torch.argmax(probas_after_masking_ext,dim=-1)\n",
    "probas_after_masking_ext = probas_after_masking_ext[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise:  Girl wearing white shirt sings on stage while playing guitar\n",
      "Hypothesis:  A man play the triangle.\n",
      "Model proba:  7.2474565505981445 -> 6.789552211761475\n",
      "External model proba:  0.9995410442352295 -> 0.999459445476532\n",
      "Located p:  <s>Girl wearing white shirt sings on stage while playing guitar\n",
      "Located h:  A man play the<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  White dog playing in the snow.\n",
      "Hypothesis:  The snow is purple.\n",
      "Model proba:  7.826869487762451 -> 1.765481948852539\n",
      "External model proba:  0.7578288912773132 -> 0.034679610282182693\n",
      "Located p:  <s>White dog playing in the snow.\n",
      "Located h:  The snow is<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Three children hold a boy's arms down while another boy in a hat shoots a water gun at him.\n",
      "Hypothesis:  The three girls hold the boy down while his girlfriend shoots water at him.\n",
      "Model proba:  3.261336326599121 -> 2.6492867469787598\n",
      "External model proba:  0.457634836435318 -> 0.05039544776082039\n",
      "Located p:  <s>Three children hold a boy's arms down while another boy in a hat shoots a water gun at him.\n",
      "Located h:  The three<mask> hold the boy down while his<mask><mask> water at him.</s>\n",
      "\n",
      "\n",
      "Premise:  A boy in a hat and glasses is playing a guitar.\n",
      "Hypothesis:  A boy is playing piano.\n",
      "Model proba:  8.134237289428711 -> 1.054682731628418\n",
      "External model proba:  0.9988681077957153 -> 0.07894154638051987\n",
      "Located p:  <s>A boy in a hat and glasses is playing a guitar.\n",
      "Located h:  A boy is playing<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A police person is on a motorcycle on the side of a street.\n",
      "Hypothesis:  The fireman is sitting in his truck.\n",
      "Model proba:  8.064376831054688 -> 7.1860198974609375\n",
      "External model proba:  0.9990519881248474 -> 0.9928426742553711\n",
      "Located p:  <s>A police person is on a motorcycle on the side of a street.\n",
      "Located h:  The<mask><mask> is sitting in his<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A lady and a man in a hat watch baseball from the stands.\n",
      "Hypothesis:  A couple are riding a rollercoaster.\n",
      "Model proba:  7.5561065673828125 -> 2.6699304580688477\n",
      "External model proba:  0.9992425441741943 -> 0.03902975469827652\n",
      "Located p:  <s>A lady and a man in a hat watch baseball from the stands.\n",
      "Located h:  A couple are<mask> a<mask><mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A group of young boys wearing track jackets stretch their legs on a gym floor as they sit in a circle.\n",
      "Hypothesis:  A group of boys are studying for a test.\n",
      "Model proba:  2.6523985862731934 -> 2.5465965270996094\n",
      "External model proba:  0.3655937612056732 -> 0.020622016862034798\n",
      "Located p:  <s>A group of young boys wearing track jackets stretch their legs on a gym floor as they sit in a circle.\n",
      "Located h:  A group of boys are<mask> for a<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A woman with a white blanket over her head is holding a baby wrapped in a blue, pink, and yellow blanket.\n",
      "Hypothesis:  The blanket is black.\n",
      "Model proba:  7.8613786697387695 -> 3.050969362258911\n",
      "External model proba:  0.997923731803894 -> 0.15328244864940643\n",
      "Located p:  <s>A woman with a white blanket over her head is holding a baby wrapped in a blue, pink, and yellow blanket.\n",
      "Located h:  The<mask> is<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  The man in the black shirt is showing the man in the orange shirt something that he has for sale.\n",
      "Hypothesis:  A man is being served a dish in a restaurant.\n",
      "Model proba:  5.569395065307617 -> 3.9232006072998047\n",
      "External model proba:  0.9991391897201538 -> 0.21722520887851715\n",
      "Located p:  <s>The man in the black shirt is showing the man in the orange shirt something that he has for sale.\n",
      "Located h:  A man is being<mask> a<mask> in a<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A soft focus picture of a little girl wearing an orange sweater.\n",
      "Hypothesis:  A girl is wearing a yellow sweater.\n",
      "Model proba:  7.918136119842529 -> 2.6417148113250732\n",
      "External model proba:  0.9984904527664185 -> 0.12001373618841171\n",
      "Located p:  <s>A soft focus picture of a little girl wearing an orange sweater.\n",
      "Located h:  A girl is wearing a<mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Two kids in black trunks bouncing on a wet trampoline.\n",
      "Hypothesis:  Two kids are building a trampoline from scratch.\n",
      "Model proba:  4.322233200073242 -> 2.7032976150512695\n",
      "External model proba:  0.9492819309234619 -> 0.2979235053062439\n",
      "Located p:  <s>Two kids in black trunks bouncing on a wet trampoline.\n",
      "Located h:  Two kids are<mask> a<mask><mask><mask> from<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Five rodeo contestants wait their turn.\n",
      "Hypothesis:  Two rodeo contestants wait their turn.\n",
      "Model proba:  7.3157453536987305 -> 1.282842993736267\n",
      "External model proba:  0.9973825812339783 -> 0.2428520768880844\n",
      "Located p:  <s>Five rodeo contestants wait their turn.\n",
      "Located h:  <mask><mask><mask><mask> wait their turn.</s>\n",
      "\n",
      "\n",
      "Premise:  Six seated men converse and one man fiddles with an interesting contraption.\n",
      "Hypothesis:  Women are sitting around a table drinking coffee.\n",
      "Model proba:  7.449946403503418 -> 2.8846797943115234\n",
      "External model proba:  0.9995707869529724 -> 0.23490607738494873\n",
      "Located p:  <s>Six seated men converse and one man fiddles with an interesting contraption.\n",
      "Located h:  <mask> are sitting around a table drinking<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  San Fransisco 49ers football field with cheerleaders and a packed stadium.\n",
      "Hypothesis:  The football game got cancelled and the field is empty.\n",
      "Model proba:  6.09930944442749 -> 1.7246817350387573\n",
      "External model proba:  0.999327540397644 -> 0.21107544004917145\n",
      "Located p:  <s>San Fransisco 49ers football field with cheerleaders and a packed stadium.\n",
      "Located h:  The football game got<mask> and the field is<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Two women are getting their pictures taken with a man in his underwear.\n",
      "Hypothesis:  The is one woman in the picture.\n",
      "Model proba:  6.481042861938477 -> 2.5885839462280273\n",
      "External model proba:  0.9514561295509338 -> 0.20857684314250946\n",
      "Located p:  <s>Two women are getting their pictures taken with a man in his underwear.\n",
      "Located h:  The<mask><mask><mask> in the picture.</s>\n",
      "\n",
      "\n",
      "Premise:  A father and son are in a field of yellow flowers.\n",
      "Hypothesis:  People are moving a sofa.\n",
      "Model proba:  7.0219244956970215 -> 2.7162375450134277\n",
      "External model proba:  0.9986910223960876 -> 0.12013416737318039\n",
      "Located p:  <s>A father and son are in a field of yellow flowers.\n",
      "Located h:  People are moving a<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A young cowboy is riding bucking bronco in an arena.\n",
      "Hypothesis:  A cowboy is swimming in the arena\n",
      "Model proba:  7.863615036010742 -> 2.9007303714752197\n",
      "External model proba:  0.9974442720413208 -> 0.15992721915245056\n",
      "Located p:  <s>A young cowboy is riding bucking bronco in an arena.\n",
      "Located h:  A<mask> is<mask> in the<mask></s>\n",
      "\n",
      "\n",
      "Premise:  Some people are standing on a city sidewalk at night and waiting to get on a double-decker bus.\n",
      "Hypothesis:  People wait to get on a boat at night.\n",
      "Model proba:  6.50846004486084 -> 0.8364317417144775\n",
      "External model proba:  0.994981586933136 -> 0.0013502761721611023\n",
      "Located p:  <s>Some people are standing on a city sidewalk at night and waiting to get on a double-decker bus.\n",
      "Located h:  People wait to get on a<mask> at night.</s>\n",
      "\n",
      "\n",
      "Premise:  a boy in a blue uniform is standing next to a boy in red and a boy in yellow and they are holding baseball gloves.\n",
      "Hypothesis:  The three boys swing baseball bats\n",
      "Model proba:  5.89695930480957 -> 2.905526638031006\n",
      "External model proba:  0.5938804745674133 -> 0.15923838317394257\n",
      "Located p:  <s>a boy in a blue uniform is standing next to a boy in red and a boy in yellow and they are holding baseball gloves.\n",
      "Located h:  The three boys<mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Three men are carrying a red bag into a boat with another person and boat in the background.\n",
      "Hypothesis:  A person drives away in a winnebago.\n",
      "Model proba:  6.477780342102051 -> 4.481114864349365\n",
      "External model proba:  0.9949765205383301 -> 0.6835960149765015\n",
      "Located p:  <s>Three men are carrying a red bag into a boat with another person and boat in the background.\n",
      "Located h:  A person<mask> away in a<mask><mask><mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A woman in a headscarf sitting in front of a loom.\n",
      "Hypothesis:  the woman is standing\n",
      "Model proba:  7.792072296142578 -> 1.9880895614624023\n",
      "External model proba:  0.9969742298126221 -> 0.08493100106716156\n",
      "Located p:  <s>A woman in a headscarf sitting in front of a loom.\n",
      "Located h:  <mask> woman is<mask></s>\n",
      "\n",
      "\n",
      "Premise:  A group of people wait to cross the street in new york\n",
      "Hypothesis:  People waiting in line at an amusement park.\n",
      "Model proba:  4.870369911193848 -> 4.369933128356934\n",
      "External model proba:  0.929288387298584 -> 0.3868134319782257\n",
      "Located p:  <s>A group of people wait to cross the street in new york\n",
      "Located h:  People waiting in line at an<mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A girl is swinging, rather high, on a swing with blue ropes with lots of trees in the background.\n",
      "Hypothesis:  A girl is swinging, rather high, on a swing with white ropes.\n",
      "Model proba:  7.851250648498535 -> 3.3742523193359375\n",
      "External model proba:  0.9994956254959106 -> 0.20622959733009338\n",
      "Located p:  <s>A girl is swinging, rather high, on a swing with blue ropes with lots of trees in the background.\n",
      "Located h:  <mask><mask> is swinging, rather high, on a swing with<mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Here is a picture of a man waiting for the bus to pick him up and he is hiding his face.\n",
      "Hypothesis:  The man is driving himself somewhere.\n",
      "Model proba:  6.711551666259766 -> 3.3718743324279785\n",
      "External model proba:  0.9243913888931274 -> 0.04866708442568779\n",
      "Located p:  <s>Here is a picture of a man waiting for the bus to pick him up and he is hiding his face.\n",
      "Located h:  <mask> man is<mask> himself<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Cheerleaders in blue performing on a football field underneath a yellow football goal post.\n",
      "Hypothesis:  The San Francisco 49ers cheerleaders perform in a dark basement.\n",
      "Model proba:  6.882955551147461 -> 2.289367198944092\n",
      "External model proba:  0.9926122426986694 -> 0.020149100571870804\n",
      "Located p:  <s>Cheerleaders in blue performing on a football field underneath a yellow football goal post.\n",
      "Located h:  The San Francisco 49ers<mask><mask> perform in a<mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Mother and daughter are meeting for the first time.\n",
      "Hypothesis:  The mother and daughter are fighitn.\n",
      "Model proba:  3.009053945541382 -> 2.2349464893341064\n",
      "External model proba:  0.2752513587474823 -> 0.11547752469778061\n",
      "Located p:  <s>Mother and daughter are meeting for the first time.\n",
      "Located h:  The mother and daughter are<mask><mask><mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Painter re-creates old works of art in a museum.\n",
      "Hypothesis:  A painter creating an original work of art.\n",
      "Model proba:  6.815965175628662 -> 2.349376916885376\n",
      "External model proba:  0.9641393423080444 -> 0.14049412310123444\n",
      "Located p:  <s>Painter re-creates old works of art in a museum.\n",
      "Located h:  A<mask> creating an<mask> work of art.</s>\n",
      "\n",
      "\n",
      "Premise:  Man in plaid shirt sings into microphone while playing an acoustic guitar.\n",
      "Hypothesis:  A man is walking.\n",
      "Model proba:  6.9783477783203125 -> 2.1218008995056152\n",
      "External model proba:  0.9747977256774902 -> 0.06255706399679184\n",
      "Located p:  <s>Man in plaid shirt sings into microphone while playing an acoustic guitar.\n",
      "Located h:  A man is<mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  Three young girls in winter clothing and hats look at disposable cameras they are holding.\n",
      "Hypothesis:  The temperature is a scalding 100 degrees fahrenheit.\n",
      "Model proba:  6.089545726776123 -> 5.71285343170166\n",
      "External model proba:  0.9962857961654663 -> 0.9704661965370178\n",
      "Located p:  <s>Three young girls in winter clothing and hats look at disposable cameras they are holding.\n",
      "Located h:  The<mask> is a<mask><mask><mask> 100 degrees<mask><mask><mask><mask></s>\n",
      "\n",
      "\n",
      "Premise:  A man with his finger in his mouth is standing outside of an RV.\n",
      "Hypothesis:  The man is inside his RV.\n",
      "Model proba:  7.617451190948486 -> 3.17449951171875\n",
      "External model proba:  0.9958534240722656 -> 0.27187585830688477\n",
      "Located p:  <s>A man with his finger in his mouth is standing outside of an RV.\n",
      "Located h:  <mask> man is<mask> his<mask><mask></s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## observation 1: 어떤 sample들은 그닥 contradictive하지 않은 것 같다. --> 거를 방식이 있을까?\n",
    "## observation 2: locate된 token들이 contradictive한 부분을 잘 반영하고 있는 것 같다. \n",
    "\n",
    "classes = [\"Entail\", \"Neutral\", \"Contradict\"]\n",
    "for i, ((p, h), y) in enumerate(zip(test_examples_tuples, result)):\n",
    "    print(\"Premise: \", p)\n",
    "    print(\"Hypothesis: \", h)\n",
    "    print(\"Model proba: \", probas_before_masking[i].item(), \"->\", probas_after_masking[i].item())\n",
    "    print(\"External model proba: \", probas_before_masking_ext[i].item(), \"->\", probas_after_masking_ext[i].item())\n",
    "    # print(\"Predicted class: \", classes[class_before_masking[i].item()], \"->\", classes[class_after_masking[i].item()])\n",
    "    print(\"Located p: \", y.split('</s></s>')[0])\n",
    "    print(\"Located h: \", y.split('</s></s>')[1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results\n",
    "\n",
    "Run this code after running test_nli_locate.py for wandb runs that you want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel('/data/hyeryung/mucoco/dev_data_locating_result_merge_masks_raw_t6lbryef.xlsx')\n",
    "data2 = pd.read_excel('/data/hyeryung/mucoco/dev_data_locating_result_merge_masks_raw_25n5gs0a.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original', 'masked', 'original_class', 'masked_class',\n",
       "       'original_contradiction_proba', 'masked_contradiction_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns = ['original', 'masked_t6l', 'original_class', 'masked_class_t6l',\n",
    "       'original_contradiction_proba', 'masked_contradiction_proba_t6l']\n",
    "data2.columns = ['original', 'masked_25n', 'original_class', 'masked_class_25n',\n",
    "       'original_contradiction_proba', 'masked_contradiction_proba_25n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original', 'masked_t6l', 'masked_class_t6l',\n",
      "       'masked_contradiction_proba_t6l', 'masked_25n', 'masked_class_25n',\n",
      "       'masked_contradiction_proba_25n'],\n",
      "      dtype='object')\n",
      "(1766, 7)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data1,data2],axis=1)\n",
    "data = data.iloc[:, [0,1,3,5,7,9,11]].copy()\n",
    "print(data.columns)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['contra_class_yn_t6l'] = data['masked_contradiction_proba_t6l'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "data['contra_class_yn_25n'] = data['masked_contradiction_proba_25n'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contra_class_yn_t6l  contra_class_yn_25n\n",
       "0                    0                      958\n",
       "                     1                      126\n",
       "1                    0                      210\n",
       "                     1                      472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['contra_class_yn_t6l', 'contra_class_yn_25n']).size()\n",
    "# t6l 이 못함 -> 실제 납득 가능한가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
