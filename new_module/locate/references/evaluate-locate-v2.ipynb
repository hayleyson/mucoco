{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb03c45c-930d-4640-a8a8-f1f5dc015990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from notebooks.utils.load_ckpt import define_model\n",
    "\n",
    "pd.set_option('max_colwidth',1000)\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/hyeryung_son/mucoco/')\n",
    "\n",
    "def merge_lists(lists):\n",
    "    a = []\n",
    "    for _list in lists:\n",
    "        a.append(_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3585cab-2fd6-4a05-97f7-59b27f04ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda\n"
     ]
    }
   ],
   "source": [
    "# load model, tokenizer\n",
    "model, tokenizer = define_model('models/roberta-base-jigsaw-toxicity-classifier-with-gpt2-large-embeds/checkpoint_best/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f49fee-3a2b-4a44-8e89-30d1c79ca87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsource = \"gpt2\"\n",
    "\n",
    "# load test set files\n",
    "input_id_file = joblib.load(f'outputs/toxicity/save-init-gen-all-uniform/testset_FINAL_{dsource}_input_ids.pkl')\n",
    "gt_file = joblib.load(f'outputs/toxicity/save-init-gen-all-uniform/testset_FINAL_{dsource}_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedd4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fprefix = f\"outputs/toxicity/locate-edit-{dsource}/outputs_epsilon-5\"\n",
    "fprefix = f\"/home/hyeryung_son/mucoco/outputs/toxicity/locate-edit-{dsource}-loc-6toks--1steps-project-1steps/outputs_epsilon-5\"\n",
    "\n",
    "# load intermediate predictions file\n",
    "pred_file = pd.read_json(f'{fprefix}.txt.intermediate', lines=True)\n",
    "pred_file[\"indices\"] = pred_file[\"step_0_indices\"]\n",
    "pred_file['indices'] = pred_file['indices'].apply(lambda x: set(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "049b0ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if prediction file length equal to test file length\n"
     ]
    }
   ],
   "source": [
    "print(\"check if prediction file length equal to test file length\")\n",
    "assert len(pred_file) == len(input_id_file)\n",
    "assert len(pred_file) == len(gt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a5c30f-9340-4b01-a3de-10446b660368",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file['input_ids'] = input_id_file\n",
    "\n",
    "pred_file['gt_gt0'] = [set(np.where(np.array(x) > 0)[0]) for x in gt_file]\n",
    "pred_file['gt_eq1'] = [set(np.where(np.array(x) == 1.0)[0]) for x in gt_file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278d66e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    115.000000\n",
      "mean       5.286957\n",
      "std        4.279214\n",
      "min        0.000000\n",
      "25%        2.000000\n",
      "50%        5.000000\n",
      "75%        7.500000\n",
      "max       24.000000\n",
      "Name: len_gt_gt0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## EDA locate length => what's average # of located tokens\n",
    "pred_file['len_gt_gt0'] = pred_file['gt_gt0'].apply(len)\n",
    "pred_file['len_gt_eq1'] = pred_file['gt_eq1'].apply(len)\n",
    "\n",
    "print(pred_file['len_gt_gt0'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f612d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    115.000000\n",
       "mean       5.104348\n",
       "std        2.552515\n",
       "min        0.000000\n",
       "25%        4.000000\n",
       "50%        6.000000\n",
       "75%        6.000000\n",
       "max       18.000000\n",
       "Name: indices, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_file[\"indices\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb1062d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    115.000000\n",
       "mean       4.730435\n",
       "std        1.237724\n",
       "min        0.000000\n",
       "25%        4.000000\n",
       "50%        5.000000\n",
       "75%        6.000000\n",
       "max        6.000000\n",
       "Name: indices, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fprefix = f\"outputs/toxicity/locate-edit-{dsource}/outputs_epsilon-5\"\n",
    "fprefix = f\"/home/hyeryung_son/mucoco/outputs/toxicity/locate-edit-{dsource}/old_locate_function/outputs_epsilon-5\"\n",
    "\n",
    "# load intermediate predictions file\n",
    "pred_file2 = pd.read_json(f'{fprefix}.txt.intermediate', lines=True)\n",
    "# pred_file2[\"indices\"] = pred_file2[\"step_0_indices\"]\n",
    "pred_file2['indices'] = pred_file2['indices'].apply(lambda x: set(x[0]))\n",
    "pred_file2[\"indices\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "46f6e475-9425-4be7-8749-9ae63b5ba329",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 눈으로 확인했을 때는, 뭐가 더 낫다 라고 하기가 어려웠다. 다만, gt_gt0 라벨의 경우 a, the 같은 관사가 포함되어 있는데\n",
    "## 이것들은 굳이 필요가 없을것 같기도 하다.\n",
    "\n",
    "pred_file['gt_words_gt0'] = pred_file[['input_ids', 'gt_gt0']].apply(lambda x: tokenizer.decode(np.array(x[0])[sorted(list(x[1]))]), axis=1)\n",
    "pred_file['gt_words_eq1'] = pred_file[['input_ids', 'gt_eq1']].apply(lambda x: tokenizer.decode(np.array(x[0])[sorted(list(x[1]))]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a85f5cf2-f6af-4497-8fdc-35fcd1af331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## precision, recall\n",
    "suffix = 'gt0'\n",
    "pred_indices = pred_file['indices'].tolist()\n",
    "gt_indices = pred_file[f\"gt_{suffix}\"].tolist()\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "for i in range(len(pred_indices)):\n",
    "    intersection = pred_indices[i].intersection(gt_indices[i])\n",
    "    if len(gt_indices[i]) == 0:\n",
    "        recall = np.nan\n",
    "    else:\n",
    "        recall = len(intersection) / len(gt_indices[i])\n",
    "    if len(pred_indices[i]) == 0:\n",
    "        precision = np.nan\n",
    "    else:\n",
    "        precision = len(intersection) / len(pred_indices[i])\n",
    "        \n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "pred_file[f'precision_{suffix}'] = precision_list\n",
    "pred_file[f'recall_{suffix}'] = recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "23c99a97-c997-40da-b2bb-106d5e78336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'eq1'\n",
    "pred_indices = pred_file['indices'].tolist()\n",
    "gt_indices = pred_file[f\"gt_{suffix}\"].tolist()\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "for i in range(len(pred_indices)):\n",
    "    intersection = pred_indices[i].intersection(gt_indices[i])\n",
    "    if len(gt_indices[i]) == 0:\n",
    "        recall = np.nan\n",
    "    else:\n",
    "        recall = len(intersection) / len(gt_indices[i])\n",
    "    if len(pred_indices[i]) == 0:\n",
    "        precision = np.nan\n",
    "    else:\n",
    "        precision = len(intersection) / len(pred_indices[i])\n",
    "        \n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "pred_file[f'precision_{suffix}'] = precision_list\n",
    "pred_file[f'recall_{suffix}'] = recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "86db8397-beb4-4eb7-8637-1fd3ec74c9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_gt0 : 0.3910\n",
      "recall_gt0 : 0.6004\n"
     ]
    }
   ],
   "source": [
    "suffix = 'gt0'\n",
    "print(f\"precision_{suffix} : {pred_file[f'precision_{suffix}'].mean():.4f}\")\n",
    "print(f\"recall_{suffix} : {pred_file[f'recall_{suffix}'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bed6480d-339c-4d08-89de-bd346f639a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_eq1 : 0.2652\n",
      "recall_eq1 : 0.6990\n"
     ]
    }
   ],
   "source": [
    "suffix = 'eq1'\n",
    "print(f\"precision_{suffix} : {pred_file[f'precision_{suffix}'].mean():.4f}\")\n",
    "print(f\"recall_{suffix} : {pred_file[f'recall_{suffix}'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "51d6c87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hyeryung_son/mucoco/outputs/toxicity/locate-edit-jigsaw-loc-6toks--1steps-project-1steps/outputs_epsilon-5'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d02d09ad-d6c4-41cb-9a57-124c7260491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{fprefix}.eval', 'w') as f:\n",
    "    f.writelines(\"====================================\\n\")\n",
    "    suffix = 'gt0'\n",
    "    f.writelines(f\"precision_{suffix} : {pred_file[f'precision_{suffix}'].mean():.4f}\\n\")\n",
    "    f.writelines(f\"recall_{suffix} : {pred_file[f'recall_{suffix}'].mean():.4f}\\n\")\n",
    "    f.writelines(\"====================================\\n\")\n",
    "    suffix = 'eq1'\n",
    "    f.writelines(f\"precision_{suffix} : {pred_file[f'precision_{suffix}'].mean():.4f}\\n\")\n",
    "    f.writelines(f\"recall_{suffix} : {pred_file[f'recall_{suffix}'].mean():.4f}\\n\")\n",
    "    f.writelines(\"====================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f4366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
