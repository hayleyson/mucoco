{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fcf6a1-f1b3-442b-81b1-4593d61a5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/s3/hyeryung/mucoco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c066e8e3-16d6-4ebe-b7ef-e62b6f9302d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afb3352e-8a67-4733-9b23-7cae5182004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from new_module.losses import BaseLoss, register_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3313b997-e7ec-4879-b7ea-c2ea2cbbbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6deacf-1bac-4fe0-beaa-be4cd46c6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModel.from_pretrained('gpt2-large',cache_dir='/shared/s3/lab07/hyeryung/hf_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4f41454-ee02-4b54-93aa-93c490fc1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afacd68-e0c6-4a41-8df3-ff4a83bab0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained('gpt2-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc3fe319-6377-45b8-b4b5-1316e80cbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='abc'\n",
    "gens=['dsxe','sdvbfe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "327384c9-f3b4-4405-a94d-eb435ba8879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "286ad9f4-9d70-41ab-8fab-bfa4694974d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_enc=tokenizer.encode_plus(prompt,add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05e8dc95-ae4f-400f-b5e8-276aa96c5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_enc['input_ids']=prompt_enc['input_ids'].expand(num_samples,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "914f2777-004d-41cf-91c0-7f3430151016",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_enc['attention_mask']=prompt_enc['attention_mask'].expand(num_samples,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a38b3046-6b44-4a3b-819b-7d5f66354a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[39305],\n",
       "        [39305]], device='cuda:0'), 'attention_mask': tensor([[1],\n",
       "        [1]], device='cuda:0')}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae7eaf10-e8bc-4880-a40f-c10f8566e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gens_enc=tokenizer.batch_encode_plus(gens, add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a38eb9c-d6d5-4f4f-b308-96278e09679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 9310, 27705, 50256, 50256],\n",
       "        [21282,    85,    65,  5036]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 0, 0],\n",
       "        [1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gens_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f24b9417-4a91-4f42-8b94-bd0b3e162ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = torch.cat([prompt_enc.input_ids, gens_enc.input_ids], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fa19425-70ff-4ebe-9606-dc8aca9fcb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = torch.cat([prompt_enc.attention_mask, gens_enc.attention_mask], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64537a-5904-4536-a12e-fb3b0394b9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8410fc8-e09b-4b9a-9b91-4189267f21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model(input_ids=input_tokens,\n",
    "                    attention_mask=attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d847343a-1831-4708-be11-f63e6e433aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_logits = model_output[0][:, prompt_enc.input_ids.size(1)-1:-1, :]\n",
    "lm_logprobs = F.log_softmax(lm_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd92f986-5396-447c-8f24-da80de76468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1280])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa4880ec-1cbd-4590-b45c-1654c6727a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gens_enc.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254b016-14b0-427c-abca-dfa3ff35ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd4560-b9e3-4760-884a-cdb774c3bbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ca04c7d-ef6a-431e-93fe-bb9de0494826",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.nll_loss(lm_logprobs.permute(0,2,1), gens_enc.input_ids, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "114536e3-2c40-491a-aa8f-65ede0225f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss * gens_enc.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9185fd8-3474-47cf-a9dc-4c90b41f64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55bf0d89-efdd-4be1-99c4-012896d2fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss /= gens_enc.attention_mask.sum() ## 이렇게 하는게 맞을지 조금 고민이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02174cef-6c8c-4a1c-b0a9-1e7765cdf83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.569, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113976ab-fb1d-43b3-a0e1-f7e25eb036e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41774058-04ef-47c8-85b3-5e726868e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413f553-d9a1-4dc4-ab2e-dc302b518bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114e622-4a26-44ef-b4b9-e31ea2d063f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45f84c-8829-4597-978d-7f0593ea886b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951a249-17ee-481a-9085-9672571955f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39cebf7-c7b3-45b1-a989-e49603f0a408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f95b763-c999-4de5-844d-d448292e7b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.414, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d2a5f-711a-49f9-bb17-34b51d0c5215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b1c8bdd-f322-4dbd-9184-33bc90f709e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+0008 (4036987649.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    tokenizer.\bencode_plus(prompt, add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).long()\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+0008\n"
     ]
    }
   ],
   "source": [
    "tokenizer.\bencode_plus(prompt, add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7768930-b132-4c80-8349-3064d94d9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id=tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6113da-7c83-4cf7-a715-5cc1a35d67a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[64],\n",
       "        [65]]), 'attention_mask': tensor([[1],\n",
       "        [1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(['a','b'],truncation=True, padding=True,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cc3a3f4-a380-42a2-a3fc-331a671e235c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/loc-edit/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:731\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 731\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 1 at dim 1 (got 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbcd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loc-edit/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2838\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2830\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2831\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2836\u001b[0m )\n\u001b[0;32m-> 2838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2840\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loc-edit/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:168\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m )\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loc-edit/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:473\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loc-edit/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:211\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    207\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loc-edit/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:747\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    744\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    746\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    750\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    752\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(['a','bcd'],truncation=True, padding=False,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ed0f-40d7-4773-ae36-e909aea0d524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc5027c-9b74-4775-ad35-2542f473cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Loss(BaseLoss):\n",
    "\n",
    "    def __init__(self, model, tokenizer, args):\n",
    "        super().__init__() \n",
    "\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer \n",
    "        self.args = args\n",
    "        self.device = model.device\n",
    "        \n",
    "        self.eos_token_id = self.tokenizer.eos_token_id    \n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.config.pad_token_id = self.model.config.eos_token_id # to remove the warning\n",
    "    \n",
    "    def compute_gold_loss(self, prompt, prediction, **kwargs):\n",
    "        '''\n",
    "        given a discrete target output, this will compute the loss wrt to it. Useful in debugging\n",
    "        '''\n",
    "        prompt = self.tokenizer.\bbatch_encode_plus(prompt, add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).to(self.device).long()\n",
    "        # assuming batch size of 1 (prediction is a string instance.)\n",
    "        prediction = self.tokenizer.batch_encode_plus(prediction, add_special_tokens=False, return_tensors=\"pt\", padding=True, truncation=True).to(self.device).long()\n",
    "        input_tokens = torch.cat([prompt.input_ids, prediction.input_ids], dim=1)\n",
    "        model_output = self.model(input_tokens)\n",
    "\n",
    "        lm_logits = model_output[0][:, prompt.size(1)-1:-1, :]\n",
    "        lm_logprobs = F.log_softmax(lm_logits, dim=-1)\n",
    "\n",
    "        loss = F.nll_loss(lm_logprobs.squeeze(0), prediction.squeeze(0), reduction=\"none\").sum(dim=-1)\n",
    "        \n",
    "        if self.args.length_normalize:\n",
    "            loss /= lm_logprobs.size(1)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def generate(self, input_ids, **kwargs):\n",
    "        prepared_input = self._prepare_input_for_generation(input_ids, **kwargs)\n",
    "        output = self.model.generate(**prepared_input)\n",
    "        \n",
    "        return self._postprocess_output(prepared_input, output)\n",
    "\n",
    "    def _prepare_input_for_generation(self, input_ids, **kwargs):\n",
    "        max_output_length = getattr(self.args, \"max_output_length\", 10)\n",
    "        batch_size = input_ids.size(0)\n",
    "        #batch size is 1, padding and stuff needs to be modified for this to work for larger batches\n",
    "\n",
    "        return_object = {'input_ids': input_ids,\n",
    "                'max_length': input_ids.size(1) + max_output_length,\n",
    "                'do_sample': True,\n",
    "                'temperature': self.args.AR_temperature,\n",
    "                'top_k': self.args.AR_top_k,\n",
    "                'top_p': self.args.AR_top_p,\n",
    "                'num_return_sequences': kwargs.get('num_return_sequences', 1)}\n",
    "   \n",
    "        return return_object\n",
    "    \n",
    "    def _postprocess_output(self, prepared_input, output_ids):\n",
    "        return output_ids[:, prepared_input['input_ids'].size(1):, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beaf9974-8584-4fac-93d9-a3e88aa770f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_loss = GPT2Loss(model,tokenizer,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b365b-834a-4b21-b1f5-800d32e03aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
